{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "主題分類.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BgEXj19f997n",
        "UHMkE-Ps_cFH"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPrDQ2fkA1oqMAM3Kebupju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chunshan-Theta/mandarin_intent_classify/blob/main/examples/%E4%B8%BB%E9%A1%8C%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgEXj19f997n"
      },
      "source": [
        "# 建置環境\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abe9IX_9nwQd",
        "outputId": "0b08c24d-1440-4b37-a285-d84e6be61476"
      },
      "source": [
        "!git clone --branch automation https://github.com/Chunshan-Theta/bert_mulit_label_chinese.git ./bert_mulit_label_chinese/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into './bert_mulit_label_chinese'...\n",
            "remote: Enumerating objects: 55, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 55 (delta 18), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VCG7m_KzEGV",
        "outputId": "8530fc28-6109-476f-a573-8137b46c97ba"
      },
      "source": [
        "!mv -v ./bert_mulit_label_chinese/* ./\n",
        "!rm -rf ./bert_mulit_label_chinese/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed './bert_mulit_label_chinese/bert_wwm' -> './bert_wwm'\n",
            "renamed './bert_mulit_label_chinese/data' -> './data'\n",
            "renamed './bert_mulit_label_chinese/modeling.py' -> './modeling.py'\n",
            "renamed './bert_mulit_label_chinese/mulit_label.py' -> './mulit_label.py'\n",
            "renamed './bert_mulit_label_chinese/optimization.py' -> './optimization.py'\n",
            "renamed './bert_mulit_label_chinese/output' -> './output'\n",
            "renamed './bert_mulit_label_chinese/README.md' -> './README.md'\n",
            "renamed './bert_mulit_label_chinese/requirements.txt' -> './requirements.txt'\n",
            "renamed './bert_mulit_label_chinese/run_mulit.ipynb' -> './run_mulit.ipynb'\n",
            "renamed './bert_mulit_label_chinese/tf_metrics.py' -> './tf_metrics.py'\n",
            "renamed './bert_mulit_label_chinese/tokenization.py' -> './tokenization.py'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NOHxv2WDzxWI",
        "outputId": "d0795a9c-071a-412d-b285-e27608c0bf46"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting absl-py==0.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/58/0aa6fb779dc69cfc811df3398fcbeaeefbf18561b6e36b185df0782781cc/absl_py-0.11.0-py3-none-any.whl (127kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 24.2MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 32.2MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 30kB 37.5MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 40kB 40.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 61kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 71kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 102kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 112kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 122kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.8.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.6.3)\n",
            "Collecting bert4keras==0.6.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/4c/0dfe26eeeb13b46dc1a74f57c7f9531cc0881c5a8efc9f31a058f0c70f61/bert4keras-0.6.5.tar.gz\n",
            "Requirement already satisfied: cachetools==4.2.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.2.1)\n",
            "Requirement already satisfied: certifi==2020.12.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (2020.12.5)\n",
            "Collecting chardet==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/c7/fa589626997dd07bd87d9269342ccb74b1720384a4d739a1872bd84fbe68/chardet-4.0.0-py2.py3-none-any.whl (178kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 46.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers==1.12 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.12)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting gensim==3.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/afe2315e08a38967f8a3036bbe7e38b428e9b7a90e823a83d0d49df1adf5/gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.3MB/s \n",
            "\u001b[?25hCollecting google-auth==1.25.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/90/58d541b95c501063dc3cee96e2ae87660e264f97e8cbb0887cffb627211b/google_auth-1.25.0-py2.py3-none-any.whl (116kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib==0.4.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.4.2)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: grpcio==1.32.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (1.32.0)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.10)\n",
            "Collecting importlib-metadata==3.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/ed/da40116a204abb5c4dd1d929346d33e0d29cedb2cedd18ea98f0385dcd92/importlib_metadata-3.4.0-py3-none-any.whl\n",
            "Collecting joblib==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/5b/bd0f0fb5564183884d8e35b81d06d7ec06a20d1a0c8b4c407f1554691dce/joblib-1.0.0-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 54.6MB/s \n",
            "\u001b[?25hCollecting kashgari==1.1.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/da/cc2e6d092125c805d0721227f34e288657f6bbb6cd750c491227137053ba/kashgari-1.1.5-py3-none-any.whl (88kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (2.4.3)\n",
            "Collecting Keras-Applications==1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hCollecting keras-bert==0.86.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/7f/95fabd29f4502924fa3f09ff6538c5a7d290dfef2c2fe076d3d1a16e08f0/keras-bert-0.86.0.tar.gz\n",
            "Collecting keras-embed-sim==0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/57/ef/61a1e39082c9e1834a2d09261d4a0b69f7c818b359216d4e1912b20b1c86/keras-embed-sim-0.8.0.tar.gz\n",
            "Collecting keras-gpt-2==0.15.0\n",
            "  Downloading https://files.pythonhosted.org/packages/62/31/4a838fff27a4fb7e4455e7848b1db4bfe7f8a4f5241c6012164c596e7d46/keras-gpt-2-0.15.0.tar.gz\n",
            "Collecting keras-layer-normalization==0.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-multi-head==0.27.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
            "Collecting keras-pos-embd==0.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward==0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Requirement already satisfied: Keras-Preprocessing==1.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (1.1.2)\n",
            "Collecting keras-self-attention==0.46.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
            "Collecting keras-transformer==0.38.0\n",
            "  Downloading https://files.pythonhosted.org/packages/89/6c/d6f0c164f4cc16fbc0d0fea85f5526e87a7d2df7b077809e422a7e626150/keras-transformer-0.38.0.tar.gz\n",
            "Collecting Markdown==3.3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/ef/24a91ca96efa0d7802dffb83ccc7a3c677027bea19ec3c9ee80be740408e/Markdown-3.3.3-py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.1MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/d1/45be1144b03b6b1e24f9a924f23f66b4ad030d834ad31fb9e5581bd328af/numpy-1.16.4-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 198kB/s \n",
            "\u001b[?25hRequirement already satisfied: oauthlib==3.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 34)) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (3.3.0)\n",
            "Requirement already satisfied: pandas==1.1.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (1.1.5)\n",
            "Collecting protobuf==3.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e0/dd/5c5d156ee1c4dba470d76dac5ae57084829b4e17547f28e9f636ce3fa54b/protobuf-3.14.0-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 54.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1==0.4.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 38)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules==0.2.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 39)) (0.2.8)\n",
            "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 40)) (2.8.1)\n",
            "Collecting pytz==2021.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/94/784178ca5dd892a98f113cdd923372024dc04b8d40abe77ca76b5fb90ca6/pytz-2021.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 56.5MB/s \n",
            "\u001b[?25hCollecting PyYAML==5.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 43.7MB/s \n",
            "\u001b[?25hCollecting regex==2020.11.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/b2/8f281520d9f08d0f6771b8160a87a4b487850cde9f1abe257da4d8bab599/regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719kB)\n",
            "\u001b[K     |████████████████████████████████| 727kB 57.7MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib==1.3.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 45)) (1.3.0)\n",
            "Collecting rsa==4.7\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/87/dc7a6ebf0afbc602548627fa48e9c1147fa187233bf71d4c51c76a2cfb27/rsa-4.7-py3-none-any.whl\n",
            "Collecting scikit-learn==0.24.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/74/eb899f41d55f957e2591cde5528e75871f817d9fb46d4732423ecaca736d/scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3MB 1.2MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/7e/8f6a79b102ca1ea928bae8998b05bf5dc24a90571db13cd119f275ba6252/scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9MB 1.5MB/s \n",
            "\u001b[?25hCollecting seqeval==0.0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/55/dd/3bf1c646c310daabae47fceb84ea9ab66df7f518a31a89955290d82b8100/seqeval-0.0.10-py3-none-any.whl\n",
            "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 50)) (1.15.0)\n",
            "Collecting smart-open==4.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/54/01525817b6f31533d308968b814999f7e666b2234f39a55cbe5de7c1ff99/smart_open-4.1.2-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 61.2MB/s \n",
            "\u001b[?25hCollecting tensorboard==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 53)) (1.8.0)\n",
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 32kB/s \n",
            "\u001b[?25hCollecting tensorflow-addons==0.12.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 51.5MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 61.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 57)) (1.1.0)\n",
            "Collecting threadpoolctl==2.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Collecting tqdm==4.56.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/02/8f8880a4fd6625461833abcf679d4c12a44c76f9925f92bf212bb6cefaad/tqdm-4.56.0-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.9MB/s \n",
            "\u001b[?25hCollecting typeguard==2.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/28/cc6df4c26d14c338c9744dc510a8c7f1a9115f8233e7602cca140a61430c/typeguard-2.10.0-py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 61)) (3.7.4.3)\n",
            "Collecting urllib3==1.26.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/fc/8a49991f7905261f9ca9df5aa9b58363c3c821ce3e7f671895442b7100f2/urllib3-1.26.3-py2.py3-none-any.whl (137kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 61.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: Werkzeug==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 63)) (1.0.1)\n",
            "Requirement already satisfied: wrapt==1.12.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 64)) (1.12.1)\n",
            "Requirement already satisfied: zipp==3.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 65)) (3.4.0)\n",
            "Collecting tensorflow-gpu==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/72/d06017379ad4760dc58781c765376ce4ba5dcf3c08d37032eeefbccf1c51/tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse==1.6.3->-r requirements.txt (line 3)) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth==1.25.0->-r requirements.txt (line 11)) (53.0.0)\n",
            "Building wheels for collected packages: bert4keras, gast, keras-bert, keras-embed-sim, keras-gpt-2, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention, keras-transformer\n",
            "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert4keras: filename=bert4keras-0.6.5-cp37-none-any.whl size=34211 sha256=09464e451766b939355b0d5ef14f862625676968f3dda8d28e1fa143ff0d8399\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/82/72/56a894ccb2337a25b679cbac552bf2f15f5e8e798a37313de6\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=56cb0227ef8ad3a59508bcc396a49c7ca0408f47a4b5c27eeaca91c2f4f3ffc0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.86.0-cp37-none-any.whl size=34144 sha256=8b9ffcc42fef3f5de0c1c673062b18b3c72bacb9718a67e15c71e9c88d9eed8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/f0/b1/748128b58562fc9e31b907bb5e2ab6a35eb37695e83911236b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.8.0-cp37-none-any.whl size=4558 sha256=67aa8ab6dd093e7b8dd076dc49ce5263a10b119e902518275ae76f2ce32da248\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/45/8b/c111f6cc8bec253e984677de73a6f4f5d2f1649f42aac191c8\n",
            "  Building wheel for keras-gpt-2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-gpt-2: filename=keras_gpt_2-0.15.0-cp37-none-any.whl size=10525 sha256=43d9d1bc18a4edc0d01e011728a5235481aa9d422dfb6a504557b4d374221401\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/b3/c7/fb39496446fc6493380fe3983788cc2dae979acdf3d00ee97f\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp37-none-any.whl size=5269 sha256=dc8458f2c05f775da7abb7e924156d769b520958d486d6445cee15a14c607012\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp37-none-any.whl size=15611 sha256=99ce3261b7b6bc51680e0893f23b1152c14c921e454825de32b236ade3f3a0bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp37-none-any.whl size=7554 sha256=b9327d246326387e7f975871e3f92f5d0a4ca2605fca398b598cd5c0ba5a5409\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp37-none-any.whl size=5623 sha256=4763fb2412e0112d3cb23a1530f4654b7def24abf688cc63d8e3dc1fb857981d\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp37-none-any.whl size=17278 sha256=b6e66a78d6a5f40e7ca667342d200f48784e602d8e0b0da8fee0a551bed109bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.38.0-cp37-none-any.whl size=12942 sha256=245b57b388ab94f45b027d61df8bcdbaa653fd346b068232fe6952644eeda259\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/fb/3a/37b2b9326c799aa010ae46a04ddb04f320d8c77c0b7e837f4e\n",
            "Successfully built bert4keras gast keras-bert keras-embed-sim keras-gpt-2 keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention keras-transformer\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-metadata 0.28.0 has requirement absl-py<0.11,>=0.9, but you'll have absl-py 0.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2 has requirement numpy>=1.17, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: absl-py, bert4keras, chardet, gast, numpy, scipy, smart-open, gensim, rsa, google-auth, importlib-metadata, joblib, threadpoolctl, scikit-learn, seqeval, regex, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-gpt-2, keras-bert, kashgari, Keras-Applications, Markdown, protobuf, pytz, PyYAML, urllib3, requests, tensorboard, tensorflow-estimator, tensorflow, typeguard, tensorflow-addons, tqdm, tensorflow-gpu\n",
            "  Found existing installation: absl-py 0.10.0\n",
            "    Uninstalling absl-py-0.10.0:\n",
            "      Successfully uninstalled absl-py-0.10.0\n",
            "  Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Found existing installation: smart-open 4.2.0\n",
            "    Uninstalling smart-open-4.2.0:\n",
            "      Successfully uninstalled smart-open-4.2.0\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "  Found existing installation: rsa 4.7.2\n",
            "    Uninstalling rsa-4.7.2:\n",
            "      Successfully uninstalled rsa-4.7.2\n",
            "  Found existing installation: google-auth 1.27.0\n",
            "    Uninstalling google-auth-1.27.0:\n",
            "      Successfully uninstalled google-auth-1.27.0\n",
            "  Found existing installation: importlib-metadata 3.7.0\n",
            "    Uninstalling importlib-metadata-3.7.0:\n",
            "      Successfully uninstalled importlib-metadata-3.7.0\n",
            "  Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: Markdown 3.3.4\n",
            "    Uninstalling Markdown-3.3.4:\n",
            "      Successfully uninstalled Markdown-3.3.4\n",
            "  Found existing installation: protobuf 3.12.4\n",
            "    Uninstalling protobuf-3.12.4:\n",
            "      Successfully uninstalled protobuf-3.12.4\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "  Found existing installation: typeguard 2.7.1\n",
            "    Uninstalling typeguard-2.7.1:\n",
            "      Successfully uninstalled typeguard-2.7.1\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed Keras-Applications-1.0.8 Markdown-3.3.3 PyYAML-5.4.1 absl-py-0.11.0 bert4keras-0.6.5 chardet-4.0.0 gast-0.2.2 gensim-3.8.3 google-auth-1.25.0 importlib-metadata-3.4.0 joblib-1.0.0 kashgari-1.1.5 keras-bert-0.86.0 keras-embed-sim-0.8.0 keras-gpt-2-0.15.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.38.0 numpy-1.16.4 protobuf-3.14.0 pytz-2021.1 regex-2020.11.13 requests-2.25.1 rsa-4.7 scikit-learn-0.24.1 scipy-1.5.4 seqeval-0.0.10 smart-open-4.1.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-addons-0.12.1 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0 threadpoolctl-2.1.0 tqdm-4.56.0 typeguard-2.10.0 urllib3-1.26.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXy1PABl0YS8"
      },
      "source": [
        "# 下載wwm模型\n",
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_id = \"1RoTQsXp2hkQ1gSRVylRIJfQxJUgkfJMW\"\n",
        "    destination = './bert_wwm/chinese_wwm_L-12_H-768_A-12.zip'\n",
        "    download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LfAN78I3dRB",
        "outputId": "d904a667-11ab-40e8-c1c3-7cb52b7157a7"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "file_path = f'./bert_wwm/chinese_wwm_L-12_H-768_A-12.zip'\n",
        "out_path = \"./bert_wwm/\"\n",
        "# zipfile example\n",
        "def zip_list(file_path):\n",
        "    zip = zipfile.ZipFile(file_path, 'r')\n",
        "    print(zip.namelist())\n",
        "    zip.extractall(out_path)\n",
        "\n",
        "zip_list(file_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['publish/', 'publish/vocab.txt', 'publish/bert_model.ckpt.index', 'publish/bert_model.ckpt.data-00000-of-00001', 'publish/bert_config.json', 'publish/bert_model.ckpt.meta']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u_PEpG3--Us",
        "outputId": "20c3d61a-324f-402e-9e9f-43067a6943bc"
      },
      "source": [
        "!mv -v ./bert_wwm/publish/* ./bert_wwm/\n",
        "!rm -rf ./bert_wwm/publish/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed './bert_wwm/publish/bert_config.json' -> './bert_wwm/bert_config.json'\n",
            "renamed './bert_wwm/publish/bert_model.ckpt.data-00000-of-00001' -> './bert_wwm/bert_model.ckpt.data-00000-of-00001'\n",
            "renamed './bert_wwm/publish/bert_model.ckpt.index' -> './bert_wwm/bert_model.ckpt.index'\n",
            "renamed './bert_wwm/publish/bert_model.ckpt.meta' -> './bert_wwm/bert_model.ckpt.meta'\n",
            "renamed './bert_wwm/publish/vocab.txt' -> './bert_wwm/vocab.txt'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHMkE-Ps_cFH"
      },
      "source": [
        "# 產生原始資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ks0LJVc9_bwz",
        "outputId": "a5e2456f-8f58-4db4-9c03-17f15fd7b3cb"
      },
      "source": [
        "# 下載wiki資料\n",
        "import urllib.request\n",
        "import progressbar\n",
        "# https://dumps.wikimedia.org/zhwiki/latest/ 可以在這裡找到其他檔案\n",
        "url = \"https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-meta-current1.xml-p1p187712.bz2\"\n",
        "url = \"https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles1.xml-p1p187712.bz2\"\n",
        "filename = \"./data/zhwiki-latest-pages-meta-current1.xml.bz2\"\n",
        "pbar = None\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "        pbar.start()\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None\n",
        "\n",
        "data = urllib.request.urlretrieve(url=url,filename=filename,reporthook=show_progress)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (200806036 of 200806036) |##########| Elapsed Time: 0:00:43 Time:  0:00:43\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0TwT1vP_vQp",
        "outputId": "a88f5034-54be-491a-a6c4-0429dd1c3718"
      },
      "source": [
        "# 處理wiki文章\n",
        "import logging\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings(action ='ignore', category = UserWarning, module = 'gensim')\n",
        "from gensim.corpora import WikiCorpus\n",
        "\n",
        "# 將 wiki 資料集載下後進行 xml convert to txt \n",
        "class Wiki_to_txt(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        # 用默認 Formatter 為日誌系統建立一個 StreamHandler ，設置基礎配置並加到 root logger 中\n",
        "        logging.basicConfig(format = '%(asctime)s : %(levelname)s : %(message)s', level = logging.INFO)\n",
        "\n",
        "    # 使用方法 https://radimrehurek.com/gensim/corpora/wikicorpus.html\n",
        "    def set_wiki_to_txt(self, wiki_data_path = None):\n",
        "        if wiki_data_path == None:\n",
        "            # 系統下參數\n",
        "            if len(sys.argv) != 2:\n",
        "                print(\"Please Usage: python3 \" + sys.argv[0] + \" wiki_data_path\")\n",
        "                exit()\n",
        "            else:\n",
        "                wiki_corpus = WikiCorpus(sys.argv[1], dictionary = {})\n",
        "        else:\n",
        "            wiki_corpus = WikiCorpus(wiki_data_path, dictionary = {})\n",
        "        # wiki.xml convert to wiki.txt\n",
        "        with open(\"./data/wiki_text.txt\", 'w', encoding = 'utf-8') as output:\n",
        "            text_count = 0\n",
        "            \n",
        "            for text in wiki_corpus.get_texts():\n",
        "                # save use string(gensim)\n",
        "                output.write(' '.join(text) + '\\n')\n",
        "                text_count += 1\n",
        "                if text_count % 1000 == 0:\n",
        "                    print(f\"目前已處理 {text_count} 篇文章\")\n",
        "            print(\"轉檔完畢!\")\n",
        "            \n",
        "if __name__ == \"__main__\":\n",
        "    wiki_to_txt = Wiki_to_txt()\n",
        "    # 將 wiki xml 轉換成 wiki txt\n",
        "    wiki_to_txt.set_wiki_to_txt(filename)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "目前已處理 1000 篇文章\n",
            "目前已處理 2000 篇文章\n",
            "目前已處理 3000 篇文章\n",
            "目前已處理 4000 篇文章\n",
            "目前已處理 5000 篇文章\n",
            "目前已處理 6000 篇文章\n",
            "目前已處理 7000 篇文章\n",
            "目前已處理 8000 篇文章\n",
            "目前已處理 9000 篇文章\n",
            "目前已處理 10000 篇文章\n",
            "目前已處理 11000 篇文章\n",
            "目前已處理 12000 篇文章\n",
            "目前已處理 13000 篇文章\n",
            "目前已處理 14000 篇文章\n",
            "目前已處理 15000 篇文章\n",
            "目前已處理 16000 篇文章\n",
            "目前已處理 17000 篇文章\n",
            "目前已處理 18000 篇文章\n",
            "目前已處理 19000 篇文章\n",
            "目前已處理 20000 篇文章\n",
            "目前已處理 21000 篇文章\n",
            "目前已處理 22000 篇文章\n",
            "目前已處理 23000 篇文章\n",
            "目前已處理 24000 篇文章\n",
            "目前已處理 25000 篇文章\n",
            "目前已處理 26000 篇文章\n",
            "目前已處理 27000 篇文章\n",
            "目前已處理 28000 篇文章\n",
            "目前已處理 29000 篇文章\n",
            "目前已處理 30000 篇文章\n",
            "目前已處理 31000 篇文章\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-02-28 16:09:49,269 : INFO : finished iterating over Wikipedia corpus of 31626 documents with 11448587 positions (total 86064 articles, 11827400 positions before pruning articles shorter than 50 words)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "轉檔完畢!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5D0gUFgAQUy",
        "outputId": "80eaf114-1641-45f7-b77a-08076926232b"
      },
      "source": [
        "!pip install hanziconv\n",
        "!pip install pypinyin"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hanziconv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/71/b89cb63077fd807fe31cf7c016a06e7e579a289d8a37aa24a30282d02dd2/hanziconv-0.3.2.tar.gz (276kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 5.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: hanziconv\n",
            "  Building wheel for hanziconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hanziconv: filename=hanziconv-0.3.2-py2.py3-none-any.whl size=23215 sha256=04271fff5d469f1333c2c3e6ed4ba928f0c211ae6d88c21dfba6257e5f844802\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/d8/3c/c39898fa9c9ce6e34b0ab4c6604892462d440c743715c94054\n",
            "Successfully built hanziconv\n",
            "Installing collected packages: hanziconv\n",
            "Successfully installed hanziconv-0.3.2\n",
            "Collecting pypinyin\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/50/58b16cb56aeb003246d76ce3648f8e449605d7595e444a9b7c87bd543db8/pypinyin-0.40.0-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 5.6MB/s \n",
            "\u001b[?25hInstalling collected packages: pypinyin\n",
            "Successfully installed pypinyin-0.40.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTUys19uAQ6_",
        "outputId": "30d3684c-7d46-4b7b-8312-d21627cc0416"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import jieba\n",
        "import logging\n",
        "from hanziconv import HanziConv\n",
        "import urllib.request\n",
        "from pypinyin import lazy_pinyin,Style\n",
        "\n",
        "\n",
        "ENV_simplified_to_traditional = True\n",
        "ENV_lazy_pinyin = False\n",
        "ENV_lazy_pinyin_style=Style.TONE3\n",
        "\n",
        "\n",
        "# 進行斷詞並過濾 stopword\n",
        "class Segmentation(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        # 用默認 Formatter 為日誌系統建立一個 StreamHandler ，設置基礎配置並加到 root logger 中\n",
        "        logging.basicConfig(format = \"%(asctime)s : %(levelname)s : %(message)s\", level = logging.INFO)\n",
        "        self.stopwordset = set()\n",
        "        \n",
        "    # 讀取 stopword 辭典，並存到 stopwordset\n",
        "    def set_stopword(self):\n",
        "        stopwords_url =\"https://raw.githubusercontent.com/Chunshan-Theta/mandarin_fields_intent/main/stopword.txt\" # it's a file like object and works just like a file\n",
        "        for line in urllib.request.urlopen(stopwords_url):\n",
        "            self.stopwordset.add(line.decode(\"utf-8\").strip(\"\\n\"))\n",
        "        #print(self.stopwordset)\n",
        "        print(\"StopWord Set 已儲存!\")\n",
        "\n",
        "    # 簡 to 繁\n",
        "    def simplified_to_traditional(self):\n",
        "        logging.info(\"等待中..(簡 to 繁)\")\n",
        "        traditional = open(\"./data/traditional.txt\", \"w\", encoding = \"utf-8\")\n",
        "        with open(\"./data/wiki_text.txt\", \"r\", encoding = \"utf-8\") as simplified:\n",
        "            simplifiedData = list(simplified)\n",
        "            idx = 0\n",
        "            for s in simplifiedData:\n",
        "                if ENV_simplified_to_traditional:\n",
        "                    traditional.write(HanziConv.toTraditional(s))\n",
        "                else:\n",
        "                    traditional.write(s)\n",
        "                idx +=1\n",
        "                if idx % 1000 == 0:\n",
        "                    print(f\"{idx} /{len(simplifiedData)}篇文章已成功簡體轉繁體\")\n",
        "        print(\"成功簡體轉繁體!\")\n",
        "        traditional.close()\n",
        "\n",
        "    # 斷詞(Segmentation)並過濾掉停用詞(Stop Word) \n",
        "    def segmentation(self):\n",
        "        logging.info(\"等待中..(jieba 斷詞，並過濾停用詞)\")\n",
        "        segmentation = open(\"./data/segmentation.txt\", \"w\", encoding = \"utf-8\")\n",
        "        with open(\"./data/traditional.txt\", \"r\", encoding = \"utf-8\") as Corpus:\n",
        "            CorpusData = list(Corpus)\n",
        "            for idx, sentence in enumerate(CorpusData):\n",
        "                sentence = sentence.strip(\"\\n\")\n",
        "                pos = jieba.cut(sentence, cut_all = False)\n",
        "                for term in pos:\n",
        "                    if term not in self.stopwordset:\n",
        "                        if ENV_lazy_pinyin:\n",
        "                            term_pinyin = \"\".join(lazy_pinyin(term,style=ENV_lazy_pinyin_style))\n",
        "                            segmentation.write(term_pinyin + \" \")\n",
        "                        else:\n",
        "                            segmentation.write(term + \" \")\n",
        "                segmentation.write(\"\\n\")\n",
        "                if idx % 100 == 0:\n",
        "                    print(f\"{idx}/ {len(CorpusData)}篇文章已 jieba 斷詞完畢，並完成過濾停用詞!\")\n",
        "        print(\"全部篇文章已jieba 斷詞完畢，並已完成過濾停用詞!\")\n",
        "        segmentation.close()\n",
        "\n",
        "    # 斷詞(Segmentation)並過濾掉停用詞(Stop Word)\n",
        "    @staticmethod\n",
        "    def CorpusSegmentation(Corpus,stopwordset):\n",
        "        formattedCorpus = []\n",
        "        for sentence in Corpus:\n",
        "            if ENV_simplified_to_traditional:\n",
        "                sentence = HanziConv.toTraditional(sentence.strip(\"\\n\"))\n",
        "            else:\n",
        "                sentence = sentence.strip(\"\\n\")\n",
        "            pos = jieba.cut(sentence, cut_all = False)\n",
        "            sentence = \"\"\n",
        "            for term in pos:\n",
        "                if term not in stopwordset:\n",
        "                    if ENV_lazy_pinyin:\n",
        "                        term_pinyin = \"\".join(lazy_pinyin(term,style=ENV_lazy_pinyin_style))\n",
        "                        sentence += (term_pinyin + \" \")\n",
        "                    else:\n",
        "                        sentence += (term + \" \")\n",
        "            formattedCorpus.append(sentence)\n",
        "        return formattedCorpus\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    segmentation = Segmentation()\n",
        "    # 讀取停用詞辭典\n",
        "    segmentation.set_stopword()\n",
        "    # data 進行簡體轉繁體\n",
        "    segmentation.simplified_to_traditional()\n",
        "    # 進行 jieba 斷詞同步過濾停用詞，並產生辭典\n",
        "    #segmentation.segmentation()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-28 16:09:58,077 : INFO : 等待中..(簡 to 繁)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "StopWord Set 已儲存!\n",
            "1000 /31626篇文章已成功簡體轉繁體\n",
            "2000 /31626篇文章已成功簡體轉繁體\n",
            "3000 /31626篇文章已成功簡體轉繁體\n",
            "4000 /31626篇文章已成功簡體轉繁體\n",
            "5000 /31626篇文章已成功簡體轉繁體\n",
            "6000 /31626篇文章已成功簡體轉繁體\n",
            "7000 /31626篇文章已成功簡體轉繁體\n",
            "8000 /31626篇文章已成功簡體轉繁體\n",
            "9000 /31626篇文章已成功簡體轉繁體\n",
            "10000 /31626篇文章已成功簡體轉繁體\n",
            "11000 /31626篇文章已成功簡體轉繁體\n",
            "12000 /31626篇文章已成功簡體轉繁體\n",
            "13000 /31626篇文章已成功簡體轉繁體\n",
            "14000 /31626篇文章已成功簡體轉繁體\n",
            "15000 /31626篇文章已成功簡體轉繁體\n",
            "16000 /31626篇文章已成功簡體轉繁體\n",
            "17000 /31626篇文章已成功簡體轉繁體\n",
            "18000 /31626篇文章已成功簡體轉繁體\n",
            "19000 /31626篇文章已成功簡體轉繁體\n",
            "20000 /31626篇文章已成功簡體轉繁體\n",
            "21000 /31626篇文章已成功簡體轉繁體\n",
            "22000 /31626篇文章已成功簡體轉繁體\n",
            "23000 /31626篇文章已成功簡體轉繁體\n",
            "24000 /31626篇文章已成功簡體轉繁體\n",
            "25000 /31626篇文章已成功簡體轉繁體\n",
            "26000 /31626篇文章已成功簡體轉繁體\n",
            "27000 /31626篇文章已成功簡體轉繁體\n",
            "28000 /31626篇文章已成功簡體轉繁體\n",
            "29000 /31626篇文章已成功簡體轉繁體\n",
            "30000 /31626篇文章已成功簡體轉繁體\n",
            "31000 /31626篇文章已成功簡體轉繁體\n",
            "成功簡體轉繁體!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuZX4jyP4qTA"
      },
      "source": [
        "# 產生訓練集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rcrTk0YA8zp",
        "outputId": "4a4ce49b-bb64-4759-a50f-7449e6341f11"
      },
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "\n",
        "def check_match_re(rule, string):\n",
        "    rule = rule.replace(\"｜\", \"|\")\n",
        "    regex = re.compile(rule)\n",
        "    if regex.match(string) is None:\n",
        "        return None\n",
        "    else:\n",
        "        return regex.match(string).string\n",
        "\n",
        "\n",
        "\n",
        "types = {\n",
        "    \"經濟_成本\": [\n",
        "        r\".*(成本|花費|昂貴)+.*\"\n",
        "    ],\n",
        "    \"永續_污染\": [\n",
        "        r\".*(環境|自然|生態|森林|海洋|空氣|天空|生物)+.*(破壞|浩劫|災害)+.*\",\n",
        "        r\".*(破壞|影響|造成)+.*(環境|自然|生態|森林|海洋|空氣|天空)+.*\"\n",
        "    ],\n",
        "    \"社會_人民感受\": [\n",
        "        r\".*(人民|民眾|社區|居民|大家|多數人|造成|引發|人群)+.*(畏懼|害怕|擔心|恐懼|緊張|慌張)+.*\",\n",
        "        r\".*(主婦|中年|年輕人|老年|幼童|小孩)+.*(畏懼|害怕|擔心|恐懼|緊張|慌張)+.*\",\n",
        "        r\".*(恐慌)+.*\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "if not os.path.isdir(\"./data/data-wiki/\") :\n",
        "    os.makedirs(\"./data/data-wiki/\")\n",
        "sentences_classify = {}\n",
        "with open(\"./data/traditional.txt\", \"r\", encoding=\"utf-8\") as Corpus, open(\"./data/data-wiki/train.tsv\", \"w\", encoding=\"utf-8\") as f,  open(\"./data/data-wiki/test.tsv\", \"w\", encoding=\"utf-8\") as o:\n",
        "    CorpusData = list(Corpus)\n",
        "    for t, ks in types.items():\n",
        "        cut = 0\n",
        "        for k in ks:\n",
        "            print(f\"{t}\\t{k}\")\n",
        "            for idx, sentence in enumerate(CorpusData):\n",
        "                sentences = sentence.split(\" \")\n",
        "                for s in sentences:\n",
        "                    s = check_match_re(rule=k, string=s)\n",
        "                    if s is not None and len(s) > 12:\n",
        "                        cut+=1\n",
        "                        if s not in sentences_classify:\n",
        "                            sentences_classify[s] = []\n",
        "                        if t not in sentences_classify[s]:\n",
        "                            sentences_classify[s].append(t)\n",
        "        print(f\"{t}: {cut}\")\n",
        "    idx = 0\n",
        "    for s, ts in sentences_classify.items():\n",
        "        idx +=1\n",
        "        t = str(ts).replace(\"\\'\", \"\")\n",
        "        if idx %10 != 0:\n",
        "          f.write(f\"{t}\\t{s}\\n\")\n",
        "        else:\n",
        "          o.write(f\"{t}\\t{s}\\n\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "經濟_成本\t.*(成本|花費|昂貴)+.*\n",
            "經濟_成本: 761\n",
            "永續_污染\t.*(環境|自然|生態|森林|海洋|空氣|天空)+.*(破壞|浩劫|災害)+.*\n",
            "永續_污染\t.*(破壞|影響|造成)+.*(環境|自然|生態|森林|海洋|空氣|天空)+.*\n",
            "永續_污染: 134\n",
            "社會_人民感受\t.*(人民|民眾|社區|居民|大家|多數人|造成|引發)+.*(畏懼|害怕|擔心|恐懼|緊張|慌張)+.*\n",
            "社會_人民感受\t.*(主婦|中年|年輕人|老年|幼童|小孩)+.*(畏懼|害怕|擔心|恐懼|緊張|慌張)+.*\n",
            "社會_人民感受\t.*(恐慌)+.*\n",
            "社會_人民感受: 91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFSdRvDY-CSv"
      },
      "source": [
        "# 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyR17P23KtHk",
        "outputId": "6a582744-0ac9-4282-f89e-06ca61ddc278"
      },
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2018 The Google AI Language Team Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\"BERT finetuning runner.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import csv\n",
        "import os\n",
        "import modeling\n",
        "import optimization\n",
        "import tokenization\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import metrics_impl\n",
        "from tensorflow.python.ops import variable_scope\n",
        "from tensorflow.python.distribute import distribution_strategy_context\n",
        "\n",
        "import tf_metrics\n",
        "\n",
        "model_tag = \"1\"\n",
        "data_dir = f'data/data-wiki/'\n",
        "bert_config_file = 'bert_wwm/bert_config.json'\n",
        "task_name = \"customized\"\n",
        "output_dir = f'./output-wiki-{model_tag}/'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "init_checkpoint = 'bert_wwm/bert_model.ckpt'\n",
        "do_lower_case = True\n",
        "max_seq_length = 20\n",
        "use_tpu = False\n",
        "use_one_hot_embeddings = False\n",
        "do_train = True\n",
        "do_eval = True\n",
        "do_predict = True\n",
        "train_batch_size = 32\n",
        "eval_batch_size = 32\n",
        "predict_batch_size = 32\n",
        "learning_rate = 5e-5\n",
        "num_train_epochs = 35\n",
        "warmup_proportion = 0.1\n",
        "save_checkpoints_steps = 100\n",
        "iterations_per_loop = 1000\n",
        "vocab_file = './bert_wwm/vocab.txt'\n",
        "master = None\n",
        "num_tpu_cores = 8\n",
        "crf_loss_method=True\n",
        "do_export = False\n",
        "export_dir = None\n",
        "dataset = [\"train.tsv\", \"train.tsv\", \"test.tsv\"]\n",
        "\n",
        "\n",
        "####\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "          guid: Unique id for the example.\n",
        "          text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "          text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "          label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text = text\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class PaddingInputExample(object):\n",
        "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
        "    When running eval/predict on the TPU, we need to pad the number of examples\n",
        "    to be a multiple of the batch size, because the TPU requires a fixed batch\n",
        "    size. The alternative is to drop the last batch, which is bad because it means\n",
        "    the entire output data won't be generated.\n",
        "    We use this class instead of `None` because treating `None` as padding\n",
        "    battches could cause silent errors.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 input_ids,\n",
        "                 input_mask,\n",
        "                 segment_ids,\n",
        "                 label_ids,\n",
        "                 is_real_example=True):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids\n",
        "        self.is_real_example = is_real_example\n",
        "\n",
        "\n",
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for prediction.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with tf.gfile.Open(input_file, \"r\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                if len(line) > 0:\n",
        "                    lines.append(line)\n",
        "\n",
        "            return lines\n",
        "\n",
        "    @classmethod\n",
        "    def _read_data(cls, input_file):\n",
        "        \"\"\"Reads a BIO data.\"\"\"\n",
        "        with open(input_file) as f:\n",
        "            lines = []\n",
        "            words = []\n",
        "            labels = []\n",
        "            for line in f:\n",
        "                contends = line.strip()\n",
        "                word = line.strip().split(' ')[0]\n",
        "                label = line.strip().split(' ')[-1]\n",
        "                if contends.startswith(\"-DOCSTART-\"):\n",
        "                    words.append('')\n",
        "                    continue\n",
        "                # if len(contends) == 0 and words[-1] == '。':\n",
        "                if len(contends) == 0:\n",
        "                    l = ' '.join([label for label in labels if len(label) > 0])\n",
        "                    w = ' '.join([word for word in words if len(word) > 0])\n",
        "                    lines.append([l, w])\n",
        "                    words = []\n",
        "                    labels = []\n",
        "                    continue\n",
        "                words.append(word)\n",
        "                labels.append(label)\n",
        "            return lines\n",
        "\n",
        "\n",
        "class customizedProcessor(DataProcessor):\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, dataset[0])), \"train\")\n",
        "\n",
        "    def get_dev_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, dataset[1])), \"dev\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"See base class.\"\"\"\n",
        "        return self._create_examples(\n",
        "            self._read_tsv(os.path.join(data_dir, dataset[2])), \"test\")\n",
        "\n",
        "    def get_labels_info(self):\n",
        "        labels = []\n",
        "        label_map = {}\n",
        "        label_map_file = os.path.join( output_dir, \"label_map.txt\")\n",
        "        lines = self._read_tsv(os.path.join( data_dir, dataset[0]))\n",
        "\n",
        "        for line in lines:\n",
        "            if len(line) == 0:\n",
        "                continue\n",
        "            try:\n",
        "                line_of_labels = line[0].strip(\"[]\").split(', ')\n",
        "            except IndexError as e:\n",
        "                print(f\"IndexError:{line}\")\n",
        "                raise e\n",
        "            for label in line_of_labels:\n",
        "                labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "        all_labels = labels  # for cal intent_weights\n",
        "\n",
        "        labels = sorted(set(labels), reverse=False)\n",
        "        num_labels = sorted(set(labels), reverse=True).__len__()\n",
        "\n",
        "        intent_class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                                 labels,\n",
        "                                                                 all_labels)\n",
        "\n",
        "\n",
        "        with tf.gfile.GFile(label_map_file, \"w\") as writer:\n",
        "            for (i, label) in enumerate(labels):\n",
        "                label_map[label] = i\n",
        "                writer.write(\"{}:{}\\n\".format(i, label))\n",
        "\n",
        "\n",
        "\n",
        "        return label_map, num_labels, intent_class_weights\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "        examples = []\n",
        "        for (i, line) in enumerate(lines):\n",
        "            guid = \"%s-%s\" % (set_type, i)\n",
        "            try:\n",
        "                label = tokenization.convert_to_unicode(line[0])\n",
        "                text = tokenization.convert_to_unicode(line[1])\n",
        "                examples.append(InputExample(guid=guid, text=text, label=label))\n",
        "            except IndexError as e:\n",
        "                print(line)\n",
        "                raise e\n",
        "        return examples\n",
        "\n",
        "\n",
        "def write_tokens(tokens, mode):\n",
        "    if mode == \"test\":\n",
        "        path = os.path.join( output_dir, \"token_\" + mode + \".txt\")\n",
        "        wf = open(path, 'a')\n",
        "        for token in tokens:\n",
        "            if token != \"**NULL**\":\n",
        "                wf.write(token + '\\n')\n",
        "        wf.close()\n",
        "\n",
        "def convert_single_example(ex_index, example, label_map,\n",
        "                           max_seq_length, tokenizer):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        return InputFeatures(\n",
        "            input_ids=[0] * max_seq_length,\n",
        "            input_mask=[0] * max_seq_length,\n",
        "            segment_ids=[0] * max_seq_length,\n",
        "            label_ids=[0] * len(label_map),\n",
        "            is_real_example=False)\n",
        "\n",
        "    tokens_list = example.text\n",
        "    tokens = []\n",
        "    tags = []\n",
        "\n",
        "    tokens.append(\"[CLS]\")\n",
        "\n",
        "    for i, word in enumerate(tokens_list):\n",
        "        token = tokenizer.tokenize(word)\n",
        "        tokens.extend(token)\n",
        "\n",
        "    tokens.append(\"[SEP]\")\n",
        "\n",
        "\n",
        "    if len(tokens) >= max_seq_length:\n",
        "        tokens = tokens[0:max_seq_length]\n",
        "\n",
        "    \n",
        "\n",
        "    segment_ids = [0] * max_seq_length\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    input_mask = [1] * len(input_ids)\n",
        "    label_list = example.label.strip('[]').split(', ')\n",
        "    multi_label_list = [0] * len(label_map)\n",
        "\n",
        "    for label in label_list:\n",
        "        label_index = label_map[label]\n",
        "        multi_label_list[label_index] = 1\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    if ex_index < 5:\n",
        "        tf.logging.info(\"*** Example ***\")\n",
        "        tf.logging.info(\"guid: %s\" % (example.guid))\n",
        "        tf.logging.info(\"label: %s\" % (example.label))\n",
        "        tf.logging.info(\"tokens: %s\" % \" \".join(\n",
        "            [tokenization.printable_text(x) for x in tokens]))\n",
        "        tf.logging.info(\n",
        "            \"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "        tf.logging.info(\n",
        "            \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "        tf.logging.info(\n",
        "            \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
        "        #tf.logging.info(\"tags_ids: %s\" % \" \".join([str(x) for x in tags_ids]))\n",
        "    feature = InputFeatures(\n",
        "        label_ids=multi_label_list,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        segment_ids=segment_ids)\n",
        "    return feature\n",
        "\n",
        "\n",
        "def file_based_convert_examples_to_features(\n",
        "        examples, label_map, max_seq_length, tokenizer, output_file):\n",
        "    \"\"\"Convert a set of `InputExample`s to a TFRecord file.\"\"\"\n",
        "    writer = tf.python_io.TFRecordWriter(output_file)\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            tf.logging.info(\n",
        "                \"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "        feature = convert_single_example(ex_index, example, label_map,\n",
        "                                        max_seq_length, tokenizer)\n",
        "\n",
        "        def create_int_feature(values):\n",
        "            f = tf.train.Feature(\n",
        "                int64_list=tf.train.Int64List(value=list(values)))\n",
        "            return f\n",
        "\n",
        "        features = collections.OrderedDict()\n",
        "        features[\"label_ids\"] = create_int_feature(feature.label_ids)\n",
        "        features[\"input_ids\"] = create_int_feature(feature.input_ids)\n",
        "        features[\"input_mask\"] = create_int_feature(feature.input_mask)\n",
        "        features[\"segment_ids\"] = create_int_feature(feature.segment_ids)\n",
        "        features[\"is_real_example\"] = create_int_feature(\n",
        "            [int(feature.is_real_example)])\n",
        "\n",
        "        tf_example = tf.train.Example(\n",
        "            features=tf.train.Features(feature=features))\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
        "                                drop_remainder, num_labels):\n",
        "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "    name_to_features = {\n",
        "        \"label_ids\": tf.FixedLenFeature([num_labels], tf.int64),\n",
        "        \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"input_mask\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
        "        \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
        "    }\n",
        "\n",
        "    def _decode_record(record, name_to_features):\n",
        "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "        example = tf.parse_single_example(record, name_to_features)\n",
        "\n",
        "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "        # So cast all int64 to int32.\n",
        "        for name in list(example.keys()):\n",
        "            t = example[name]\n",
        "            if t.dtype == tf.int64:\n",
        "                t = tf.to_int32(t)\n",
        "            example[name] = t\n",
        "\n",
        "        return example\n",
        "\n",
        "    def input_fn(params):\n",
        "        \"\"\"The actual input function.\"\"\"\n",
        "        batch_size = params[\"batch_size\"]\n",
        "\n",
        "        # For training, we want a lot of parallel reading and shuffling.\n",
        "        # For eval, we want no shuffling and parallel reading doesn't matter.\n",
        "        d = tf.data.TFRecordDataset(input_file)\n",
        "        if is_training:\n",
        "            d = d.repeat()\n",
        "            d = d.shuffle(buffer_size=100)\n",
        "\n",
        "        d = d.apply(\n",
        "            tf.contrib.data.map_and_batch(\n",
        "                lambda record: _decode_record(record, name_to_features),\n",
        "                batch_size=batch_size,\n",
        "                drop_remainder=drop_remainder))\n",
        "\n",
        "        return d\n",
        "\n",
        "    return input_fn\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "\n",
        "def create_model(bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "                 label_ids,  intent_num_labels, intent_class_weights,\n",
        "                 use_one_hot_embeddings):\n",
        "    \"\"\"Creates a classification model.\"\"\"\n",
        "    model = modeling.BertModel(\n",
        "        config=bert_config,\n",
        "        is_training=is_training,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=segment_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    # In the demo, we are doing a simple classification task on the entire\n",
        "    # segment.\n",
        "    #\n",
        "    # If you want to use the token-level output, use model.get_sequence_output()\n",
        "    # instead.\n",
        "    intent_output_layer = model.get_pooled_output()\n",
        "    sequence_output_layer = model.get_sequence_output()\n",
        "\n",
        "    hidden_size = sequence_output_layer.shape[-1].value\n",
        "\n",
        "    ## intent loss\n",
        "    intent_output_weights = tf.get_variable(\n",
        "        \"intent_output_weights\", [intent_num_labels, hidden_size],\n",
        "        # initializer=tf.truncated_normal_initializer(stddev=0.02)\n",
        "        initializer=tf.contrib.layers.xavier_initializer()\n",
        "    )\n",
        "\n",
        "    intent_output_bias = tf.get_variable(\n",
        "        \"intent_output_bias\", [intent_num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "    with tf.variable_scope(\"intent_loss\"):\n",
        "        if is_training:\n",
        "            # I.e., 0.1 dropout\n",
        "            intent_output_layer = tf.nn.dropout(intent_output_layer, keep_prob=0.9)\n",
        "\n",
        "        intent_logits = tf.matmul(intent_output_layer, intent_output_weights, transpose_b=True)\n",
        "        intent_logits = tf.nn.bias_add(intent_logits, intent_output_bias, name='intent_logits')\n",
        "        intent_probabilities = tf.nn.sigmoid(intent_logits, name='intent_probabilities')\n",
        "        # classes_weights = tf.constant([1] * intent_num_labels, dtype=tf.float32)\n",
        "\n",
        "        classes_weights = tf.constant(intent_class_weights, dtype=tf.float32)\n",
        "\n",
        "        weighted_cross_entropy = tf.nn.weighted_cross_entropy_with_logits(labels=tf.cast(label_ids, tf.float32),\n",
        "                                                                          logits=intent_logits,\n",
        "                                                                          pos_weight=classes_weights)\n",
        "        intent_per_example_loss = tf.reduce_sum(weighted_cross_entropy, axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "    loss = tf.reduce_mean(intent_per_example_loss)\n",
        "\n",
        "    return (loss, -1, intent_logits, -1, intent_probabilities)\n",
        "\n",
        "\n",
        "def f1_score(labels, predictions, weights=None, num_thresholds=200,\n",
        "             metrics_collections=None, updates_collections=None, name=None):\n",
        "    with variable_scope.variable_scope(\n",
        "            name, 'f1', (labels, predictions, weights)):\n",
        "        predictions, labels, weights = metrics_impl._remove_squeezable_dimensions(  # pylint: disable=protected-access\n",
        "            predictions=predictions, labels=labels, weights=weights)\n",
        "        # To account for floating point imprecisions / avoid division by zero.\n",
        "        epsilon = 1e-7\n",
        "        thresholds = [(i + 1) * 1.0 / (num_thresholds - 1)\n",
        "                      for i in range(num_thresholds - 2)]\n",
        "        thresholds = [0.0 - epsilon] + thresholds + [1.0 + epsilon]\n",
        "        thresholds_tensor = tf.constant(thresholds)\n",
        "\n",
        "        # Confusion matrix.\n",
        "        values, update_ops = metrics_impl._confusion_matrix_at_thresholds(  # pylint: disable=protected-access\n",
        "            labels, predictions, thresholds, weights, includes=('tp', 'fp', 'fn'))\n",
        "\n",
        "        # Compute precision and recall at various thresholds.\n",
        "        def compute_best_f1_score(tp, fp, fn, name):\n",
        "            precision_at_t = math_ops.div(tp, epsilon + tp + fp,\n",
        "                                          name='precision_' + name)\n",
        "            recall_at_t = math_ops.div(tp, epsilon + tp + fn, name='recall_' + name)\n",
        "            # Compute F1 score.\n",
        "            f1_at_thresholds = (\n",
        "                    2.0 * precision_at_t * recall_at_t /\n",
        "                    (precision_at_t + recall_at_t + epsilon))\n",
        "\n",
        "            best_f1 = math_ops.reduce_max(f1_at_thresholds)\n",
        "            best_f1_index = tf.math.argmax(f1_at_thresholds)\n",
        "            precision = precision_at_t[best_f1_index]\n",
        "            recall = recall_at_t[best_f1_index]\n",
        "            threshold = thresholds_tensor[best_f1_index]\n",
        "            return best_f1, precision, recall, threshold\n",
        "\n",
        "        def f1_across_replicas(_, values):\n",
        "            best_f1, precision, recall, threshold = compute_best_f1_score(tp=values['tp'], fp=values['fp'],\n",
        "                                                                          fn=values['fn'], name='value')\n",
        "            if metrics_collections:\n",
        "                ops.add_to_collections(metrics_collections, best_f1, precision, recall, threshold)\n",
        "            return best_f1, precision, recall, threshold\n",
        "\n",
        "        best_f1, precision, recall, threshold = distribution_strategy_context.get_replica_context().merge_call(\n",
        "            f1_across_replicas, args=(values,))\n",
        "\n",
        "        update_op = compute_best_f1_score(tp=update_ops['tp'], fp=update_ops['fp'],\n",
        "                                          fn=update_ops['fn'], name='update')\n",
        "        if updates_collections:\n",
        "            ops.add_to_collections(updates_collections, update_op)\n",
        "\n",
        "        # return (best_f1, precision, recall, threshold), update_op\n",
        "        return (best_f1, update_op), (precision, update_op), (recall, update_op), (threshold, update_op)\n",
        "        # return best_f1, precision, recall, threshold\n",
        "\n",
        "\n",
        "def model_fn_builder(bert_config, num_labels, intent_class_weights, init_checkpoint,\n",
        "                     learning_rate,\n",
        "                     num_train_steps, num_warmup_steps, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "        tf.logging.info(\"*** Features ***\")\n",
        "        for name in sorted(features.keys()):\n",
        "            tf.logging.info(\"  name = %s, shape = %s\" % (name, features[name].shape))\n",
        "\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "        is_real_example = None\n",
        "        if \"is_real_example\" in features:\n",
        "            is_real_example = tf.cast(features[\"is_real_example\"], dtype=tf.float32)\n",
        "        else:\n",
        "            is_real_example = tf.ones(tf.shape(label_ids), dtype=tf.float32)\n",
        "\n",
        "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
        "\n",
        "        (total_loss, sequence_logits, intent_logits, decode_tags, probabilities) = create_model(\n",
        "            bert_config, is_training, input_ids, input_mask, segment_ids,\n",
        "            label_ids, num_labels, intent_class_weights, use_one_hot_embeddings)\n",
        "\n",
        "        tvars = tf.trainable_variables()\n",
        "        initialized_variable_names = {}\n",
        "        scaffold_fn = None\n",
        "        if init_checkpoint:\n",
        "            (assignment_map, initialized_variable_names\n",
        "             ) = modeling.get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
        "            if use_tpu:\n",
        "\n",
        "                def tpu_scaffold():\n",
        "                    tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "                    return tf.train.Scaffold()\n",
        "\n",
        "                scaffold_fn = tpu_scaffold\n",
        "            else:\n",
        "                tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "        tf.logging.info(\"**** Trainable Variables ****\")\n",
        "        for var in tvars:\n",
        "            init_string = \"\"\n",
        "            if var.name in initialized_variable_names:\n",
        "                init_string = \", *INIT_FROM_CKPT*\"\n",
        "            tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                            init_string)\n",
        "\n",
        "        output_spec = None\n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "\n",
        "            train_op = optimization.create_optimizer(\n",
        "                total_loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu)\n",
        "\n",
        "            logging_hook = tf.train.LoggingTensorHook({\"loss\": total_loss}, every_n_iter=10)\n",
        "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "                mode=mode,\n",
        "                loss=total_loss,\n",
        "                train_op=train_op,\n",
        "                training_hooks=[logging_hook],\n",
        "                scaffold_fn=scaffold_fn)\n",
        "        elif mode == tf.estimator.ModeKeys.EVAL:\n",
        "            def metric_fn( label_ids, decode_tags, probabilities, input_mask):\n",
        "               \n",
        "                best_f1, precision, recall, threshold = f1_score(label_ids, probabilities)\n",
        "                evl_metrics = {}\n",
        "                evl_metrics.update({'class_intent_f1': best_f1})\n",
        "                evl_metrics.update({'class_precision': precision})\n",
        "                evl_metrics.update({'class_recall': recall})\n",
        "                evl_metrics.update({'class_threshold_': threshold})\n",
        "                for i in range(num_labels):\n",
        "                    best_f1, precision, recall, threshold = f1_score(label_ids[:, i], probabilities[:, i])\n",
        "                    evl_metrics[f'class{i:0>2d}_f1'] = best_f1\n",
        "                    evl_metrics[f'class{i:0>2d}_precision'] = precision\n",
        "                    evl_metrics[f'class{i:0>2d}_recall'] = recall\n",
        "                    evl_metrics[f'class{i:0>2d}_threshold'] = threshold\n",
        "\n",
        "\n",
        "                for metric_name, op in evl_metrics.items():\n",
        "                    tf.summary.scalar(metric_name, op[1])\n",
        "\n",
        "                return evl_metrics\n",
        "\n",
        "            eval_metrics = (metric_fn, [label_ids, decode_tags, probabilities, input_mask])\n",
        "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "                mode=mode,\n",
        "                loss=total_loss,\n",
        "                eval_metrics=eval_metrics,\n",
        "                scaffold_fn=scaffold_fn)\n",
        "        else:\n",
        "            output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "                mode=mode,\n",
        "                predictions={\n",
        "                             \"intent_predicted\": probabilities,\n",
        "                             \"label_ids\": label_ids,\n",
        "                             \"input_ids\": input_ids,\n",
        "                             \"mask_length\": tf.reduce_sum(input_mask, axis=1)},\n",
        "                scaffold_fn=scaffold_fn)\n",
        "        return output_spec\n",
        "\n",
        "    return model_fn\n",
        "\n",
        "\n",
        "# This function is not used by this file but is still used by the Colab and\n",
        "# people who depend on it.\n",
        "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
        "    \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "    all_input_ids = []\n",
        "    all_input_mask = []\n",
        "    all_segment_ids = []\n",
        "    all_label_ids = []\n",
        "\n",
        "    for feature in features:\n",
        "        all_input_ids.append(feature.input_ids)\n",
        "        all_input_mask.append(feature.input_mask)\n",
        "        all_segment_ids.append(feature.segment_ids)\n",
        "        all_label_ids.append(feature.label_ids)\n",
        "\n",
        "    def input_fn(params):\n",
        "        \"\"\"The actual input function.\"\"\"\n",
        "        batch_size = params[\"batch_size\"]\n",
        "\n",
        "        num_examples = len(features)\n",
        "\n",
        "        # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "        # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "        # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "        d = tf.data.Dataset.from_tensor_slices({\n",
        "            \"input_ids\":\n",
        "                tf.constant(\n",
        "                    all_input_ids, shape=[num_examples, seq_length],\n",
        "                    dtype=tf.int32),\n",
        "            \"input_mask\":\n",
        "                tf.constant(\n",
        "                    all_input_mask,\n",
        "                    shape=[num_examples, seq_length],\n",
        "                    dtype=tf.int32),\n",
        "            \"segment_ids\":\n",
        "                tf.constant(\n",
        "                    all_segment_ids,\n",
        "                    shape=[num_examples, seq_length],\n",
        "                    dtype=tf.int32),\n",
        "            \"label_ids\":\n",
        "                tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "        })\n",
        "\n",
        "        if is_training:\n",
        "            d = d.repeat()\n",
        "            d = d.shuffle(buffer_size=100)\n",
        "\n",
        "        d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "        return d\n",
        "\n",
        "    return input_fn\n",
        "\n",
        "\n",
        "# This function is not used by this file but is still used by the Colab and\n",
        "# people who depend on it.\n",
        "def convert_examples_to_features(examples, label_list, max_seq_length,\n",
        "                                 tokenizer):\n",
        "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
        "\n",
        "        feature = convert_single_example(ex_index, example, label_list,\n",
        "                                         max_seq_length, tokenizer)\n",
        "\n",
        "        features.append(feature)\n",
        "    return features\n",
        "\n",
        "\n",
        "def main():\n",
        "    tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "    processors = {\n",
        "        \"customized\": customizedProcessor\n",
        "    }\n",
        "\n",
        "    tokenization.validate_case_matches_checkpoint( do_lower_case,\n",
        "                                                   init_checkpoint)\n",
        "\n",
        "    if not  do_train and not  do_eval and not  do_predict and not  do_export:\n",
        "        raise ValueError(\n",
        "            \"At least one of `do_train`, `do_eval`, `do_predict' or 'do_export' must be True.\")\n",
        "\n",
        "    bert_config = modeling.BertConfig.from_json_file( bert_config_file)\n",
        "\n",
        "    if  max_seq_length > bert_config.max_position_embeddings:\n",
        "        raise ValueError(\n",
        "            \"Cannot use sequence length %d because the BERT model \"\n",
        "            \"was only trained up to sequence length %d\" %\n",
        "            ( max_seq_length, bert_config.max_position_embeddings))\n",
        "\n",
        "    tf.gfile.MakeDirs( output_dir)\n",
        "\n",
        "\n",
        "    if task_name not in processors:\n",
        "        raise ValueError(\"Task not found: %s\" % (task_name))\n",
        "\n",
        "    processor = processors[task_name]()\n",
        "\n",
        "    label_map, num_labels, intent_class_weights = processor.get_labels_info()\n",
        "\n",
        "    tokenizer = tokenization.FullTokenizer(\n",
        "        vocab_file= vocab_file, do_lower_case= do_lower_case)\n",
        "\n",
        "    tpu_cluster_resolver = None\n",
        "    if use_tpu and tpu_name:\n",
        "        tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
        "            tpu_name, zone=tpu_zone, project=gcp_project)\n",
        "\n",
        "    is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "    run_config = tf.contrib.tpu.RunConfig(\n",
        "        cluster=tpu_cluster_resolver,\n",
        "        master=master,\n",
        "        model_dir=output_dir,\n",
        "        save_checkpoints_steps=save_checkpoints_steps,\n",
        "        tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "            iterations_per_loop=iterations_per_loop,\n",
        "            num_shards=num_tpu_cores,\n",
        "            per_host_input_for_training=is_per_host))\n",
        "\n",
        "    train_examples = None\n",
        "    num_train_steps = None\n",
        "    num_warmup_steps = None\n",
        "    if do_train:\n",
        "        train_examples = processor.get_train_examples(data_dir)\n",
        "        num_train_steps = int(\n",
        "            len(train_examples) / train_batch_size * num_train_epochs)\n",
        "        num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "    model_fn = model_fn_builder(\n",
        "        bert_config=bert_config,\n",
        "        num_labels=num_labels,\n",
        "        intent_class_weights=intent_class_weights,\n",
        "        init_checkpoint=init_checkpoint,\n",
        "        learning_rate=learning_rate,\n",
        "        num_train_steps=num_train_steps,\n",
        "        num_warmup_steps=num_warmup_steps,\n",
        "        use_tpu=use_tpu,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "    \n",
        "\n",
        "\n",
        "    # If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "    # or GPU.\n",
        "    estimator = tf.contrib.tpu.TPUEstimator(\n",
        "        use_tpu=use_tpu,\n",
        "        model_fn=model_fn,\n",
        "        config=run_config,\n",
        "        train_batch_size=train_batch_size,\n",
        "        eval_batch_size=eval_batch_size,\n",
        "        predict_batch_size=predict_batch_size)\n",
        "\n",
        "    if do_train:\n",
        "        train_file = os.path.join(output_dir, \"train.tf_record\")\n",
        "        file_based_convert_examples_to_features(\n",
        "            train_examples, label_map, max_seq_length, tokenizer, train_file)\n",
        "        tf.logging.info(\"***** Running training *****\")\n",
        "        tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
        "        tf.logging.info(\"  Batch size = %d\", train_batch_size)\n",
        "        tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "        train_input_fn = file_based_input_fn_builder(\n",
        "            input_file=train_file,\n",
        "            seq_length=max_seq_length,\n",
        "            is_training=True,\n",
        "            drop_remainder=False,\n",
        "            num_labels=num_labels)\n",
        "        estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "\n",
        "    if do_eval:\n",
        "        eval_examples = processor.get_dev_examples(data_dir)\n",
        "        num_actual_eval_examples = len(eval_examples)\n",
        "\n",
        "        if use_tpu:\n",
        "            # TPU requires a fixed batch size for all batches, therefore the number\n",
        "            # of examples must be a multiple of the batch size, or else examples\n",
        "            # will get dropped. So we pad with fake examples which are ignored\n",
        "            # later on. These do NOT count towards the metric (all tf.metrics\n",
        "            # support a per-instance weight, and these get a weight of 0.0).\n",
        "            while len(eval_examples) % eval_batch_size != 0:\n",
        "                eval_examples.append(PaddingInputExample())\n",
        "\n",
        "        eval_file = os.path.join(output_dir, \"eval.tf_record\")\n",
        "        file_based_convert_examples_to_features(\n",
        "            eval_examples, label_map, max_seq_length, tokenizer, eval_file)\n",
        "\n",
        "        tf.logging.info(\"***** Running evaluation *****\")\n",
        "        tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                        len(eval_examples), num_actual_eval_examples,\n",
        "                        len(eval_examples) - num_actual_eval_examples)\n",
        "        tf.logging.info(\"  Batch size = %d\", eval_batch_size)\n",
        "\n",
        "        # This tells the estimator to run through the entire set.\n",
        "        eval_steps = None\n",
        "        # However, if running eval on the TPU, you will need to specify the\n",
        "        # number of steps.\n",
        "        if use_tpu:\n",
        "            assert len(eval_examples) % eval_batch_size == 0\n",
        "            eval_steps = int(len(eval_examples) // eval_batch_size)\n",
        "\n",
        "        eval_drop_remainder = True if use_tpu else False\n",
        "        eval_input_fn = file_based_input_fn_builder(\n",
        "            input_file=eval_file,\n",
        "            seq_length=max_seq_length,\n",
        "            is_training=False,\n",
        "            drop_remainder=eval_drop_remainder,\n",
        "            num_labels=num_labels)\n",
        "\n",
        "        result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "\n",
        "        output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n",
        "        best_threshold_file = os.path.join(output_dir, \"best_class_threshold.txt\")\n",
        "        with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "            with tf.gfile.GFile(best_threshold_file, \"w\") as threshold_writer:\n",
        "                tf.logging.info(\"***** Eval results *****\")\n",
        "                for key in result.keys():\n",
        "                    tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
        "                    writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "                    if key.endswith('threshold'):\n",
        "                        threshold_writer.write(\"%s\\n\" % str(result[key]))\n",
        "                        tf.logging.info(\"\")\n",
        "                        writer.write(\"\\n\")\n",
        "\n",
        "    if do_predict:\n",
        "        predict_examples = processor.get_test_examples(data_dir)\n",
        "        num_actual_predict_examples = len(predict_examples)\n",
        "        if use_tpu:\n",
        "            # TPU requires a fixed batch size for all batches, therefore the number\n",
        "            # of examples must be a multiple of the batch size, or else examples\n",
        "            # will get dropped. So we pad with fake examples which are ignored\n",
        "            # later on.\n",
        "            while len(predict_examples) % predict_batch_size != 0:\n",
        "                predict_examples.append(PaddingInputExample())\n",
        "\n",
        "        predict_file = os.path.join(output_dir, \"predict.tf_record\")\n",
        "        file_based_convert_examples_to_features(predict_examples, label_map,\n",
        "                                                max_seq_length, tokenizer, predict_file)\n",
        "\n",
        "        tf.logging.info(\"***** Running prediction*****\")\n",
        "        tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                        len(predict_examples), num_actual_predict_examples,\n",
        "                        len(predict_examples) - num_actual_predict_examples)\n",
        "        tf.logging.info(\"  Batch size = %d\", predict_batch_size)\n",
        "\n",
        "        predict_drop_remainder = True if use_tpu else False\n",
        "        predict_input_fn = file_based_input_fn_builder(\n",
        "            input_file=predict_file,\n",
        "            seq_length=max_seq_length,\n",
        "            is_training=False,\n",
        "            drop_remainder=predict_drop_remainder,\n",
        "            num_labels=num_labels)\n",
        "\n",
        "        result = estimator.predict(input_fn=predict_input_fn)\n",
        "        id2label = {v: k for k, v in label_map.items()}\n",
        "        output_predict_file = os.path.join(output_dir, \"test_results.tsv\")\n",
        "\n",
        "        best_threshold_file = os.path.join(output_dir, \"best_class_threshold.txt\")\n",
        "        if not tf.gfile.Exists(best_threshold_file):\n",
        "            threshold = [0.5] * num_labels\n",
        "        else:\n",
        "            with tf.gfile.GFile(best_threshold_file, \"r\") as reader:\n",
        "                threshold = reader.read().splitlines()\n",
        "            threshold = list(map(float, threshold))\n",
        "\n",
        "        with tf.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "            num_written_lines = 0\n",
        "            output_line = \"\\t\".join(\n",
        "                ['frame_O_X', 'intent OX', 'intent_label', 'intent_pred', 'sentence']) + \"\\n\"\n",
        "            writer.write(output_line)\n",
        "\n",
        "            # below for cal metrics\n",
        "            slot_pred_all_data = []\n",
        "            slot_label_all_data = []\n",
        "            intent_pred_all_data = []\n",
        "            intent_label_all_data = []\n",
        "\n",
        "            for index, item in enumerate(result):\n",
        "                mask_length = item[\"mask_length\"]\n",
        "                intent_predicted = item[\"intent_predicted\"]\n",
        "                intent_predicted = [intent_predicted[i] > threshold[i] for i in range(num_labels)]\n",
        "\n",
        "                label_ids = item[\"label_ids\"]\n",
        "                input_ids = item[\"input_ids\"][:mask_length]\n",
        "                tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "\n",
        "                intent_pred_all_data.append(intent_predicted)\n",
        "                intent_label_all_data.append(label_ids)\n",
        "\n",
        "                pre_intent = ' '.join([id2label[index] for index, pred in enumerate(intent_predicted) if pred])\n",
        "                label_intent = ' '.join([id2label[index] for index, label in enumerate(label_ids) if label])\n",
        "\n",
        "                sentence = ''.join(tokens)\n",
        "                intent_compare = 'O' if pre_intent == label_intent else 'X'\n",
        "                frame_O_X = 'O' if pre_intent == label_intent else 'X'\n",
        "                output_line = \"\\t\".join(\n",
        "                    [str(item[\"intent_predicted\"]), label_intent, pre_intent, sentence]) + \"\\n\"\n",
        "                writer.write(output_line)\n",
        "                num_written_lines += 1\n",
        "            assert num_written_lines == num_actual_predict_examples\n",
        "\n",
        "        # write test metrics\n",
        "        from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "        import numpy as np\n",
        "        output_test_metrics_file = os.path.join(output_dir, \"test_results.txt\")\n",
        "        with tf.gfile.GFile(output_test_metrics_file, \"w\") as writer:\n",
        "\n",
        "            intent_label_all_data = np.array(intent_label_all_data)\n",
        "            intent_pred_all_data = np.array(intent_pred_all_data)\n",
        "\n",
        "            for i in range(num_labels):\n",
        "                f1 = f1_score(intent_label_all_data[:, i], intent_pred_all_data[:, i])\n",
        "                precision = precision_score(intent_label_all_data[:, i], intent_pred_all_data[:, i])\n",
        "                recall = recall_score(intent_label_all_data[:, i], intent_pred_all_data[:, i])\n",
        "\n",
        "                writer.write(f'class{i:0>2d}_f1 = {f1}\\n')\n",
        "                writer.write(f'class{i:0>2d}_precision = {precision}\\n')\n",
        "                writer.write(f'class{i:0>2d}_recall = {recall}\\n')\n",
        "                writer.write('\\n\\n')\n",
        "\n",
        "            intent_label_flatten = intent_label_all_data.reshape(-1)\n",
        "            intent_pred_flatten = intent_pred_all_data.reshape(-1)\n",
        "            intent_f1 = f1_score(intent_label_flatten, intent_pred_flatten)\n",
        "            intent_precision = precision_score(intent_label_flatten, intent_pred_flatten)\n",
        "            intent_recall = recall_score(intent_label_flatten, intent_pred_flatten)\n",
        "\n",
        "            writer.write(f'class_intent_f1 = {intent_f1}\\n')\n",
        "            writer.write(f'class_intent_precision = {intent_precision}\\n')\n",
        "            writer.write(f'class_intent_recall = {intent_recall}\\n')\n",
        "            writer.write('\\n\\n')\n",
        "\n",
        "    if do_export:\n",
        "        def serving_input_fn():\n",
        "            label_ids = tf.placeholder(tf.int32, [None, num_labels], name='label_ids')\n",
        "            input_ids = tf.placeholder(tf.int32, [None, max_seq_length], name='input_ids')\n",
        "            input_mask = tf.placeholder(tf.int32, [None, max_seq_length], name='input_mask')\n",
        "            segment_ids = tf.placeholder(tf.int32, [None, max_seq_length], name='segment_ids')\n",
        "            input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
        "                'label_ids': label_ids,\n",
        "                'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'segment_ids': segment_ids\n",
        "            })()\n",
        "            return input_fn\n",
        "\n",
        "        estimator._export_to_tpu = False\n",
        "        estimator.export_saved_model(export_dir, serving_input_fn)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=['永續_污染', '社會_人民感受', '經濟_成本'], y=['經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '經濟_成本', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '永續_污染', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受', '社會_人民感受'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
            "  \"will result in an error\", FutureWarning)\n",
            "2021-02-28 16:42:26,141 : WARNING : Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f76d4fd7b90>) includes params argument, but params are not passed to Estimator.\n",
            "2021-02-28 16:42:26,142 : INFO : Using config: {'_model_dir': './output-wiki-1/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f76d4b5b9d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "2021-02-28 16:42:26,143 : INFO : _TPUContext: eval_on_tpu True\n",
            "2021-02-28 16:42:26,144 : WARNING : eval_on_tpu ignored because use_tpu is False.\n",
            "2021-02-28 16:42:26,145 : INFO : Writing example 0 of 861\n",
            "2021-02-28 16:42:26,146 : INFO : *** Example ***\n",
            "2021-02-28 16:42:26,146 : INFO : guid: train-0\n",
            "2021-02-28 16:42:26,147 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:42:26,148 : INFO : tokens: [CLS] 使 用 形 式 化 方 法 會 帶 來 很 高 的 成 本 [SEP]\n",
            "2021-02-28 16:42:26,148 : INFO : input_ids: 101 886 4500 2501 2466 1265 3175 3791 3298 2380 889 2523 7770 4638 2768 3315 102 0 0 0\n",
            "2021-02-28 16:42:26,149 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            "2021-02-28 16:42:26,153 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:42:26,157 : INFO : *** Example ***\n",
            "2021-02-28 16:42:26,158 : INFO : guid: train-1\n",
            "2021-02-28 16:42:26,159 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:42:26,166 : INFO : tokens: [CLS] 機 會 成 本 指 的 是 生 產 的 經 濟 成 本 [SEP]\n",
            "2021-02-28 16:42:26,171 : INFO : input_ids: 101 3582 3298 2768 3315 2900 4638 3221 4495 4496 4638 5195 4089 2768 3315 102 0 0 0 0\n",
            "2021-02-28 16:42:26,174 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "2021-02-28 16:42:26,176 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:42:26,178 : INFO : *** Example ***\n",
            "2021-02-28 16:42:26,180 : INFO : guid: train-2\n",
            "2021-02-28 16:42:26,181 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:42:26,183 : INFO : tokens: [CLS] 更 包 含 瞭 計 算 實 際 成 本 的 因 素 [SEP]\n",
            "2021-02-28 16:42:26,185 : INFO : input_ids: 101 3291 1259 1419 4747 6243 5050 2179 7396 2768 3315 4638 1728 5162 102 0 0 0 0 0\n",
            "2021-02-28 16:42:26,187 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "2021-02-28 16:42:26,191 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:42:26,193 : INFO : *** Example ***\n",
            "2021-02-28 16:42:26,195 : INFO : guid: train-3\n",
            "2021-02-28 16:42:26,195 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:42:26,196 : INFO : tokens: [CLS] 而 不 是 其 他 較 為 昂 貴 的 替 代 品 [SEP]\n",
            "2021-02-28 16:42:26,197 : INFO : input_ids: 101 5445 679 3221 1071 800 6733 4158 3203 6523 4638 3296 807 1501 102 0 0 0 0 0\n",
            "2021-02-28 16:42:26,198 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "2021-02-28 16:42:26,200 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:42:26,201 : INFO : *** Example ***\n",
            "2021-02-28 16:42:26,203 : INFO : guid: train-4\n",
            "2021-02-28 16:42:26,204 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:42:26,205 : INFO : tokens: [CLS] 供 給 [UNK] 線 上 的 點 則 代 錶 瞭 邊 際 成 本 [SEP]\n",
            "2021-02-28 16:42:26,205 : INFO : input_ids: 101 897 5183 100 5221 677 4638 7953 1179 807 7100 4747 6920 7396 2768 3315 102 0 0 0\n",
            "2021-02-28 16:42:26,206 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            "2021-02-28 16:42:26,208 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:42:26,436 : INFO : ***** Running training *****\n",
            "2021-02-28 16:42:26,436 : INFO :   Num examples = 861\n",
            "2021-02-28 16:42:26,438 : INFO :   Batch size = 32\n",
            "2021-02-28 16:42:26,439 : INFO :   Num steps = 941\n",
            "2021-02-28 16:42:26,483 : INFO : Calling model_fn.\n",
            "2021-02-28 16:42:26,483 : INFO : Running train on CPU\n",
            "2021-02-28 16:42:26,484 : INFO : *** Features ***\n",
            "2021-02-28 16:42:26,485 : INFO :   name = input_ids, shape = (?, 20)\n",
            "2021-02-28 16:42:26,488 : INFO :   name = input_mask, shape = (?, 20)\n",
            "2021-02-28 16:42:26,489 : INFO :   name = is_real_example, shape = (?,)\n",
            "2021-02-28 16:42:26,495 : INFO :   name = label_ids, shape = (?, 3)\n",
            "2021-02-28 16:42:26,496 : INFO :   name = segment_ids, shape = (?, 20)\n",
            "2021-02-28 16:42:28,818 : INFO : **** Trainable Variables ****\n",
            "2021-02-28 16:42:28,818 : INFO :   name = bert/embeddings/word_embeddings:0, shape = (21128, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,823 : INFO :   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,826 : INFO :   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,827 : INFO :   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,829 : INFO :   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,830 : INFO :   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,835 : INFO :   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,835 : INFO :   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,836 : INFO :   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,837 : INFO :   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,838 : INFO :   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,840 : INFO :   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,841 : INFO :   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,856 : INFO :   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,858 : INFO :   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,861 : INFO :   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,863 : INFO :   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,863 : INFO :   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,864 : INFO :   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,865 : INFO :   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,865 : INFO :   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,866 : INFO :   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,874 : INFO :   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,874 : INFO :   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,875 : INFO :   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,876 : INFO :   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,877 : INFO :   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,877 : INFO :   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,878 : INFO :   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,879 : INFO :   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,882 : INFO :   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,883 : INFO :   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,883 : INFO :   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,885 : INFO :   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,886 : INFO :   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,888 : INFO :   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,894 : INFO :   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,895 : INFO :   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,895 : INFO :   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,899 : INFO :   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,900 : INFO :   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,901 : INFO :   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,902 : INFO :   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,903 : INFO :   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,904 : INFO :   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,905 : INFO :   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,905 : INFO :   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,907 : INFO :   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,908 : INFO :   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,908 : INFO :   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,909 : INFO :   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,911 : INFO :   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,911 : INFO :   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,912 : INFO :   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,913 : INFO :   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,914 : INFO :   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,915 : INFO :   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,916 : INFO :   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,920 : INFO :   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,924 : INFO :   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,925 : INFO :   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,926 : INFO :   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,928 : INFO :   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,928 : INFO :   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,929 : INFO :   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,930 : INFO :   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,931 : INFO :   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,932 : INFO :   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,933 : INFO :   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,934 : INFO :   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,934 : INFO :   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,935 : INFO :   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,936 : INFO :   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,939 : INFO :   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,940 : INFO :   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,942 : INFO :   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,944 : INFO :   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,945 : INFO :   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,953 : INFO :   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,954 : INFO :   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,956 : INFO :   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,958 : INFO :   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,959 : INFO :   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,960 : INFO :   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,961 : INFO :   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,961 : INFO :   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,962 : INFO :   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,963 : INFO :   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,964 : INFO :   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,965 : INFO :   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,966 : INFO :   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,968 : INFO :   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,970 : INFO :   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,973 : INFO :   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,975 : INFO :   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,976 : INFO :   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,977 : INFO :   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,978 : INFO :   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,979 : INFO :   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,979 : INFO :   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,980 : INFO :   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,981 : INFO :   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,982 : INFO :   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,982 : INFO :   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,983 : INFO :   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,984 : INFO :   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,985 : INFO :   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,985 : INFO :   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,992 : INFO :   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,992 : INFO :   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,994 : INFO :   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,995 : INFO :   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,997 : INFO :   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:28,997 : INFO :   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,000 : INFO :   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,000 : INFO :   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,001 : INFO :   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,002 : INFO :   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,003 : INFO :   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,004 : INFO :   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,006 : INFO :   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,007 : INFO :   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,007 : INFO :   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,008 : INFO :   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,009 : INFO :   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,010 : INFO :   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,011 : INFO :   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,011 : INFO :   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,012 : INFO :   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,014 : INFO :   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,014 : INFO :   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,021 : INFO :   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,024 : INFO :   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,028 : INFO :   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,028 : INFO :   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,029 : INFO :   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,030 : INFO :   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,030 : INFO :   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,031 : INFO :   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,032 : INFO :   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,033 : INFO :   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,033 : INFO :   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,034 : INFO :   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,038 : INFO :   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,039 : INFO :   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,041 : INFO :   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,042 : INFO :   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,043 : INFO :   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,043 : INFO :   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,046 : INFO :   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,049 : INFO :   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,051 : INFO :   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,053 : INFO :   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,054 : INFO :   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,057 : INFO :   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,059 : INFO :   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,061 : INFO :   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,063 : INFO :   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,066 : INFO :   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,067 : INFO :   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,068 : INFO :   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,069 : INFO :   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,069 : INFO :   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,070 : INFO :   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,077 : INFO :   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,079 : INFO :   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,081 : INFO :   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,085 : INFO :   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,086 : INFO :   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,089 : INFO :   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,090 : INFO :   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,092 : INFO :   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,093 : INFO :   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,094 : INFO :   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,096 : INFO :   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,098 : INFO :   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,101 : INFO :   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,102 : INFO :   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,103 : INFO :   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,103 : INFO :   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,107 : INFO :   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,108 : INFO :   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,109 : INFO :   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,117 : INFO :   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,118 : INFO :   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,118 : INFO :   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,119 : INFO :   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,121 : INFO :   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,122 : INFO :   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,122 : INFO :   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,125 : INFO :   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,126 : INFO :   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,126 : INFO :   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,127 : INFO :   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,128 : INFO :   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,130 : INFO :   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,130 : INFO :   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,131 : INFO :   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,131 : INFO :   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:42:29,133 : INFO :   name = intent_output_weights:0, shape = (3, 768)\n",
            "2021-02-28 16:42:29,134 : INFO :   name = intent_output_bias:0, shape = (3,)\n",
            "2021-02-28 16:42:36,081 : INFO : Done calling model_fn.\n",
            "2021-02-28 16:42:36,083 : INFO : Create CheckpointSaverHook.\n",
            "2021-02-28 16:42:38,520 : INFO : Graph was finalized.\n",
            "2021-02-28 16:42:52,806 : INFO : Running local_init_op.\n",
            "2021-02-28 16:42:53,033 : INFO : Done running local_init_op.\n",
            "2021-02-28 16:42:59,336 : INFO : Saving checkpoints for 0 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:43:08,347 : INFO : loss = 2.2712917\n",
            "2021-02-28 16:43:14,020 : INFO : global_step/sec: 0.176408\n",
            "2021-02-28 16:43:14,021 : INFO : examples/sec: 5.64505\n",
            "2021-02-28 16:43:14,153 : INFO : global_step/sec: 7.54878\n",
            "2021-02-28 16:43:14,154 : INFO : examples/sec: 241.561\n",
            "2021-02-28 16:43:14,286 : INFO : global_step/sec: 7.51735\n",
            "2021-02-28 16:43:14,289 : INFO : examples/sec: 240.555\n",
            "2021-02-28 16:43:14,419 : INFO : global_step/sec: 7.51245\n",
            "2021-02-28 16:43:14,420 : INFO : examples/sec: 240.398\n",
            "2021-02-28 16:43:14,551 : INFO : global_step/sec: 7.54015\n",
            "2021-02-28 16:43:14,552 : INFO : examples/sec: 241.285\n",
            "2021-02-28 16:43:14,683 : INFO : global_step/sec: 7.60272\n",
            "2021-02-28 16:43:14,684 : INFO : examples/sec: 243.287\n",
            "2021-02-28 16:43:14,819 : INFO : global_step/sec: 7.34588\n",
            "2021-02-28 16:43:14,820 : INFO : examples/sec: 235.068\n",
            "2021-02-28 16:43:14,950 : INFO : global_step/sec: 7.63806\n",
            "2021-02-28 16:43:14,951 : INFO : examples/sec: 244.418\n",
            "2021-02-28 16:43:15,083 : INFO : global_step/sec: 7.51688\n",
            "2021-02-28 16:43:15,084 : INFO : examples/sec: 240.54\n",
            "2021-02-28 16:43:15,211 : INFO : loss = 0.528286 (6.864 sec)\n",
            "2021-02-28 16:43:15,214 : INFO : global_step/sec: 7.61145\n",
            "2021-02-28 16:43:15,217 : INFO : examples/sec: 243.566\n",
            "2021-02-28 16:43:15,345 : INFO : global_step/sec: 7.65598\n",
            "2021-02-28 16:43:15,346 : INFO : examples/sec: 244.991\n",
            "2021-02-28 16:43:15,477 : INFO : global_step/sec: 7.57024\n",
            "2021-02-28 16:43:15,478 : INFO : examples/sec: 242.248\n",
            "2021-02-28 16:43:15,608 : INFO : global_step/sec: 7.63321\n",
            "2021-02-28 16:43:15,609 : INFO : examples/sec: 244.263\n",
            "2021-02-28 16:43:15,739 : INFO : global_step/sec: 7.61319\n",
            "2021-02-28 16:43:15,740 : INFO : examples/sec: 243.622\n",
            "2021-02-28 16:43:15,873 : INFO : global_step/sec: 7.47996\n",
            "2021-02-28 16:43:15,876 : INFO : examples/sec: 239.359\n",
            "2021-02-28 16:43:16,005 : INFO : global_step/sec: 7.58155\n",
            "2021-02-28 16:43:16,006 : INFO : examples/sec: 242.61\n",
            "2021-02-28 16:43:16,137 : INFO : global_step/sec: 7.55307\n",
            "2021-02-28 16:43:16,138 : INFO : examples/sec: 241.698\n",
            "2021-02-28 16:43:16,268 : INFO : global_step/sec: 7.65381\n",
            "2021-02-28 16:43:16,269 : INFO : examples/sec: 244.922\n",
            "2021-02-28 16:43:16,399 : INFO : global_step/sec: 7.64579\n",
            "2021-02-28 16:43:16,400 : INFO : examples/sec: 244.665\n",
            "2021-02-28 16:43:16,529 : INFO : loss = 12.027132 (1.318 sec)\n",
            "2021-02-28 16:43:16,532 : INFO : global_step/sec: 7.49589\n",
            "2021-02-28 16:43:16,533 : INFO : examples/sec: 239.869\n",
            "2021-02-28 16:43:16,666 : INFO : global_step/sec: 7.46283\n",
            "2021-02-28 16:43:16,667 : INFO : examples/sec: 238.811\n",
            "2021-02-28 16:43:16,798 : INFO : global_step/sec: 7.56883\n",
            "2021-02-28 16:43:16,799 : INFO : examples/sec: 242.203\n",
            "2021-02-28 16:43:16,929 : INFO : global_step/sec: 7.66108\n",
            "2021-02-28 16:43:16,930 : INFO : examples/sec: 245.155\n",
            "2021-02-28 16:43:17,062 : INFO : global_step/sec: 7.51023\n",
            "2021-02-28 16:43:17,063 : INFO : examples/sec: 240.327\n",
            "2021-02-28 16:43:17,192 : INFO : global_step/sec: 7.70253\n",
            "2021-02-28 16:43:17,193 : INFO : examples/sec: 246.481\n",
            "2021-02-28 16:43:17,321 : INFO : global_step/sec: 7.72703\n",
            "2021-02-28 16:43:17,322 : INFO : examples/sec: 247.265\n",
            "2021-02-28 16:43:17,454 : INFO : global_step/sec: 7.55038\n",
            "2021-02-28 16:43:17,456 : INFO : examples/sec: 241.612\n",
            "2021-02-28 16:43:17,584 : INFO : global_step/sec: 7.68638\n",
            "2021-02-28 16:43:17,585 : INFO : examples/sec: 245.964\n",
            "2021-02-28 16:43:17,715 : INFO : global_step/sec: 7.64788\n",
            "2021-02-28 16:43:17,717 : INFO : examples/sec: 244.732\n",
            "2021-02-28 16:43:17,845 : INFO : loss = 1.4086683 (1.316 sec)\n",
            "2021-02-28 16:43:17,846 : INFO : global_step/sec: 7.59029\n",
            "2021-02-28 16:43:17,848 : INFO : examples/sec: 242.889\n",
            "2021-02-28 16:43:17,976 : INFO : global_step/sec: 7.68599\n",
            "2021-02-28 16:43:17,977 : INFO : examples/sec: 245.952\n",
            "2021-02-28 16:43:18,107 : INFO : global_step/sec: 7.63463\n",
            "2021-02-28 16:43:18,110 : INFO : examples/sec: 244.308\n",
            "2021-02-28 16:43:18,238 : INFO : global_step/sec: 7.64757\n",
            "2021-02-28 16:43:18,239 : INFO : examples/sec: 244.722\n",
            "2021-02-28 16:43:18,367 : INFO : global_step/sec: 7.75689\n",
            "2021-02-28 16:43:18,368 : INFO : examples/sec: 248.22\n",
            "2021-02-28 16:43:18,498 : INFO : global_step/sec: 7.65922\n",
            "2021-02-28 16:43:18,499 : INFO : examples/sec: 245.095\n",
            "2021-02-28 16:43:18,629 : INFO : global_step/sec: 7.60481\n",
            "2021-02-28 16:43:18,630 : INFO : examples/sec: 243.354\n",
            "2021-02-28 16:43:18,763 : INFO : global_step/sec: 7.47902\n",
            "2021-02-28 16:43:18,764 : INFO : examples/sec: 239.329\n",
            "2021-02-28 16:43:18,893 : INFO : global_step/sec: 7.67064\n",
            "2021-02-28 16:43:18,895 : INFO : examples/sec: 245.46\n",
            "2021-02-28 16:43:19,026 : INFO : global_step/sec: 7.55031\n",
            "2021-02-28 16:43:19,027 : INFO : examples/sec: 241.61\n",
            "2021-02-28 16:43:19,155 : INFO : loss = 0.038489398 (1.310 sec)\n",
            "2021-02-28 16:43:19,156 : INFO : global_step/sec: 7.64915\n",
            "2021-02-28 16:43:19,158 : INFO : examples/sec: 244.773\n",
            "2021-02-28 16:43:19,289 : INFO : global_step/sec: 7.52493\n",
            "2021-02-28 16:43:19,290 : INFO : examples/sec: 240.798\n",
            "2021-02-28 16:43:19,420 : INFO : global_step/sec: 7.65535\n",
            "2021-02-28 16:43:19,421 : INFO : examples/sec: 244.971\n",
            "2021-02-28 16:43:19,551 : INFO : global_step/sec: 7.65666\n",
            "2021-02-28 16:43:19,551 : INFO : examples/sec: 245.013\n",
            "2021-02-28 16:43:19,680 : INFO : global_step/sec: 7.69795\n",
            "2021-02-28 16:43:19,681 : INFO : examples/sec: 246.334\n",
            "2021-02-28 16:43:19,810 : INFO : global_step/sec: 7.71105\n",
            "2021-02-28 16:43:19,811 : INFO : examples/sec: 246.754\n",
            "2021-02-28 16:43:19,942 : INFO : global_step/sec: 7.59743\n",
            "2021-02-28 16:43:19,943 : INFO : examples/sec: 243.118\n",
            "2021-02-28 16:43:20,073 : INFO : global_step/sec: 7.62204\n",
            "2021-02-28 16:43:20,074 : INFO : examples/sec: 243.905\n",
            "2021-02-28 16:43:20,204 : INFO : global_step/sec: 7.61785\n",
            "2021-02-28 16:43:20,205 : INFO : examples/sec: 243.771\n",
            "2021-02-28 16:43:20,336 : INFO : global_step/sec: 7.59682\n",
            "2021-02-28 16:43:20,337 : INFO : examples/sec: 243.098\n",
            "2021-02-28 16:43:20,465 : INFO : loss = 2.5044143 (1.310 sec)\n",
            "2021-02-28 16:43:20,467 : INFO : global_step/sec: 7.63438\n",
            "2021-02-28 16:43:20,469 : INFO : examples/sec: 244.3\n",
            "2021-02-28 16:43:20,600 : INFO : global_step/sec: 7.51409\n",
            "2021-02-28 16:43:20,601 : INFO : examples/sec: 240.451\n",
            "2021-02-28 16:43:20,733 : INFO : global_step/sec: 7.50277\n",
            "2021-02-28 16:43:20,734 : INFO : examples/sec: 240.089\n",
            "2021-02-28 16:43:20,864 : INFO : global_step/sec: 7.65399\n",
            "2021-02-28 16:43:20,865 : INFO : examples/sec: 244.928\n",
            "2021-02-28 16:43:20,991 : INFO : global_step/sec: 7.84525\n",
            "2021-02-28 16:43:20,992 : INFO : examples/sec: 251.048\n",
            "2021-02-28 16:43:21,118 : INFO : global_step/sec: 7.87067\n",
            "2021-02-28 16:43:21,119 : INFO : examples/sec: 251.861\n",
            "2021-02-28 16:43:21,250 : INFO : global_step/sec: 7.59839\n",
            "2021-02-28 16:43:21,251 : INFO : examples/sec: 243.148\n",
            "2021-02-28 16:43:21,384 : INFO : global_step/sec: 7.4443\n",
            "2021-02-28 16:43:21,385 : INFO : examples/sec: 238.218\n",
            "2021-02-28 16:43:21,516 : INFO : global_step/sec: 7.58759\n",
            "2021-02-28 16:43:21,517 : INFO : examples/sec: 242.803\n",
            "2021-02-28 16:43:21,643 : INFO : global_step/sec: 7.88815\n",
            "2021-02-28 16:43:21,644 : INFO : examples/sec: 252.421\n",
            "2021-02-28 16:43:21,774 : INFO : loss = 0.010181127 (1.309 sec)\n",
            "2021-02-28 16:43:21,776 : INFO : global_step/sec: 7.52905\n",
            "2021-02-28 16:43:21,782 : INFO : examples/sec: 240.929\n",
            "2021-02-28 16:43:21,914 : INFO : global_step/sec: 7.22872\n",
            "2021-02-28 16:43:21,915 : INFO : examples/sec: 231.319\n",
            "2021-02-28 16:43:22,045 : INFO : global_step/sec: 7.62293\n",
            "2021-02-28 16:43:22,046 : INFO : examples/sec: 243.934\n",
            "2021-02-28 16:43:22,177 : INFO : global_step/sec: 7.57282\n",
            "2021-02-28 16:43:22,178 : INFO : examples/sec: 242.33\n",
            "2021-02-28 16:43:22,306 : INFO : global_step/sec: 7.74704\n",
            "2021-02-28 16:43:22,307 : INFO : examples/sec: 247.905\n",
            "2021-02-28 16:43:22,435 : INFO : global_step/sec: 7.77172\n",
            "2021-02-28 16:43:22,436 : INFO : examples/sec: 248.695\n",
            "2021-02-28 16:43:22,564 : INFO : global_step/sec: 7.73393\n",
            "2021-02-28 16:43:22,565 : INFO : examples/sec: 247.486\n",
            "2021-02-28 16:43:22,697 : INFO : global_step/sec: 7.52377\n",
            "2021-02-28 16:43:22,700 : INFO : examples/sec: 240.761\n",
            "2021-02-28 16:43:22,832 : INFO : global_step/sec: 7.43551\n",
            "2021-02-28 16:43:22,833 : INFO : examples/sec: 237.936\n",
            "2021-02-28 16:43:22,966 : INFO : global_step/sec: 7.44783\n",
            "2021-02-28 16:43:22,967 : INFO : examples/sec: 238.331\n",
            "2021-02-28 16:43:23,097 : INFO : loss = 0.0010073488 (1.323 sec)\n",
            "2021-02-28 16:43:23,101 : INFO : global_step/sec: 7.42298\n",
            "2021-02-28 16:43:23,103 : INFO : examples/sec: 237.535\n",
            "2021-02-28 16:43:23,232 : INFO : global_step/sec: 7.60884\n",
            "2021-02-28 16:43:23,233 : INFO : examples/sec: 243.483\n",
            "2021-02-28 16:43:23,369 : INFO : global_step/sec: 7.31395\n",
            "2021-02-28 16:43:23,370 : INFO : examples/sec: 234.047\n",
            "2021-02-28 16:43:23,501 : INFO : global_step/sec: 7.57278\n",
            "2021-02-28 16:43:23,502 : INFO : examples/sec: 242.329\n",
            "2021-02-28 16:43:23,633 : INFO : global_step/sec: 7.59586\n",
            "2021-02-28 16:43:23,633 : INFO : examples/sec: 243.067\n",
            "2021-02-28 16:43:23,760 : INFO : global_step/sec: 7.82425\n",
            "2021-02-28 16:43:23,761 : INFO : examples/sec: 250.376\n",
            "2021-02-28 16:43:23,893 : INFO : global_step/sec: 7.51787\n",
            "2021-02-28 16:43:23,894 : INFO : examples/sec: 240.572\n",
            "2021-02-28 16:43:24,028 : INFO : global_step/sec: 7.42693\n",
            "2021-02-28 16:43:24,029 : INFO : examples/sec: 237.662\n",
            "2021-02-28 16:43:24,157 : INFO : global_step/sec: 7.7617\n",
            "2021-02-28 16:43:24,158 : INFO : examples/sec: 248.374\n",
            "2021-02-28 16:43:24,289 : INFO : global_step/sec: 7.57648\n",
            "2021-02-28 16:43:24,290 : INFO : examples/sec: 242.448\n",
            "2021-02-28 16:43:24,418 : INFO : loss = 0.013991123 (1.320 sec)\n",
            "2021-02-28 16:43:24,421 : INFO : global_step/sec: 7.56879\n",
            "2021-02-28 16:43:24,423 : INFO : examples/sec: 242.201\n",
            "2021-02-28 16:43:24,549 : INFO : global_step/sec: 7.80082\n",
            "2021-02-28 16:43:24,550 : INFO : examples/sec: 249.626\n",
            "2021-02-28 16:43:24,680 : INFO : global_step/sec: 7.66481\n",
            "2021-02-28 16:43:24,680 : INFO : examples/sec: 245.274\n",
            "2021-02-28 16:43:24,812 : INFO : global_step/sec: 7.54114\n",
            "2021-02-28 16:43:24,813 : INFO : examples/sec: 241.316\n",
            "2021-02-28 16:43:24,946 : INFO : global_step/sec: 7.47982\n",
            "2021-02-28 16:43:24,947 : INFO : examples/sec: 239.354\n",
            "2021-02-28 16:43:25,077 : INFO : global_step/sec: 7.63446\n",
            "2021-02-28 16:43:25,078 : INFO : examples/sec: 244.303\n",
            "2021-02-28 16:43:25,206 : INFO : global_step/sec: 7.73549\n",
            "2021-02-28 16:43:25,207 : INFO : examples/sec: 247.536\n",
            "2021-02-28 16:43:25,339 : INFO : global_step/sec: 7.52718\n",
            "2021-02-28 16:43:25,340 : INFO : examples/sec: 240.87\n",
            "2021-02-28 16:43:25,471 : INFO : global_step/sec: 7.58509\n",
            "2021-02-28 16:43:25,472 : INFO : examples/sec: 242.723\n",
            "2021-02-28 16:43:25,601 : INFO : global_step/sec: 7.67843\n",
            "2021-02-28 16:43:25,602 : INFO : examples/sec: 245.71\n",
            "2021-02-28 16:43:25,733 : INFO : loss = 0.0010934632 (1.315 sec)\n",
            "2021-02-28 16:43:25,737 : INFO : global_step/sec: 7.34071\n",
            "2021-02-28 16:43:25,738 : INFO : examples/sec: 234.903\n",
            "2021-02-28 16:43:25,869 : INFO : global_step/sec: 7.59733\n",
            "2021-02-28 16:43:25,870 : INFO : examples/sec: 243.115\n",
            "2021-02-28 16:43:26,001 : INFO : global_step/sec: 7.5513\n",
            "2021-02-28 16:43:26,002 : INFO : examples/sec: 241.642\n",
            "2021-02-28 16:43:26,133 : INFO : global_step/sec: 7.60306\n",
            "2021-02-28 16:43:26,134 : INFO : examples/sec: 243.298\n",
            "2021-02-28 16:43:26,261 : INFO : global_step/sec: 7.79461\n",
            "2021-02-28 16:43:26,262 : INFO : examples/sec: 249.428\n",
            "2021-02-28 16:43:26,392 : INFO : global_step/sec: 7.64325\n",
            "2021-02-28 16:43:26,393 : INFO : examples/sec: 244.584\n",
            "2021-02-28 16:43:26,525 : INFO : global_step/sec: 7.51741\n",
            "2021-02-28 16:43:26,526 : INFO : examples/sec: 240.557\n",
            "2021-02-28 16:43:26,657 : INFO : global_step/sec: 7.59007\n",
            "2021-02-28 16:43:26,658 : INFO : examples/sec: 242.882\n",
            "2021-02-28 16:43:26,787 : INFO : global_step/sec: 7.66395\n",
            "2021-02-28 16:43:26,788 : INFO : examples/sec: 245.246\n",
            "2021-02-28 16:43:26,919 : INFO : Saving checkpoints for 100 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:43:31,964 : INFO : global_step/sec: 0.193182\n",
            "2021-02-28 16:43:31,965 : INFO : examples/sec: 6.18183\n",
            "2021-02-28 16:43:32,096 : INFO : loss = 0.006007416 (6.363 sec)\n",
            "2021-02-28 16:43:32,099 : INFO : global_step/sec: 7.3901\n",
            "2021-02-28 16:43:32,100 : INFO : examples/sec: 236.483\n",
            "2021-02-28 16:43:32,231 : INFO : global_step/sec: 7.59821\n",
            "2021-02-28 16:43:32,232 : INFO : examples/sec: 243.143\n",
            "2021-02-28 16:43:32,362 : INFO : global_step/sec: 7.61023\n",
            "2021-02-28 16:43:32,363 : INFO : examples/sec: 243.527\n",
            "2021-02-28 16:43:32,493 : INFO : global_step/sec: 7.63296\n",
            "2021-02-28 16:43:32,494 : INFO : examples/sec: 244.255\n",
            "2021-02-28 16:43:32,629 : INFO : global_step/sec: 7.34607\n",
            "2021-02-28 16:43:32,630 : INFO : examples/sec: 235.074\n",
            "2021-02-28 16:43:32,761 : INFO : global_step/sec: 7.57973\n",
            "2021-02-28 16:43:32,762 : INFO : examples/sec: 242.551\n",
            "2021-02-28 16:43:32,891 : INFO : global_step/sec: 7.71468\n",
            "2021-02-28 16:43:32,892 : INFO : examples/sec: 246.87\n",
            "2021-02-28 16:43:33,025 : INFO : global_step/sec: 7.44852\n",
            "2021-02-28 16:43:33,026 : INFO : examples/sec: 238.353\n",
            "2021-02-28 16:43:33,158 : INFO : global_step/sec: 7.5172\n",
            "2021-02-28 16:43:33,159 : INFO : examples/sec: 240.55\n",
            "2021-02-28 16:43:33,290 : INFO : global_step/sec: 7.58442\n",
            "2021-02-28 16:43:33,291 : INFO : examples/sec: 242.701\n",
            "2021-02-28 16:43:33,419 : INFO : loss = 0.010521837 (1.323 sec)\n",
            "2021-02-28 16:43:33,422 : INFO : global_step/sec: 7.57591\n",
            "2021-02-28 16:43:33,423 : INFO : examples/sec: 242.429\n",
            "2021-02-28 16:43:33,553 : INFO : global_step/sec: 7.62653\n",
            "2021-02-28 16:43:33,554 : INFO : examples/sec: 244.049\n",
            "2021-02-28 16:43:33,683 : INFO : global_step/sec: 7.69758\n",
            "2021-02-28 16:43:33,684 : INFO : examples/sec: 246.323\n",
            "2021-02-28 16:43:33,815 : INFO : global_step/sec: 7.57902\n",
            "2021-02-28 16:43:33,816 : INFO : examples/sec: 242.529\n",
            "2021-02-28 16:43:33,947 : INFO : global_step/sec: 7.58624\n",
            "2021-02-28 16:43:33,948 : INFO : examples/sec: 242.76\n",
            "2021-02-28 16:43:34,079 : INFO : global_step/sec: 7.53497\n",
            "2021-02-28 16:43:34,081 : INFO : examples/sec: 241.119\n",
            "2021-02-28 16:43:34,211 : INFO : global_step/sec: 7.6202\n",
            "2021-02-28 16:43:34,212 : INFO : examples/sec: 243.846\n",
            "2021-02-28 16:43:34,344 : INFO : global_step/sec: 7.51553\n",
            "2021-02-28 16:43:34,345 : INFO : examples/sec: 240.497\n",
            "2021-02-28 16:43:34,474 : INFO : global_step/sec: 7.64752\n",
            "2021-02-28 16:43:34,475 : INFO : examples/sec: 244.721\n",
            "2021-02-28 16:43:34,605 : INFO : global_step/sec: 7.66156\n",
            "2021-02-28 16:43:34,606 : INFO : examples/sec: 245.17\n",
            "2021-02-28 16:43:34,735 : INFO : loss = 0.33760566 (1.316 sec)\n",
            "2021-02-28 16:43:34,738 : INFO : global_step/sec: 7.49778\n",
            "2021-02-28 16:43:34,740 : INFO : examples/sec: 239.929\n",
            "2021-02-28 16:43:34,872 : INFO : global_step/sec: 7.49637\n",
            "2021-02-28 16:43:34,874 : INFO : examples/sec: 239.884\n",
            "2021-02-28 16:43:35,004 : INFO : global_step/sec: 7.57794\n",
            "2021-02-28 16:43:35,005 : INFO : examples/sec: 242.494\n",
            "2021-02-28 16:43:35,137 : INFO : global_step/sec: 7.51249\n",
            "2021-02-28 16:43:35,138 : INFO : examples/sec: 240.4\n",
            "2021-02-28 16:43:35,269 : INFO : global_step/sec: 7.58449\n",
            "2021-02-28 16:43:35,269 : INFO : examples/sec: 242.704\n",
            "2021-02-28 16:43:35,402 : INFO : global_step/sec: 7.5151\n",
            "2021-02-28 16:43:35,403 : INFO : examples/sec: 240.483\n",
            "2021-02-28 16:43:35,532 : INFO : global_step/sec: 7.6757\n",
            "2021-02-28 16:43:35,533 : INFO : examples/sec: 245.623\n",
            "2021-02-28 16:43:35,662 : INFO : global_step/sec: 7.669\n",
            "2021-02-28 16:43:35,663 : INFO : examples/sec: 245.408\n",
            "2021-02-28 16:43:35,790 : INFO : global_step/sec: 7.81904\n",
            "2021-02-28 16:43:35,791 : INFO : examples/sec: 250.209\n",
            "2021-02-28 16:43:35,921 : INFO : global_step/sec: 7.62799\n",
            "2021-02-28 16:43:35,922 : INFO : examples/sec: 244.096\n",
            "2021-02-28 16:43:36,050 : INFO : loss = 3.3723435 (1.315 sec)\n",
            "2021-02-28 16:43:36,051 : INFO : global_step/sec: 7.69232\n",
            "2021-02-28 16:43:36,053 : INFO : examples/sec: 246.154\n",
            "2021-02-28 16:43:36,184 : INFO : global_step/sec: 7.53051\n",
            "2021-02-28 16:43:36,185 : INFO : examples/sec: 240.976\n",
            "2021-02-28 16:43:36,313 : INFO : global_step/sec: 7.77129\n",
            "2021-02-28 16:43:36,314 : INFO : examples/sec: 248.681\n",
            "2021-02-28 16:43:36,444 : INFO : global_step/sec: 7.61696\n",
            "2021-02-28 16:43:36,445 : INFO : examples/sec: 243.743\n",
            "2021-02-28 16:43:36,573 : INFO : global_step/sec: 7.76411\n",
            "2021-02-28 16:43:36,574 : INFO : examples/sec: 248.452\n",
            "2021-02-28 16:43:36,700 : INFO : global_step/sec: 7.84453\n",
            "2021-02-28 16:43:36,701 : INFO : examples/sec: 251.025\n",
            "2021-02-28 16:43:36,832 : INFO : global_step/sec: 7.59268\n",
            "2021-02-28 16:43:36,833 : INFO : examples/sec: 242.966\n",
            "2021-02-28 16:43:36,963 : INFO : global_step/sec: 7.62044\n",
            "2021-02-28 16:43:36,966 : INFO : examples/sec: 243.854\n",
            "2021-02-28 16:43:37,094 : INFO : global_step/sec: 7.63467\n",
            "2021-02-28 16:43:37,095 : INFO : examples/sec: 244.309\n",
            "2021-02-28 16:43:37,225 : INFO : global_step/sec: 7.66974\n",
            "2021-02-28 16:43:37,225 : INFO : examples/sec: 245.432\n",
            "2021-02-28 16:43:37,354 : INFO : loss = 0.07242421 (1.304 sec)\n",
            "2021-02-28 16:43:37,358 : INFO : global_step/sec: 7.52995\n",
            "2021-02-28 16:43:37,358 : INFO : examples/sec: 240.958\n",
            "2021-02-28 16:43:37,493 : INFO : global_step/sec: 7.40755\n",
            "2021-02-28 16:43:37,493 : INFO : examples/sec: 237.042\n",
            "2021-02-28 16:43:37,621 : INFO : global_step/sec: 7.76923\n",
            "2021-02-28 16:43:37,622 : INFO : examples/sec: 248.615\n",
            "2021-02-28 16:43:37,755 : INFO : global_step/sec: 7.47617\n",
            "2021-02-28 16:43:37,756 : INFO : examples/sec: 239.237\n",
            "2021-02-28 16:43:37,887 : INFO : global_step/sec: 7.59723\n",
            "2021-02-28 16:43:37,888 : INFO : examples/sec: 243.112\n",
            "2021-02-28 16:43:38,019 : INFO : global_step/sec: 7.5758\n",
            "2021-02-28 16:43:38,020 : INFO : examples/sec: 242.426\n",
            "2021-02-28 16:43:38,149 : INFO : global_step/sec: 7.67645\n",
            "2021-02-28 16:43:38,150 : INFO : examples/sec: 245.646\n",
            "2021-02-28 16:43:38,284 : INFO : global_step/sec: 7.43098\n",
            "2021-02-28 16:43:38,284 : INFO : examples/sec: 237.791\n",
            "2021-02-28 16:43:38,415 : INFO : global_step/sec: 7.57995\n",
            "2021-02-28 16:43:38,418 : INFO : examples/sec: 242.558\n",
            "2021-02-28 16:43:38,547 : INFO : global_step/sec: 7.61377\n",
            "2021-02-28 16:43:38,548 : INFO : examples/sec: 243.641\n",
            "2021-02-28 16:43:38,677 : INFO : loss = 0.0014699168 (1.323 sec)\n",
            "2021-02-28 16:43:38,680 : INFO : global_step/sec: 7.50001\n",
            "2021-02-28 16:43:38,681 : INFO : examples/sec: 240\n",
            "2021-02-28 16:43:38,813 : INFO : global_step/sec: 7.50472\n",
            "2021-02-28 16:43:38,814 : INFO : examples/sec: 240.151\n",
            "2021-02-28 16:43:38,942 : INFO : global_step/sec: 7.7443\n",
            "2021-02-28 16:43:38,943 : INFO : examples/sec: 247.818\n",
            "2021-02-28 16:43:39,075 : INFO : global_step/sec: 7.5193\n",
            "2021-02-28 16:43:39,076 : INFO : examples/sec: 240.618\n",
            "2021-02-28 16:43:39,209 : INFO : global_step/sec: 7.51227\n",
            "2021-02-28 16:43:39,209 : INFO : examples/sec: 240.393\n",
            "2021-02-28 16:43:39,341 : INFO : global_step/sec: 7.53125\n",
            "2021-02-28 16:43:39,342 : INFO : examples/sec: 241\n",
            "2021-02-28 16:43:39,471 : INFO : global_step/sec: 7.68561\n",
            "2021-02-28 16:43:39,472 : INFO : examples/sec: 245.939\n",
            "2021-02-28 16:43:39,603 : INFO : global_step/sec: 7.58922\n",
            "2021-02-28 16:43:39,604 : INFO : examples/sec: 242.855\n",
            "2021-02-28 16:43:39,736 : INFO : global_step/sec: 7.5444\n",
            "2021-02-28 16:43:39,737 : INFO : examples/sec: 241.421\n",
            "2021-02-28 16:43:39,865 : INFO : global_step/sec: 7.72268\n",
            "2021-02-28 16:43:39,866 : INFO : examples/sec: 247.126\n",
            "2021-02-28 16:43:39,995 : INFO : loss = 0.091440305 (1.318 sec)\n",
            "2021-02-28 16:43:40,000 : INFO : global_step/sec: 7.44166\n",
            "2021-02-28 16:43:40,001 : INFO : examples/sec: 238.133\n",
            "2021-02-28 16:43:40,135 : INFO : global_step/sec: 7.39435\n",
            "2021-02-28 16:43:40,136 : INFO : examples/sec: 236.619\n",
            "2021-02-28 16:43:40,268 : INFO : global_step/sec: 7.52695\n",
            "2021-02-28 16:43:40,269 : INFO : examples/sec: 240.862\n",
            "2021-02-28 16:43:40,399 : INFO : global_step/sec: 7.59232\n",
            "2021-02-28 16:43:40,400 : INFO : examples/sec: 242.954\n",
            "2021-02-28 16:43:40,532 : INFO : global_step/sec: 7.55683\n",
            "2021-02-28 16:43:40,533 : INFO : examples/sec: 241.818\n",
            "2021-02-28 16:43:40,664 : INFO : global_step/sec: 7.55786\n",
            "2021-02-28 16:43:40,665 : INFO : examples/sec: 241.852\n",
            "2021-02-28 16:43:40,793 : INFO : global_step/sec: 7.751\n",
            "2021-02-28 16:43:40,794 : INFO : examples/sec: 248.032\n",
            "2021-02-28 16:43:40,924 : INFO : global_step/sec: 7.62749\n",
            "2021-02-28 16:43:40,925 : INFO : examples/sec: 244.08\n",
            "2021-02-28 16:43:41,055 : INFO : global_step/sec: 7.62182\n",
            "2021-02-28 16:43:41,056 : INFO : examples/sec: 243.898\n",
            "2021-02-28 16:43:41,188 : INFO : global_step/sec: 7.52335\n",
            "2021-02-28 16:43:41,189 : INFO : examples/sec: 240.747\n",
            "2021-02-28 16:43:41,318 : INFO : loss = 0.004784762 (1.323 sec)\n",
            "2021-02-28 16:43:41,322 : INFO : global_step/sec: 7.50993\n",
            "2021-02-28 16:43:41,323 : INFO : examples/sec: 240.318\n",
            "2021-02-28 16:43:41,450 : INFO : global_step/sec: 7.78034\n",
            "2021-02-28 16:43:41,451 : INFO : examples/sec: 248.971\n",
            "2021-02-28 16:43:41,583 : INFO : global_step/sec: 7.50955\n",
            "2021-02-28 16:43:41,584 : INFO : examples/sec: 240.306\n",
            "2021-02-28 16:43:41,715 : INFO : global_step/sec: 7.58811\n",
            "2021-02-28 16:43:41,716 : INFO : examples/sec: 242.819\n",
            "2021-02-28 16:43:41,846 : INFO : global_step/sec: 7.62094\n",
            "2021-02-28 16:43:41,847 : INFO : examples/sec: 243.87\n",
            "2021-02-28 16:43:41,974 : INFO : global_step/sec: 7.83666\n",
            "2021-02-28 16:43:41,975 : INFO : examples/sec: 250.773\n",
            "2021-02-28 16:43:42,107 : INFO : global_step/sec: 7.5301\n",
            "2021-02-28 16:43:42,108 : INFO : examples/sec: 240.963\n",
            "2021-02-28 16:43:42,239 : INFO : global_step/sec: 7.5568\n",
            "2021-02-28 16:43:42,240 : INFO : examples/sec: 241.818\n",
            "2021-02-28 16:43:42,371 : INFO : global_step/sec: 7.57972\n",
            "2021-02-28 16:43:42,372 : INFO : examples/sec: 242.551\n",
            "2021-02-28 16:43:42,506 : INFO : global_step/sec: 7.3844\n",
            "2021-02-28 16:43:42,507 : INFO : examples/sec: 236.301\n",
            "2021-02-28 16:43:42,638 : INFO : loss = 0.0036690484 (1.320 sec)\n",
            "2021-02-28 16:43:42,641 : INFO : global_step/sec: 7.4155\n",
            "2021-02-28 16:43:42,643 : INFO : examples/sec: 237.296\n",
            "2021-02-28 16:43:42,772 : INFO : global_step/sec: 7.65736\n",
            "2021-02-28 16:43:42,773 : INFO : examples/sec: 245.036\n",
            "2021-02-28 16:43:42,904 : INFO : global_step/sec: 7.57818\n",
            "2021-02-28 16:43:42,905 : INFO : examples/sec: 242.502\n",
            "2021-02-28 16:43:43,036 : INFO : global_step/sec: 7.57263\n",
            "2021-02-28 16:43:43,037 : INFO : examples/sec: 242.324\n",
            "2021-02-28 16:43:43,164 : INFO : global_step/sec: 7.79457\n",
            "2021-02-28 16:43:43,165 : INFO : examples/sec: 249.426\n",
            "2021-02-28 16:43:43,294 : INFO : global_step/sec: 7.70326\n",
            "2021-02-28 16:43:43,295 : INFO : examples/sec: 246.504\n",
            "2021-02-28 16:43:43,427 : INFO : global_step/sec: 7.48965\n",
            "2021-02-28 16:43:43,428 : INFO : examples/sec: 239.669\n",
            "2021-02-28 16:43:43,556 : INFO : global_step/sec: 7.78399\n",
            "2021-02-28 16:43:43,557 : INFO : examples/sec: 249.088\n",
            "2021-02-28 16:43:43,692 : INFO : global_step/sec: 7.34459\n",
            "2021-02-28 16:43:43,693 : INFO : examples/sec: 235.027\n",
            "2021-02-28 16:43:43,819 : INFO : global_step/sec: 7.84575\n",
            "2021-02-28 16:43:43,820 : INFO : examples/sec: 251.064\n",
            "2021-02-28 16:43:43,953 : INFO : loss = 0.005356251 (1.315 sec)\n",
            "2021-02-28 16:43:43,955 : INFO : global_step/sec: 7.38511\n",
            "2021-02-28 16:43:43,958 : INFO : examples/sec: 236.323\n",
            "2021-02-28 16:43:44,085 : INFO : global_step/sec: 7.69301\n",
            "2021-02-28 16:43:44,086 : INFO : examples/sec: 246.176\n",
            "2021-02-28 16:43:44,217 : INFO : global_step/sec: 7.55015\n",
            "2021-02-28 16:43:44,218 : INFO : examples/sec: 241.605\n",
            "2021-02-28 16:43:44,347 : INFO : global_step/sec: 7.72675\n",
            "2021-02-28 16:43:44,348 : INFO : examples/sec: 247.256\n",
            "2021-02-28 16:43:44,478 : INFO : global_step/sec: 7.62455\n",
            "2021-02-28 16:43:44,479 : INFO : examples/sec: 243.986\n",
            "2021-02-28 16:43:44,609 : INFO : global_step/sec: 7.60758\n",
            "2021-02-28 16:43:44,610 : INFO : examples/sec: 243.443\n",
            "2021-02-28 16:43:44,738 : INFO : global_step/sec: 7.75729\n",
            "2021-02-28 16:43:44,739 : INFO : examples/sec: 248.233\n",
            "2021-02-28 16:43:44,865 : INFO : global_step/sec: 7.86521\n",
            "2021-02-28 16:43:44,866 : INFO : examples/sec: 251.687\n",
            "2021-02-28 16:43:44,997 : INFO : global_step/sec: 7.56862\n",
            "2021-02-28 16:43:44,999 : INFO : examples/sec: 242.196\n",
            "2021-02-28 16:43:45,132 : INFO : Saving checkpoints for 200 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:43:55,284 : INFO : global_step/sec: 0.0972122\n",
            "2021-02-28 16:43:55,286 : INFO : examples/sec: 3.11079\n",
            "2021-02-28 16:43:55,430 : INFO : loss = 0.0006147986 (11.476 sec)\n",
            "2021-02-28 16:43:55,432 : INFO : global_step/sec: 6.79097\n",
            "2021-02-28 16:43:55,432 : INFO : examples/sec: 217.311\n",
            "2021-02-28 16:43:55,564 : INFO : global_step/sec: 7.52301\n",
            "2021-02-28 16:43:55,565 : INFO : examples/sec: 240.736\n",
            "2021-02-28 16:43:55,693 : INFO : global_step/sec: 7.77063\n",
            "2021-02-28 16:43:55,694 : INFO : examples/sec: 248.66\n",
            "2021-02-28 16:43:55,821 : INFO : global_step/sec: 7.79263\n",
            "2021-02-28 16:43:55,822 : INFO : examples/sec: 249.364\n",
            "2021-02-28 16:43:55,950 : INFO : global_step/sec: 7.80539\n",
            "2021-02-28 16:43:55,951 : INFO : examples/sec: 249.772\n",
            "2021-02-28 16:43:56,078 : INFO : global_step/sec: 7.78506\n",
            "2021-02-28 16:43:56,079 : INFO : examples/sec: 249.122\n",
            "2021-02-28 16:43:56,207 : INFO : global_step/sec: 7.77404\n",
            "2021-02-28 16:43:56,208 : INFO : examples/sec: 248.769\n",
            "2021-02-28 16:43:56,337 : INFO : global_step/sec: 7.66124\n",
            "2021-02-28 16:43:56,338 : INFO : examples/sec: 245.16\n",
            "2021-02-28 16:43:56,479 : INFO : global_step/sec: 7.55683\n",
            "2021-02-28 16:43:56,483 : INFO : examples/sec: 241.818\n",
            "2021-02-28 16:43:56,641 : INFO : global_step/sec: 5.8357\n",
            "2021-02-28 16:43:56,642 : INFO : examples/sec: 186.742\n",
            "2021-02-28 16:43:56,770 : INFO : loss = 0.02884718 (1.341 sec)\n",
            "2021-02-28 16:43:56,772 : INFO : global_step/sec: 7.63892\n",
            "2021-02-28 16:43:56,773 : INFO : examples/sec: 244.446\n",
            "2021-02-28 16:43:56,901 : INFO : global_step/sec: 7.73666\n",
            "2021-02-28 16:43:56,902 : INFO : examples/sec: 247.573\n",
            "2021-02-28 16:43:57,034 : INFO : global_step/sec: 7.50769\n",
            "2021-02-28 16:43:57,035 : INFO : examples/sec: 240.246\n",
            "2021-02-28 16:43:57,165 : INFO : global_step/sec: 7.63384\n",
            "2021-02-28 16:43:57,166 : INFO : examples/sec: 244.283\n",
            "2021-02-28 16:43:57,304 : INFO : global_step/sec: 7.21233\n",
            "2021-02-28 16:43:57,305 : INFO : examples/sec: 230.795\n",
            "2021-02-28 16:43:57,432 : INFO : global_step/sec: 7.81257\n",
            "2021-02-28 16:43:57,433 : INFO : examples/sec: 250.002\n",
            "2021-02-28 16:43:57,565 : INFO : global_step/sec: 7.52822\n",
            "2021-02-28 16:43:57,566 : INFO : examples/sec: 240.903\n",
            "2021-02-28 16:43:57,693 : INFO : global_step/sec: 7.80867\n",
            "2021-02-28 16:43:57,694 : INFO : examples/sec: 249.878\n",
            "2021-02-28 16:43:57,822 : INFO : global_step/sec: 7.74473\n",
            "2021-02-28 16:43:57,823 : INFO : examples/sec: 247.831\n",
            "2021-02-28 16:43:57,952 : INFO : global_step/sec: 7.65736\n",
            "2021-02-28 16:43:57,953 : INFO : examples/sec: 245.036\n",
            "2021-02-28 16:43:58,080 : INFO : loss = 0.0023526312 (1.310 sec)\n",
            "2021-02-28 16:43:58,083 : INFO : global_step/sec: 7.66619\n",
            "2021-02-28 16:43:58,086 : INFO : examples/sec: 245.318\n",
            "2021-02-28 16:43:58,218 : INFO : global_step/sec: 7.41031\n",
            "2021-02-28 16:43:58,219 : INFO : examples/sec: 237.13\n",
            "2021-02-28 16:43:58,351 : INFO : global_step/sec: 7.52358\n",
            "2021-02-28 16:43:58,352 : INFO : examples/sec: 240.754\n",
            "2021-02-28 16:43:58,484 : INFO : global_step/sec: 7.52974\n",
            "2021-02-28 16:43:58,485 : INFO : examples/sec: 240.952\n",
            "2021-02-28 16:43:58,619 : INFO : global_step/sec: 7.40398\n",
            "2021-02-28 16:43:58,622 : INFO : examples/sec: 236.927\n",
            "2021-02-28 16:43:58,751 : INFO : global_step/sec: 7.55743\n",
            "2021-02-28 16:43:58,752 : INFO : examples/sec: 241.838\n",
            "2021-02-28 16:43:58,884 : INFO : global_step/sec: 7.53676\n",
            "2021-02-28 16:43:58,885 : INFO : examples/sec: 241.176\n",
            "2021-02-28 16:43:59,014 : INFO : global_step/sec: 7.68036\n",
            "2021-02-28 16:43:59,015 : INFO : examples/sec: 245.771\n",
            "2021-02-28 16:43:59,144 : INFO : global_step/sec: 7.70485\n",
            "2021-02-28 16:43:59,144 : INFO : examples/sec: 246.555\n",
            "2021-02-28 16:43:59,278 : INFO : global_step/sec: 7.43808\n",
            "2021-02-28 16:43:59,279 : INFO : examples/sec: 238.019\n",
            "2021-02-28 16:43:59,408 : INFO : loss = 0.0011312576 (1.328 sec)\n",
            "2021-02-28 16:43:59,411 : INFO : global_step/sec: 7.534\n",
            "2021-02-28 16:43:59,414 : INFO : examples/sec: 241.088\n",
            "2021-02-28 16:43:59,543 : INFO : global_step/sec: 7.57865\n",
            "2021-02-28 16:43:59,544 : INFO : examples/sec: 242.517\n",
            "2021-02-28 16:43:59,674 : INFO : global_step/sec: 7.61811\n",
            "2021-02-28 16:43:59,675 : INFO : examples/sec: 243.78\n",
            "2021-02-28 16:43:59,806 : INFO : global_step/sec: 7.58928\n",
            "2021-02-28 16:43:59,807 : INFO : examples/sec: 242.857\n",
            "2021-02-28 16:43:59,936 : INFO : global_step/sec: 7.69151\n",
            "2021-02-28 16:43:59,937 : INFO : examples/sec: 246.128\n",
            "2021-02-28 16:44:00,069 : INFO : global_step/sec: 7.53279\n",
            "2021-02-28 16:44:00,069 : INFO : examples/sec: 241.049\n",
            "2021-02-28 16:44:00,197 : INFO : global_step/sec: 7.81393\n",
            "2021-02-28 16:44:00,197 : INFO : examples/sec: 250.046\n",
            "2021-02-28 16:44:00,332 : INFO : global_step/sec: 7.36499\n",
            "2021-02-28 16:44:00,333 : INFO : examples/sec: 235.68\n",
            "2021-02-28 16:44:00,465 : INFO : global_step/sec: 7.5286\n",
            "2021-02-28 16:44:00,466 : INFO : examples/sec: 240.915\n",
            "2021-02-28 16:44:00,595 : INFO : global_step/sec: 7.69213\n",
            "2021-02-28 16:44:00,596 : INFO : examples/sec: 246.148\n",
            "2021-02-28 16:44:00,726 : INFO : loss = 0.014444958 (1.317 sec)\n",
            "2021-02-28 16:44:00,729 : INFO : global_step/sec: 7.47131\n",
            "2021-02-28 16:44:00,731 : INFO : examples/sec: 239.082\n",
            "2021-02-28 16:44:00,860 : INFO : global_step/sec: 7.62941\n",
            "2021-02-28 16:44:00,863 : INFO : examples/sec: 244.141\n",
            "2021-02-28 16:44:00,994 : INFO : global_step/sec: 7.49374\n",
            "2021-02-28 16:44:00,994 : INFO : examples/sec: 239.8\n",
            "2021-02-28 16:44:01,124 : INFO : global_step/sec: 7.66503\n",
            "2021-02-28 16:44:01,125 : INFO : examples/sec: 245.281\n",
            "2021-02-28 16:44:01,257 : INFO : global_step/sec: 7.50621\n",
            "2021-02-28 16:44:01,258 : INFO : examples/sec: 240.199\n",
            "2021-02-28 16:44:01,390 : INFO : global_step/sec: 7.54218\n",
            "2021-02-28 16:44:01,391 : INFO : examples/sec: 241.35\n",
            "2021-02-28 16:44:01,522 : INFO : global_step/sec: 7.54686\n",
            "2021-02-28 16:44:01,524 : INFO : examples/sec: 241.5\n",
            "2021-02-28 16:44:01,655 : INFO : global_step/sec: 7.54679\n",
            "2021-02-28 16:44:01,656 : INFO : examples/sec: 241.497\n",
            "2021-02-28 16:44:01,789 : INFO : global_step/sec: 7.43061\n",
            "2021-02-28 16:44:01,791 : INFO : examples/sec: 237.779\n",
            "2021-02-28 16:44:01,922 : INFO : global_step/sec: 7.52396\n",
            "2021-02-28 16:44:01,923 : INFO : examples/sec: 240.767\n",
            "2021-02-28 16:44:02,055 : INFO : loss = 0.0006283819 (1.329 sec)\n",
            "2021-02-28 16:44:02,059 : INFO : global_step/sec: 7.32381\n",
            "2021-02-28 16:44:02,060 : INFO : examples/sec: 234.362\n",
            "2021-02-28 16:44:02,195 : INFO : global_step/sec: 7.34702\n",
            "2021-02-28 16:44:02,196 : INFO : examples/sec: 235.105\n",
            "2021-02-28 16:44:02,327 : INFO : global_step/sec: 7.58995\n",
            "2021-02-28 16:44:02,328 : INFO : examples/sec: 242.878\n",
            "2021-02-28 16:44:02,459 : INFO : global_step/sec: 7.53609\n",
            "2021-02-28 16:44:02,460 : INFO : examples/sec: 241.155\n",
            "2021-02-28 16:44:02,592 : INFO : global_step/sec: 7.55386\n",
            "2021-02-28 16:44:02,593 : INFO : examples/sec: 241.724\n",
            "2021-02-28 16:44:02,724 : INFO : global_step/sec: 7.57233\n",
            "2021-02-28 16:44:02,725 : INFO : examples/sec: 242.314\n",
            "2021-02-28 16:44:02,854 : INFO : global_step/sec: 7.67493\n",
            "2021-02-28 16:44:02,857 : INFO : examples/sec: 245.598\n",
            "2021-02-28 16:44:02,988 : INFO : global_step/sec: 7.44442\n",
            "2021-02-28 16:44:02,989 : INFO : examples/sec: 238.221\n",
            "2021-02-28 16:44:03,120 : INFO : global_step/sec: 7.62683\n",
            "2021-02-28 16:44:03,120 : INFO : examples/sec: 244.058\n",
            "2021-02-28 16:44:03,250 : INFO : global_step/sec: 7.69265\n",
            "2021-02-28 16:44:03,251 : INFO : examples/sec: 246.165\n",
            "2021-02-28 16:44:03,383 : INFO : loss = 0.0006479155 (1.328 sec)\n",
            "2021-02-28 16:44:03,384 : INFO : global_step/sec: 7.42807\n",
            "2021-02-28 16:44:03,385 : INFO : examples/sec: 237.698\n",
            "2021-02-28 16:44:03,516 : INFO : global_step/sec: 7.58786\n",
            "2021-02-28 16:44:03,517 : INFO : examples/sec: 242.812\n",
            "2021-02-28 16:44:03,649 : INFO : global_step/sec: 7.5267\n",
            "2021-02-28 16:44:03,650 : INFO : examples/sec: 240.854\n",
            "2021-02-28 16:44:03,781 : INFO : global_step/sec: 7.55158\n",
            "2021-02-28 16:44:03,782 : INFO : examples/sec: 241.65\n",
            "2021-02-28 16:44:03,914 : INFO : global_step/sec: 7.51337\n",
            "2021-02-28 16:44:03,915 : INFO : examples/sec: 240.428\n",
            "2021-02-28 16:44:04,046 : INFO : global_step/sec: 7.60433\n",
            "2021-02-28 16:44:04,047 : INFO : examples/sec: 243.338\n",
            "2021-02-28 16:44:04,180 : INFO : global_step/sec: 7.44204\n",
            "2021-02-28 16:44:04,181 : INFO : examples/sec: 238.145\n",
            "2021-02-28 16:44:04,309 : INFO : global_step/sec: 7.7577\n",
            "2021-02-28 16:44:04,310 : INFO : examples/sec: 248.247\n",
            "2021-02-28 16:44:04,437 : INFO : global_step/sec: 7.80821\n",
            "2021-02-28 16:44:04,438 : INFO : examples/sec: 249.863\n",
            "2021-02-28 16:44:04,571 : INFO : global_step/sec: 7.47091\n",
            "2021-02-28 16:44:04,573 : INFO : examples/sec: 239.069\n",
            "2021-02-28 16:44:04,703 : INFO : loss = 0.007897851 (1.320 sec)\n",
            "2021-02-28 16:44:04,705 : INFO : global_step/sec: 7.46628\n",
            "2021-02-28 16:44:04,710 : INFO : examples/sec: 238.921\n",
            "2021-02-28 16:44:04,839 : INFO : global_step/sec: 7.47195\n",
            "2021-02-28 16:44:04,840 : INFO : examples/sec: 239.102\n",
            "2021-02-28 16:44:04,968 : INFO : global_step/sec: 7.76119\n",
            "2021-02-28 16:44:04,969 : INFO : examples/sec: 248.358\n",
            "2021-02-28 16:44:05,099 : INFO : global_step/sec: 7.62246\n",
            "2021-02-28 16:44:05,100 : INFO : examples/sec: 243.919\n",
            "2021-02-28 16:44:05,226 : INFO : global_step/sec: 7.84126\n",
            "2021-02-28 16:44:05,227 : INFO : examples/sec: 250.92\n",
            "2021-02-28 16:44:05,359 : INFO : global_step/sec: 7.54546\n",
            "2021-02-28 16:44:05,360 : INFO : examples/sec: 241.455\n",
            "2021-02-28 16:44:05,489 : INFO : global_step/sec: 7.71054\n",
            "2021-02-28 16:44:05,489 : INFO : examples/sec: 246.737\n",
            "2021-02-28 16:44:05,619 : INFO : global_step/sec: 7.68644\n",
            "2021-02-28 16:44:05,619 : INFO : examples/sec: 245.966\n",
            "2021-02-28 16:44:05,753 : INFO : global_step/sec: 7.45212\n",
            "2021-02-28 16:44:05,754 : INFO : examples/sec: 238.468\n",
            "2021-02-28 16:44:05,882 : INFO : global_step/sec: 7.74996\n",
            "2021-02-28 16:44:05,883 : INFO : examples/sec: 247.999\n",
            "2021-02-28 16:44:06,011 : INFO : loss = 0.0005069674 (1.309 sec)\n",
            "2021-02-28 16:44:06,015 : INFO : global_step/sec: 7.56582\n",
            "2021-02-28 16:44:06,016 : INFO : examples/sec: 242.106\n",
            "2021-02-28 16:44:06,148 : INFO : global_step/sec: 7.47013\n",
            "2021-02-28 16:44:06,149 : INFO : examples/sec: 239.044\n",
            "2021-02-28 16:44:06,280 : INFO : global_step/sec: 7.54678\n",
            "2021-02-28 16:44:06,281 : INFO : examples/sec: 241.497\n",
            "2021-02-28 16:44:06,414 : INFO : global_step/sec: 7.47412\n",
            "2021-02-28 16:44:06,415 : INFO : examples/sec: 239.172\n",
            "2021-02-28 16:44:06,546 : INFO : global_step/sec: 7.56619\n",
            "2021-02-28 16:44:06,547 : INFO : examples/sec: 242.118\n",
            "2021-02-28 16:44:06,678 : INFO : global_step/sec: 7.62049\n",
            "2021-02-28 16:44:06,679 : INFO : examples/sec: 243.856\n",
            "2021-02-28 16:44:06,814 : INFO : global_step/sec: 7.33405\n",
            "2021-02-28 16:44:06,815 : INFO : examples/sec: 234.689\n",
            "2021-02-28 16:44:06,952 : INFO : global_step/sec: 7.27127\n",
            "2021-02-28 16:44:06,955 : INFO : examples/sec: 232.681\n",
            "2021-02-28 16:44:07,086 : INFO : global_step/sec: 7.44715\n",
            "2021-02-28 16:44:07,087 : INFO : examples/sec: 238.309\n",
            "2021-02-28 16:44:07,217 : INFO : global_step/sec: 7.63417\n",
            "2021-02-28 16:44:07,218 : INFO : examples/sec: 244.293\n",
            "2021-02-28 16:44:07,351 : INFO : loss = 0.0028182473 (1.339 sec)\n",
            "2021-02-28 16:44:07,354 : INFO : global_step/sec: 7.27119\n",
            "2021-02-28 16:44:07,356 : INFO : examples/sec: 232.678\n",
            "2021-02-28 16:44:07,485 : INFO : global_step/sec: 7.63046\n",
            "2021-02-28 16:44:07,487 : INFO : examples/sec: 244.175\n",
            "2021-02-28 16:44:07,619 : INFO : global_step/sec: 7.48947\n",
            "2021-02-28 16:44:07,620 : INFO : examples/sec: 239.663\n",
            "2021-02-28 16:44:07,752 : INFO : global_step/sec: 7.53304\n",
            "2021-02-28 16:44:07,752 : INFO : examples/sec: 241.057\n",
            "2021-02-28 16:44:07,883 : INFO : global_step/sec: 7.63296\n",
            "2021-02-28 16:44:07,883 : INFO : examples/sec: 244.255\n",
            "2021-02-28 16:44:08,017 : INFO : global_step/sec: 7.46113\n",
            "2021-02-28 16:44:08,018 : INFO : examples/sec: 238.756\n",
            "2021-02-28 16:44:08,147 : INFO : global_step/sec: 7.68508\n",
            "2021-02-28 16:44:08,148 : INFO : examples/sec: 245.923\n",
            "2021-02-28 16:44:08,275 : INFO : global_step/sec: 7.81013\n",
            "2021-02-28 16:44:08,276 : INFO : examples/sec: 249.924\n",
            "2021-02-28 16:44:08,406 : INFO : global_step/sec: 7.59718\n",
            "2021-02-28 16:44:08,409 : INFO : examples/sec: 243.11\n",
            "2021-02-28 16:44:08,540 : INFO : Saving checkpoints for 300 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:44:24,871 : INFO : global_step/sec: 0.0607371\n",
            "2021-02-28 16:44:24,872 : INFO : examples/sec: 1.94359\n",
            "2021-02-28 16:44:25,004 : INFO : loss = 0.002218787 (17.653 sec)\n",
            "2021-02-28 16:44:25,007 : INFO : global_step/sec: 7.34746\n",
            "2021-02-28 16:44:25,008 : INFO : examples/sec: 235.119\n",
            "2021-02-28 16:44:25,141 : INFO : global_step/sec: 7.46469\n",
            "2021-02-28 16:44:25,142 : INFO : examples/sec: 238.87\n",
            "2021-02-28 16:44:25,270 : INFO : global_step/sec: 7.7295\n",
            "2021-02-28 16:44:25,271 : INFO : examples/sec: 247.344\n",
            "2021-02-28 16:44:25,400 : INFO : global_step/sec: 7.70346\n",
            "2021-02-28 16:44:25,401 : INFO : examples/sec: 246.511\n",
            "2021-02-28 16:44:25,534 : INFO : global_step/sec: 7.48693\n",
            "2021-02-28 16:44:25,535 : INFO : examples/sec: 239.582\n",
            "2021-02-28 16:44:25,664 : INFO : global_step/sec: 7.68213\n",
            "2021-02-28 16:44:25,665 : INFO : examples/sec: 245.828\n",
            "2021-02-28 16:44:25,795 : INFO : global_step/sec: 7.61511\n",
            "2021-02-28 16:44:25,796 : INFO : examples/sec: 243.684\n",
            "2021-02-28 16:44:25,927 : INFO : global_step/sec: 7.57847\n",
            "2021-02-28 16:44:25,928 : INFO : examples/sec: 242.511\n",
            "2021-02-28 16:44:26,057 : INFO : global_step/sec: 7.68862\n",
            "2021-02-28 16:44:26,058 : INFO : examples/sec: 246.036\n",
            "2021-02-28 16:44:26,189 : INFO : global_step/sec: 7.60062\n",
            "2021-02-28 16:44:26,190 : INFO : examples/sec: 243.22\n",
            "2021-02-28 16:44:26,318 : INFO : loss = 0.00152826 (1.315 sec)\n",
            "2021-02-28 16:44:26,320 : INFO : global_step/sec: 7.63525\n",
            "2021-02-28 16:44:26,321 : INFO : examples/sec: 244.328\n",
            "2021-02-28 16:44:26,454 : INFO : global_step/sec: 7.47184\n",
            "2021-02-28 16:44:26,459 : INFO : examples/sec: 239.099\n",
            "2021-02-28 16:44:26,595 : INFO : global_step/sec: 7.08015\n",
            "2021-02-28 16:44:26,596 : INFO : examples/sec: 226.565\n",
            "2021-02-28 16:44:26,724 : INFO : global_step/sec: 7.72674\n",
            "2021-02-28 16:44:26,725 : INFO : examples/sec: 247.256\n",
            "2021-02-28 16:44:26,856 : INFO : global_step/sec: 7.58932\n",
            "2021-02-28 16:44:26,857 : INFO : examples/sec: 242.858\n",
            "2021-02-28 16:44:26,989 : INFO : global_step/sec: 7.51054\n",
            "2021-02-28 16:44:26,990 : INFO : examples/sec: 240.337\n",
            "2021-02-28 16:44:27,121 : INFO : global_step/sec: 7.56851\n",
            "2021-02-28 16:44:27,122 : INFO : examples/sec: 242.192\n",
            "2021-02-28 16:44:27,249 : INFO : global_step/sec: 7.81294\n",
            "2021-02-28 16:44:27,250 : INFO : examples/sec: 250.014\n",
            "2021-02-28 16:44:27,381 : INFO : global_step/sec: 7.58221\n",
            "2021-02-28 16:44:27,382 : INFO : examples/sec: 242.631\n",
            "2021-02-28 16:44:27,513 : INFO : global_step/sec: 7.59989\n",
            "2021-02-28 16:44:27,514 : INFO : examples/sec: 243.197\n",
            "2021-02-28 16:44:27,645 : INFO : loss = 0.014129806 (1.327 sec)\n",
            "2021-02-28 16:44:27,647 : INFO : global_step/sec: 7.46882\n",
            "2021-02-28 16:44:27,651 : INFO : examples/sec: 239.002\n",
            "2021-02-28 16:44:27,782 : INFO : global_step/sec: 7.40728\n",
            "2021-02-28 16:44:27,782 : INFO : examples/sec: 237.033\n",
            "2021-02-28 16:44:27,912 : INFO : global_step/sec: 7.70226\n",
            "2021-02-28 16:44:27,912 : INFO : examples/sec: 246.472\n",
            "2021-02-28 16:44:28,046 : INFO : global_step/sec: 7.44117\n",
            "2021-02-28 16:44:28,047 : INFO : examples/sec: 238.117\n",
            "2021-02-28 16:44:28,175 : INFO : global_step/sec: 7.74144\n",
            "2021-02-28 16:44:28,176 : INFO : examples/sec: 247.726\n",
            "2021-02-28 16:44:28,308 : INFO : global_step/sec: 7.50731\n",
            "2021-02-28 16:44:28,309 : INFO : examples/sec: 240.234\n",
            "2021-02-28 16:44:28,440 : INFO : global_step/sec: 7.5762\n",
            "2021-02-28 16:44:28,441 : INFO : examples/sec: 242.438\n",
            "2021-02-28 16:44:28,570 : INFO : global_step/sec: 7.69358\n",
            "2021-02-28 16:44:28,571 : INFO : examples/sec: 246.195\n",
            "2021-02-28 16:44:28,700 : INFO : global_step/sec: 7.68258\n",
            "2021-02-28 16:44:28,703 : INFO : examples/sec: 245.843\n",
            "2021-02-28 16:44:28,833 : INFO : global_step/sec: 7.52898\n",
            "2021-02-28 16:44:28,834 : INFO : examples/sec: 240.927\n",
            "2021-02-28 16:44:28,965 : INFO : loss = 0.0011293793 (1.320 sec)\n",
            "2021-02-28 16:44:28,966 : INFO : global_step/sec: 7.52118\n",
            "2021-02-28 16:44:28,967 : INFO : examples/sec: 240.678\n",
            "2021-02-28 16:44:29,102 : INFO : global_step/sec: 7.364\n",
            "2021-02-28 16:44:29,103 : INFO : examples/sec: 235.648\n",
            "2021-02-28 16:44:29,234 : INFO : global_step/sec: 7.58368\n",
            "2021-02-28 16:44:29,235 : INFO : examples/sec: 242.678\n",
            "2021-02-28 16:44:29,362 : INFO : global_step/sec: 7.82427\n",
            "2021-02-28 16:44:29,363 : INFO : examples/sec: 250.377\n",
            "2021-02-28 16:44:29,493 : INFO : global_step/sec: 7.6023\n",
            "2021-02-28 16:44:29,494 : INFO : examples/sec: 243.274\n",
            "2021-02-28 16:44:29,628 : INFO : global_step/sec: 7.40115\n",
            "2021-02-28 16:44:29,629 : INFO : examples/sec: 236.837\n",
            "2021-02-28 16:44:29,766 : INFO : global_step/sec: 7.28769\n",
            "2021-02-28 16:44:29,766 : INFO : examples/sec: 233.206\n",
            "2021-02-28 16:44:29,899 : INFO : global_step/sec: 7.48233\n",
            "2021-02-28 16:44:29,900 : INFO : examples/sec: 239.435\n",
            "2021-02-28 16:44:30,031 : INFO : global_step/sec: 7.58423\n",
            "2021-02-28 16:44:30,032 : INFO : examples/sec: 242.695\n",
            "2021-02-28 16:44:30,161 : INFO : global_step/sec: 7.68694\n",
            "2021-02-28 16:44:30,162 : INFO : examples/sec: 245.982\n",
            "2021-02-28 16:44:30,290 : INFO : loss = 0.2638559 (1.326 sec)\n",
            "2021-02-28 16:44:30,292 : INFO : global_step/sec: 7.64381\n",
            "2021-02-28 16:44:30,296 : INFO : examples/sec: 244.602\n",
            "2021-02-28 16:44:30,426 : INFO : global_step/sec: 7.47978\n",
            "2021-02-28 16:44:30,427 : INFO : examples/sec: 239.353\n",
            "2021-02-28 16:44:30,559 : INFO : global_step/sec: 7.47146\n",
            "2021-02-28 16:44:30,561 : INFO : examples/sec: 239.087\n",
            "2021-02-28 16:44:30,694 : INFO : global_step/sec: 7.4337\n",
            "2021-02-28 16:44:30,695 : INFO : examples/sec: 237.879\n",
            "2021-02-28 16:44:30,827 : INFO : global_step/sec: 7.50003\n",
            "2021-02-28 16:44:30,828 : INFO : examples/sec: 240.001\n",
            "2021-02-28 16:44:30,961 : INFO : global_step/sec: 7.46631\n",
            "2021-02-28 16:44:30,962 : INFO : examples/sec: 238.922\n",
            "2021-02-28 16:44:31,089 : INFO : global_step/sec: 7.80205\n",
            "2021-02-28 16:44:31,090 : INFO : examples/sec: 249.666\n",
            "2021-02-28 16:44:31,219 : INFO : global_step/sec: 7.73794\n",
            "2021-02-28 16:44:31,219 : INFO : examples/sec: 247.614\n",
            "2021-02-28 16:44:31,348 : INFO : global_step/sec: 7.7521\n",
            "2021-02-28 16:44:31,348 : INFO : examples/sec: 248.067\n",
            "2021-02-28 16:44:31,479 : INFO : global_step/sec: 7.60747\n",
            "2021-02-28 16:44:31,480 : INFO : examples/sec: 243.439\n",
            "2021-02-28 16:44:31,609 : INFO : loss = 0.0011166973 (1.319 sec)\n",
            "2021-02-28 16:44:31,612 : INFO : global_step/sec: 7.49868\n",
            "2021-02-28 16:44:31,614 : INFO : examples/sec: 239.958\n",
            "2021-02-28 16:44:31,747 : INFO : global_step/sec: 7.45674\n",
            "2021-02-28 16:44:31,747 : INFO : examples/sec: 238.616\n",
            "2021-02-28 16:44:31,879 : INFO : global_step/sec: 7.57603\n",
            "2021-02-28 16:44:31,879 : INFO : examples/sec: 242.433\n",
            "2021-02-28 16:44:32,012 : INFO : global_step/sec: 7.49593\n",
            "2021-02-28 16:44:32,013 : INFO : examples/sec: 239.87\n",
            "2021-02-28 16:44:32,145 : INFO : global_step/sec: 7.51507\n",
            "2021-02-28 16:44:32,146 : INFO : examples/sec: 240.482\n",
            "2021-02-28 16:44:32,277 : INFO : global_step/sec: 7.57267\n",
            "2021-02-28 16:44:32,278 : INFO : examples/sec: 242.325\n",
            "2021-02-28 16:44:32,409 : INFO : global_step/sec: 7.58425\n",
            "2021-02-28 16:44:32,411 : INFO : examples/sec: 242.696\n",
            "2021-02-28 16:44:32,543 : INFO : global_step/sec: 7.43832\n",
            "2021-02-28 16:44:32,545 : INFO : examples/sec: 238.026\n",
            "2021-02-28 16:44:32,677 : INFO : global_step/sec: 7.46474\n",
            "2021-02-28 16:44:32,679 : INFO : examples/sec: 238.872\n",
            "2021-02-28 16:44:32,810 : INFO : global_step/sec: 7.53718\n",
            "2021-02-28 16:44:32,811 : INFO : examples/sec: 241.19\n",
            "2021-02-28 16:44:32,944 : INFO : loss = 0.00034613133 (1.335 sec)\n",
            "2021-02-28 16:44:32,946 : INFO : global_step/sec: 7.35635\n",
            "2021-02-28 16:44:32,948 : INFO : examples/sec: 235.403\n",
            "2021-02-28 16:44:33,081 : INFO : global_step/sec: 7.41927\n",
            "2021-02-28 16:44:33,082 : INFO : examples/sec: 237.417\n",
            "2021-02-28 16:44:33,210 : INFO : global_step/sec: 7.72496\n",
            "2021-02-28 16:44:33,211 : INFO : examples/sec: 247.199\n",
            "2021-02-28 16:44:33,344 : INFO : global_step/sec: 7.49498\n",
            "2021-02-28 16:44:33,344 : INFO : examples/sec: 239.839\n",
            "2021-02-28 16:44:33,472 : INFO : global_step/sec: 7.76834\n",
            "2021-02-28 16:44:33,473 : INFO : examples/sec: 248.587\n",
            "2021-02-28 16:44:33,607 : INFO : global_step/sec: 7.42413\n",
            "2021-02-28 16:44:33,608 : INFO : examples/sec: 237.572\n",
            "2021-02-28 16:44:33,740 : INFO : global_step/sec: 7.50896\n",
            "2021-02-28 16:44:33,741 : INFO : examples/sec: 240.287\n",
            "2021-02-28 16:44:33,874 : INFO : global_step/sec: 7.45795\n",
            "2021-02-28 16:44:33,875 : INFO : examples/sec: 238.654\n",
            "2021-02-28 16:44:34,009 : INFO : global_step/sec: 7.45304\n",
            "2021-02-28 16:44:34,012 : INFO : examples/sec: 238.497\n",
            "2021-02-28 16:44:34,139 : INFO : global_step/sec: 7.65124\n",
            "2021-02-28 16:44:34,140 : INFO : examples/sec: 244.84\n",
            "2021-02-28 16:44:34,270 : INFO : loss = 0.00045424237 (1.326 sec)\n",
            "2021-02-28 16:44:34,274 : INFO : global_step/sec: 7.40999\n",
            "2021-02-28 16:44:34,276 : INFO : examples/sec: 237.12\n",
            "2021-02-28 16:44:34,408 : INFO : global_step/sec: 7.46565\n",
            "2021-02-28 16:44:34,409 : INFO : examples/sec: 238.901\n",
            "2021-02-28 16:44:34,541 : INFO : global_step/sec: 7.51235\n",
            "2021-02-28 16:44:34,542 : INFO : examples/sec: 240.395\n",
            "2021-02-28 16:44:34,674 : INFO : global_step/sec: 7.54439\n",
            "2021-02-28 16:44:34,677 : INFO : examples/sec: 241.421\n",
            "2021-02-28 16:44:34,809 : INFO : global_step/sec: 7.40471\n",
            "2021-02-28 16:44:34,810 : INFO : examples/sec: 236.951\n",
            "2021-02-28 16:44:34,942 : INFO : global_step/sec: 7.51981\n",
            "2021-02-28 16:44:34,943 : INFO : examples/sec: 240.634\n",
            "2021-02-28 16:44:35,075 : INFO : global_step/sec: 7.48594\n",
            "2021-02-28 16:44:35,078 : INFO : examples/sec: 239.55\n",
            "2021-02-28 16:44:35,209 : INFO : global_step/sec: 7.47099\n",
            "2021-02-28 16:44:35,210 : INFO : examples/sec: 239.072\n",
            "2021-02-28 16:44:35,343 : INFO : global_step/sec: 7.48406\n",
            "2021-02-28 16:44:35,346 : INFO : examples/sec: 239.49\n",
            "2021-02-28 16:44:35,476 : INFO : global_step/sec: 7.4882\n",
            "2021-02-28 16:44:35,477 : INFO : examples/sec: 239.622\n",
            "2021-02-28 16:44:35,611 : INFO : loss = 0.0015344211 (1.340 sec)\n",
            "2021-02-28 16:44:35,613 : INFO : global_step/sec: 7.33514\n",
            "2021-02-28 16:44:35,615 : INFO : examples/sec: 234.724\n",
            "2021-02-28 16:44:35,747 : INFO : global_step/sec: 7.42718\n",
            "2021-02-28 16:44:35,749 : INFO : examples/sec: 237.67\n",
            "2021-02-28 16:44:35,883 : INFO : global_step/sec: 7.36479\n",
            "2021-02-28 16:44:35,884 : INFO : examples/sec: 235.673\n",
            "2021-02-28 16:44:36,017 : INFO : global_step/sec: 7.46576\n",
            "2021-02-28 16:44:36,018 : INFO : examples/sec: 238.904\n",
            "2021-02-28 16:44:36,153 : INFO : global_step/sec: 7.37791\n",
            "2021-02-28 16:44:36,154 : INFO : examples/sec: 236.093\n",
            "2021-02-28 16:44:36,288 : INFO : global_step/sec: 7.37165\n",
            "2021-02-28 16:44:36,289 : INFO : examples/sec: 235.893\n",
            "2021-02-28 16:44:36,421 : INFO : global_step/sec: 7.54538\n",
            "2021-02-28 16:44:36,422 : INFO : examples/sec: 241.452\n",
            "2021-02-28 16:44:36,552 : INFO : global_step/sec: 7.61363\n",
            "2021-02-28 16:44:36,553 : INFO : examples/sec: 243.636\n",
            "2021-02-28 16:44:36,685 : INFO : global_step/sec: 7.55524\n",
            "2021-02-28 16:44:36,685 : INFO : examples/sec: 241.768\n",
            "2021-02-28 16:44:36,818 : INFO : global_step/sec: 7.49822\n",
            "2021-02-28 16:44:36,819 : INFO : examples/sec: 239.943\n",
            "2021-02-28 16:44:36,952 : INFO : loss = 0.0003331047 (1.342 sec)\n",
            "2021-02-28 16:44:36,956 : INFO : global_step/sec: 7.22498\n",
            "2021-02-28 16:44:36,958 : INFO : examples/sec: 231.199\n",
            "2021-02-28 16:44:37,092 : INFO : global_step/sec: 7.34724\n",
            "2021-02-28 16:44:37,093 : INFO : examples/sec: 235.112\n",
            "2021-02-28 16:44:37,228 : INFO : global_step/sec: 7.38293\n",
            "2021-02-28 16:44:37,229 : INFO : examples/sec: 236.254\n",
            "2021-02-28 16:44:37,359 : INFO : global_step/sec: 7.59821\n",
            "2021-02-28 16:44:37,360 : INFO : examples/sec: 243.143\n",
            "2021-02-28 16:44:37,491 : INFO : global_step/sec: 7.59035\n",
            "2021-02-28 16:44:37,493 : INFO : examples/sec: 242.891\n",
            "2021-02-28 16:44:37,623 : INFO : global_step/sec: 7.60894\n",
            "2021-02-28 16:44:37,624 : INFO : examples/sec: 243.486\n",
            "2021-02-28 16:44:37,753 : INFO : global_step/sec: 7.63824\n",
            "2021-02-28 16:44:37,754 : INFO : examples/sec: 244.424\n",
            "2021-02-28 16:44:37,887 : INFO : global_step/sec: 7.49779\n",
            "2021-02-28 16:44:37,888 : INFO : examples/sec: 239.929\n",
            "2021-02-28 16:44:38,022 : INFO : global_step/sec: 7.42545\n",
            "2021-02-28 16:44:38,023 : INFO : examples/sec: 237.614\n",
            "2021-02-28 16:44:38,156 : INFO : Saving checkpoints for 400 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:44:52,843 : INFO : global_step/sec: 0.0674706\n",
            "2021-02-28 16:44:52,844 : INFO : examples/sec: 2.15906\n",
            "2021-02-28 16:44:52,985 : INFO : loss = 0.019816145 (16.033 sec)\n",
            "2021-02-28 16:44:52,989 : INFO : global_step/sec: 6.85618\n",
            "2021-02-28 16:44:52,990 : INFO : examples/sec: 219.398\n",
            "2021-02-28 16:44:53,121 : INFO : global_step/sec: 7.53301\n",
            "2021-02-28 16:44:53,122 : INFO : examples/sec: 241.056\n",
            "2021-02-28 16:44:53,255 : INFO : global_step/sec: 7.46894\n",
            "2021-02-28 16:44:53,256 : INFO : examples/sec: 239.006\n",
            "2021-02-28 16:44:53,392 : INFO : global_step/sec: 7.29355\n",
            "2021-02-28 16:44:53,394 : INFO : examples/sec: 233.394\n",
            "2021-02-28 16:44:53,530 : INFO : global_step/sec: 7.26304\n",
            "2021-02-28 16:44:53,531 : INFO : examples/sec: 232.417\n",
            "2021-02-28 16:44:53,662 : INFO : global_step/sec: 7.58941\n",
            "2021-02-28 16:44:53,663 : INFO : examples/sec: 242.861\n",
            "2021-02-28 16:44:53,795 : INFO : global_step/sec: 7.49793\n",
            "2021-02-28 16:44:53,796 : INFO : examples/sec: 239.934\n",
            "2021-02-28 16:44:53,925 : INFO : global_step/sec: 7.68883\n",
            "2021-02-28 16:44:53,926 : INFO : examples/sec: 246.043\n",
            "2021-02-28 16:44:54,057 : INFO : global_step/sec: 7.56416\n",
            "2021-02-28 16:44:54,058 : INFO : examples/sec: 242.053\n",
            "2021-02-28 16:44:54,191 : INFO : global_step/sec: 7.4801\n",
            "2021-02-28 16:44:54,192 : INFO : examples/sec: 239.363\n",
            "2021-02-28 16:44:54,322 : INFO : loss = 0.0020286378 (1.337 sec)\n",
            "2021-02-28 16:44:54,325 : INFO : global_step/sec: 7.48479\n",
            "2021-02-28 16:44:54,326 : INFO : examples/sec: 239.513\n",
            "2021-02-28 16:44:54,460 : INFO : global_step/sec: 7.41969\n",
            "2021-02-28 16:44:54,460 : INFO : examples/sec: 237.43\n",
            "2021-02-28 16:44:54,592 : INFO : global_step/sec: 7.5284\n",
            "2021-02-28 16:44:54,593 : INFO : examples/sec: 240.909\n",
            "2021-02-28 16:44:54,726 : INFO : global_step/sec: 7.47248\n",
            "2021-02-28 16:44:54,727 : INFO : examples/sec: 239.119\n",
            "2021-02-28 16:44:54,859 : INFO : global_step/sec: 7.54564\n",
            "2021-02-28 16:44:54,860 : INFO : examples/sec: 241.46\n",
            "2021-02-28 16:44:54,989 : INFO : global_step/sec: 7.68407\n",
            "2021-02-28 16:44:54,990 : INFO : examples/sec: 245.89\n",
            "2021-02-28 16:44:55,118 : INFO : global_step/sec: 7.72159\n",
            "2021-02-28 16:44:55,119 : INFO : examples/sec: 247.091\n",
            "2021-02-28 16:44:55,251 : INFO : global_step/sec: 7.54598\n",
            "2021-02-28 16:44:55,253 : INFO : examples/sec: 241.471\n",
            "2021-02-28 16:44:55,384 : INFO : global_step/sec: 7.49593\n",
            "2021-02-28 16:44:55,385 : INFO : examples/sec: 239.87\n",
            "2021-02-28 16:44:55,513 : INFO : global_step/sec: 7.78407\n",
            "2021-02-28 16:44:55,514 : INFO : examples/sec: 249.09\n",
            "2021-02-28 16:44:55,643 : INFO : loss = 0.00031785457 (1.320 sec)\n",
            "2021-02-28 16:44:55,646 : INFO : global_step/sec: 7.51005\n",
            "2021-02-28 16:44:55,647 : INFO : examples/sec: 240.322\n",
            "2021-02-28 16:44:55,775 : INFO : global_step/sec: 7.75788\n",
            "2021-02-28 16:44:55,776 : INFO : examples/sec: 248.252\n",
            "2021-02-28 16:44:55,904 : INFO : global_step/sec: 7.71748\n",
            "2021-02-28 16:44:55,905 : INFO : examples/sec: 246.959\n",
            "2021-02-28 16:44:56,035 : INFO : global_step/sec: 7.67486\n",
            "2021-02-28 16:44:56,036 : INFO : examples/sec: 245.596\n",
            "2021-02-28 16:44:56,167 : INFO : global_step/sec: 7.57416\n",
            "2021-02-28 16:44:56,167 : INFO : examples/sec: 242.373\n",
            "2021-02-28 16:44:56,301 : INFO : global_step/sec: 7.46697\n",
            "2021-02-28 16:44:56,301 : INFO : examples/sec: 238.943\n",
            "2021-02-28 16:44:56,432 : INFO : global_step/sec: 7.60135\n",
            "2021-02-28 16:44:56,433 : INFO : examples/sec: 243.243\n",
            "2021-02-28 16:44:56,567 : INFO : global_step/sec: 7.44674\n",
            "2021-02-28 16:44:56,568 : INFO : examples/sec: 238.296\n",
            "2021-02-28 16:44:56,701 : INFO : global_step/sec: 7.4334\n",
            "2021-02-28 16:44:56,702 : INFO : examples/sec: 237.869\n",
            "2021-02-28 16:44:56,834 : INFO : global_step/sec: 7.52243\n",
            "2021-02-28 16:44:56,835 : INFO : examples/sec: 240.718\n",
            "2021-02-28 16:44:56,967 : INFO : loss = 0.008403729 (1.324 sec)\n",
            "2021-02-28 16:44:56,969 : INFO : global_step/sec: 7.42327\n",
            "2021-02-28 16:44:56,970 : INFO : examples/sec: 237.545\n",
            "2021-02-28 16:44:57,103 : INFO : global_step/sec: 7.44789\n",
            "2021-02-28 16:44:57,104 : INFO : examples/sec: 238.333\n",
            "2021-02-28 16:44:57,237 : INFO : global_step/sec: 7.4467\n",
            "2021-02-28 16:44:57,238 : INFO : examples/sec: 238.295\n",
            "2021-02-28 16:44:57,366 : INFO : global_step/sec: 7.74137\n",
            "2021-02-28 16:44:57,367 : INFO : examples/sec: 247.724\n",
            "2021-02-28 16:44:57,499 : INFO : global_step/sec: 7.56969\n",
            "2021-02-28 16:44:57,500 : INFO : examples/sec: 242.23\n",
            "2021-02-28 16:44:57,632 : INFO : global_step/sec: 7.49857\n",
            "2021-02-28 16:44:57,633 : INFO : examples/sec: 239.954\n",
            "2021-02-28 16:44:57,760 : INFO : global_step/sec: 7.79687\n",
            "2021-02-28 16:44:57,761 : INFO : examples/sec: 249.5\n",
            "2021-02-28 16:44:57,894 : INFO : global_step/sec: 7.48008\n",
            "2021-02-28 16:44:57,895 : INFO : examples/sec: 239.362\n",
            "2021-02-28 16:44:58,025 : INFO : global_step/sec: 7.64975\n",
            "2021-02-28 16:44:58,025 : INFO : examples/sec: 244.792\n",
            "2021-02-28 16:44:58,159 : INFO : global_step/sec: 7.46246\n",
            "2021-02-28 16:44:58,159 : INFO : examples/sec: 238.799\n",
            "2021-02-28 16:44:58,290 : INFO : loss = 0.0003049391 (1.323 sec)\n",
            "2021-02-28 16:44:58,293 : INFO : global_step/sec: 7.41836\n",
            "2021-02-28 16:44:58,295 : INFO : examples/sec: 237.388\n",
            "2021-02-28 16:44:58,423 : INFO : global_step/sec: 7.70065\n",
            "2021-02-28 16:44:58,425 : INFO : examples/sec: 246.421\n",
            "2021-02-28 16:44:58,555 : INFO : global_step/sec: 7.56419\n",
            "2021-02-28 16:44:58,556 : INFO : examples/sec: 242.054\n",
            "2021-02-28 16:44:58,689 : INFO : global_step/sec: 7.50446\n",
            "2021-02-28 16:44:58,690 : INFO : examples/sec: 240.143\n",
            "2021-02-28 16:44:58,821 : INFO : global_step/sec: 7.55166\n",
            "2021-02-28 16:44:58,822 : INFO : examples/sec: 241.653\n",
            "2021-02-28 16:44:58,952 : INFO : global_step/sec: 7.64064\n",
            "2021-02-28 16:44:58,953 : INFO : examples/sec: 244.5\n",
            "2021-02-28 16:44:59,086 : INFO : global_step/sec: 7.46393\n",
            "2021-02-28 16:44:59,087 : INFO : examples/sec: 238.846\n",
            "2021-02-28 16:44:59,216 : INFO : global_step/sec: 7.66443\n",
            "2021-02-28 16:44:59,217 : INFO : examples/sec: 245.262\n",
            "2021-02-28 16:44:59,351 : INFO : global_step/sec: 7.45442\n",
            "2021-02-28 16:44:59,351 : INFO : examples/sec: 238.541\n",
            "2021-02-28 16:44:59,484 : INFO : global_step/sec: 7.47916\n",
            "2021-02-28 16:44:59,485 : INFO : examples/sec: 239.333\n",
            "2021-02-28 16:44:59,613 : INFO : loss = 0.0003531454 (1.323 sec)\n",
            "2021-02-28 16:44:59,617 : INFO : global_step/sec: 7.53909\n",
            "2021-02-28 16:44:59,619 : INFO : examples/sec: 241.251\n",
            "2021-02-28 16:44:59,751 : INFO : global_step/sec: 7.48066\n",
            "2021-02-28 16:44:59,751 : INFO : examples/sec: 239.381\n",
            "2021-02-28 16:44:59,879 : INFO : global_step/sec: 7.7801\n",
            "2021-02-28 16:44:59,880 : INFO : examples/sec: 248.963\n",
            "2021-02-28 16:45:00,014 : INFO : global_step/sec: 7.42512\n",
            "2021-02-28 16:45:00,015 : INFO : examples/sec: 237.604\n",
            "2021-02-28 16:45:00,142 : INFO : global_step/sec: 7.8142\n",
            "2021-02-28 16:45:00,143 : INFO : examples/sec: 250.054\n",
            "2021-02-28 16:45:00,275 : INFO : global_step/sec: 7.51268\n",
            "2021-02-28 16:45:00,276 : INFO : examples/sec: 240.406\n",
            "2021-02-28 16:45:00,406 : INFO : global_step/sec: 7.64731\n",
            "2021-02-28 16:45:00,407 : INFO : examples/sec: 244.714\n",
            "2021-02-28 16:45:00,539 : INFO : global_step/sec: 7.4858\n",
            "2021-02-28 16:45:00,540 : INFO : examples/sec: 239.546\n",
            "2021-02-28 16:45:00,674 : INFO : global_step/sec: 7.41335\n",
            "2021-02-28 16:45:00,675 : INFO : examples/sec: 237.227\n",
            "2021-02-28 16:45:00,809 : INFO : global_step/sec: 7.41768\n",
            "2021-02-28 16:45:00,810 : INFO : examples/sec: 237.366\n",
            "2021-02-28 16:45:00,940 : INFO : loss = 0.0009603578 (1.327 sec)\n",
            "2021-02-28 16:45:00,942 : INFO : global_step/sec: 7.53378\n",
            "2021-02-28 16:45:00,943 : INFO : examples/sec: 241.081\n",
            "2021-02-28 16:45:01,079 : INFO : global_step/sec: 7.26763\n",
            "2021-02-28 16:45:01,080 : INFO : examples/sec: 232.564\n",
            "2021-02-28 16:45:01,215 : INFO : global_step/sec: 7.37851\n",
            "2021-02-28 16:45:01,216 : INFO : examples/sec: 236.112\n",
            "2021-02-28 16:45:01,346 : INFO : global_step/sec: 7.61597\n",
            "2021-02-28 16:45:01,347 : INFO : examples/sec: 243.711\n",
            "2021-02-28 16:45:01,478 : INFO : global_step/sec: 7.60538\n",
            "2021-02-28 16:45:01,478 : INFO : examples/sec: 243.372\n",
            "2021-02-28 16:45:01,610 : INFO : global_step/sec: 7.57501\n",
            "2021-02-28 16:45:01,611 : INFO : examples/sec: 242.4\n",
            "2021-02-28 16:45:01,742 : INFO : global_step/sec: 7.53691\n",
            "2021-02-28 16:45:01,743 : INFO : examples/sec: 241.181\n",
            "2021-02-28 16:45:01,879 : INFO : global_step/sec: 7.337\n",
            "2021-02-28 16:45:01,881 : INFO : examples/sec: 234.784\n",
            "2021-02-28 16:45:02,013 : INFO : global_step/sec: 7.44427\n",
            "2021-02-28 16:45:02,014 : INFO : examples/sec: 238.217\n",
            "2021-02-28 16:45:02,152 : INFO : global_step/sec: 7.18593\n",
            "2021-02-28 16:45:02,153 : INFO : examples/sec: 229.95\n",
            "2021-02-28 16:45:02,285 : INFO : loss = 0.0002657036 (1.345 sec)\n",
            "2021-02-28 16:45:02,287 : INFO : global_step/sec: 7.4342\n",
            "2021-02-28 16:45:02,288 : INFO : examples/sec: 237.895\n",
            "2021-02-28 16:45:02,423 : INFO : global_step/sec: 7.32906\n",
            "2021-02-28 16:45:02,424 : INFO : examples/sec: 234.53\n",
            "2021-02-28 16:45:02,553 : INFO : global_step/sec: 7.70049\n",
            "2021-02-28 16:45:02,554 : INFO : examples/sec: 246.416\n",
            "2021-02-28 16:45:02,684 : INFO : global_step/sec: 7.63377\n",
            "2021-02-28 16:45:02,685 : INFO : examples/sec: 244.281\n",
            "2021-02-28 16:45:02,821 : INFO : global_step/sec: 7.27969\n",
            "2021-02-28 16:45:02,823 : INFO : examples/sec: 232.95\n",
            "2021-02-28 16:45:02,955 : INFO : global_step/sec: 7.4918\n",
            "2021-02-28 16:45:02,956 : INFO : examples/sec: 239.737\n",
            "2021-02-28 16:45:03,089 : INFO : global_step/sec: 7.42733\n",
            "2021-02-28 16:45:03,090 : INFO : examples/sec: 237.675\n",
            "2021-02-28 16:45:03,218 : INFO : global_step/sec: 7.75552\n",
            "2021-02-28 16:45:03,219 : INFO : examples/sec: 248.177\n",
            "2021-02-28 16:45:03,353 : INFO : global_step/sec: 7.41567\n",
            "2021-02-28 16:45:03,354 : INFO : examples/sec: 237.301\n",
            "2021-02-28 16:45:03,486 : INFO : global_step/sec: 7.53041\n",
            "2021-02-28 16:45:03,487 : INFO : examples/sec: 240.973\n",
            "2021-02-28 16:45:03,618 : INFO : loss = 0.01749661 (1.333 sec)\n",
            "2021-02-28 16:45:03,620 : INFO : global_step/sec: 7.47985\n",
            "2021-02-28 16:45:03,621 : INFO : examples/sec: 239.355\n",
            "2021-02-28 16:45:03,757 : INFO : global_step/sec: 7.29347\n",
            "2021-02-28 16:45:03,758 : INFO : examples/sec: 233.391\n",
            "2021-02-28 16:45:03,888 : INFO : global_step/sec: 7.62613\n",
            "2021-02-28 16:45:03,889 : INFO : examples/sec: 244.036\n",
            "2021-02-28 16:45:04,022 : INFO : global_step/sec: 7.4642\n",
            "2021-02-28 16:45:04,023 : INFO : examples/sec: 238.854\n",
            "2021-02-28 16:45:04,155 : INFO : global_step/sec: 7.50317\n",
            "2021-02-28 16:45:04,158 : INFO : examples/sec: 240.102\n",
            "2021-02-28 16:45:04,287 : INFO : global_step/sec: 7.60076\n",
            "2021-02-28 16:45:04,287 : INFO : examples/sec: 243.224\n",
            "2021-02-28 16:45:04,416 : INFO : global_step/sec: 7.71156\n",
            "2021-02-28 16:45:04,417 : INFO : examples/sec: 246.77\n",
            "2021-02-28 16:45:04,549 : INFO : global_step/sec: 7.52716\n",
            "2021-02-28 16:45:04,550 : INFO : examples/sec: 240.869\n",
            "2021-02-28 16:45:04,680 : INFO : global_step/sec: 7.65271\n",
            "2021-02-28 16:45:04,681 : INFO : examples/sec: 244.887\n",
            "2021-02-28 16:45:04,810 : INFO : global_step/sec: 7.68418\n",
            "2021-02-28 16:45:04,811 : INFO : examples/sec: 245.894\n",
            "2021-02-28 16:45:04,940 : INFO : loss = 0.00026071953 (1.322 sec)\n",
            "2021-02-28 16:45:04,947 : INFO : global_step/sec: 7.31557\n",
            "2021-02-28 16:45:04,948 : INFO : examples/sec: 234.098\n",
            "2021-02-28 16:45:05,080 : INFO : global_step/sec: 7.52158\n",
            "2021-02-28 16:45:05,080 : INFO : examples/sec: 240.691\n",
            "2021-02-28 16:45:05,213 : INFO : global_step/sec: 7.50908\n",
            "2021-02-28 16:45:05,214 : INFO : examples/sec: 240.291\n",
            "2021-02-28 16:45:05,344 : INFO : global_step/sec: 7.6028\n",
            "2021-02-28 16:45:05,345 : INFO : examples/sec: 243.29\n",
            "2021-02-28 16:45:05,475 : INFO : global_step/sec: 7.66958\n",
            "2021-02-28 16:45:05,476 : INFO : examples/sec: 245.427\n",
            "2021-02-28 16:45:05,605 : INFO : global_step/sec: 7.68875\n",
            "2021-02-28 16:45:05,606 : INFO : examples/sec: 246.04\n",
            "2021-02-28 16:45:05,740 : INFO : global_step/sec: 7.41209\n",
            "2021-02-28 16:45:05,741 : INFO : examples/sec: 237.187\n",
            "2021-02-28 16:45:05,869 : INFO : global_step/sec: 7.73487\n",
            "2021-02-28 16:45:05,870 : INFO : examples/sec: 247.516\n",
            "2021-02-28 16:45:06,002 : INFO : global_step/sec: 7.5391\n",
            "2021-02-28 16:45:06,003 : INFO : examples/sec: 241.251\n",
            "2021-02-28 16:45:06,135 : INFO : Saving checkpoints for 500 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:45:21,893 : INFO : global_step/sec: 0.0629263\n",
            "2021-02-28 16:45:21,894 : INFO : examples/sec: 2.01364\n",
            "2021-02-28 16:45:22,027 : INFO : loss = 0.00027501167 (17.087 sec)\n",
            "2021-02-28 16:45:22,029 : INFO : global_step/sec: 7.34924\n",
            "2021-02-28 16:45:22,037 : INFO : examples/sec: 235.176\n",
            "2021-02-28 16:45:22,173 : INFO : global_step/sec: 6.9655\n",
            "2021-02-28 16:45:22,174 : INFO : examples/sec: 222.896\n",
            "2021-02-28 16:45:22,301 : INFO : global_step/sec: 7.82836\n",
            "2021-02-28 16:45:22,302 : INFO : examples/sec: 250.508\n",
            "2021-02-28 16:45:22,436 : INFO : global_step/sec: 7.41219\n",
            "2021-02-28 16:45:22,437 : INFO : examples/sec: 237.19\n",
            "2021-02-28 16:45:22,566 : INFO : global_step/sec: 7.66769\n",
            "2021-02-28 16:45:22,573 : INFO : examples/sec: 245.366\n",
            "2021-02-28 16:45:22,702 : INFO : global_step/sec: 7.37625\n",
            "2021-02-28 16:45:22,703 : INFO : examples/sec: 236.04\n",
            "2021-02-28 16:45:22,837 : INFO : global_step/sec: 7.37919\n",
            "2021-02-28 16:45:22,838 : INFO : examples/sec: 236.134\n",
            "2021-02-28 16:45:22,969 : INFO : global_step/sec: 7.60482\n",
            "2021-02-28 16:45:22,970 : INFO : examples/sec: 243.354\n",
            "2021-02-28 16:45:23,100 : INFO : global_step/sec: 7.61898\n",
            "2021-02-28 16:45:23,101 : INFO : examples/sec: 243.807\n",
            "2021-02-28 16:45:23,231 : INFO : global_step/sec: 7.60261\n",
            "2021-02-28 16:45:23,233 : INFO : examples/sec: 243.283\n",
            "2021-02-28 16:45:23,365 : INFO : loss = 0.0100006275 (1.337 sec)\n",
            "2021-02-28 16:45:23,367 : INFO : global_step/sec: 7.39582\n",
            "2021-02-28 16:45:23,370 : INFO : examples/sec: 236.666\n",
            "2021-02-28 16:45:23,505 : INFO : global_step/sec: 7.22493\n",
            "2021-02-28 16:45:23,506 : INFO : examples/sec: 231.198\n",
            "2021-02-28 16:45:23,640 : INFO : global_step/sec: 7.42681\n",
            "2021-02-28 16:45:23,641 : INFO : examples/sec: 237.658\n",
            "2021-02-28 16:45:23,773 : INFO : global_step/sec: 7.51929\n",
            "2021-02-28 16:45:23,774 : INFO : examples/sec: 240.617\n",
            "2021-02-28 16:45:23,903 : INFO : global_step/sec: 7.65589\n",
            "2021-02-28 16:45:23,904 : INFO : examples/sec: 244.989\n",
            "2021-02-28 16:45:24,036 : INFO : global_step/sec: 7.52292\n",
            "2021-02-28 16:45:24,037 : INFO : examples/sec: 240.733\n",
            "2021-02-28 16:45:24,167 : INFO : global_step/sec: 7.62917\n",
            "2021-02-28 16:45:24,168 : INFO : examples/sec: 244.133\n",
            "2021-02-28 16:45:24,301 : INFO : global_step/sec: 7.47936\n",
            "2021-02-28 16:45:24,302 : INFO : examples/sec: 239.339\n",
            "2021-02-28 16:45:24,435 : INFO : global_step/sec: 7.4338\n",
            "2021-02-28 16:45:24,436 : INFO : examples/sec: 237.881\n",
            "2021-02-28 16:45:24,567 : INFO : global_step/sec: 7.62324\n",
            "2021-02-28 16:45:24,568 : INFO : examples/sec: 243.944\n",
            "2021-02-28 16:45:24,698 : INFO : loss = 0.00059817446 (1.333 sec)\n",
            "2021-02-28 16:45:24,699 : INFO : global_step/sec: 7.53493\n",
            "2021-02-28 16:45:24,701 : INFO : examples/sec: 241.118\n",
            "2021-02-28 16:45:24,838 : INFO : global_step/sec: 7.23272\n",
            "2021-02-28 16:45:24,839 : INFO : examples/sec: 231.447\n",
            "2021-02-28 16:45:24,970 : INFO : global_step/sec: 7.58465\n",
            "2021-02-28 16:45:24,970 : INFO : examples/sec: 242.709\n",
            "2021-02-28 16:45:25,102 : INFO : global_step/sec: 7.54345\n",
            "2021-02-28 16:45:25,103 : INFO : examples/sec: 241.391\n",
            "2021-02-28 16:45:25,236 : INFO : global_step/sec: 7.4905\n",
            "2021-02-28 16:45:25,237 : INFO : examples/sec: 239.696\n",
            "2021-02-28 16:45:25,371 : INFO : global_step/sec: 7.3967\n",
            "2021-02-28 16:45:25,372 : INFO : examples/sec: 236.694\n",
            "2021-02-28 16:45:25,504 : INFO : global_step/sec: 7.5003\n",
            "2021-02-28 16:45:25,505 : INFO : examples/sec: 240.01\n",
            "2021-02-28 16:45:25,639 : INFO : global_step/sec: 7.40912\n",
            "2021-02-28 16:45:25,640 : INFO : examples/sec: 237.092\n",
            "2021-02-28 16:45:25,772 : INFO : global_step/sec: 7.53106\n",
            "2021-02-28 16:45:25,773 : INFO : examples/sec: 240.994\n",
            "2021-02-28 16:45:25,903 : INFO : global_step/sec: 7.63315\n",
            "2021-02-28 16:45:25,904 : INFO : examples/sec: 244.261\n",
            "2021-02-28 16:45:26,033 : INFO : loss = 0.0005653597 (1.335 sec)\n",
            "2021-02-28 16:45:26,034 : INFO : global_step/sec: 7.60667\n",
            "2021-02-28 16:45:26,036 : INFO : examples/sec: 243.414\n",
            "2021-02-28 16:45:26,176 : INFO : global_step/sec: 7.07718\n",
            "2021-02-28 16:45:26,177 : INFO : examples/sec: 226.47\n",
            "2021-02-28 16:45:26,308 : INFO : global_step/sec: 7.54955\n",
            "2021-02-28 16:45:26,309 : INFO : examples/sec: 241.586\n",
            "2021-02-28 16:45:26,443 : INFO : global_step/sec: 7.3932\n",
            "2021-02-28 16:45:26,444 : INFO : examples/sec: 236.582\n",
            "2021-02-28 16:45:26,576 : INFO : global_step/sec: 7.52567\n",
            "2021-02-28 16:45:26,577 : INFO : examples/sec: 240.821\n",
            "2021-02-28 16:45:26,710 : INFO : global_step/sec: 7.45678\n",
            "2021-02-28 16:45:26,711 : INFO : examples/sec: 238.617\n",
            "2021-02-28 16:45:26,843 : INFO : global_step/sec: 7.53289\n",
            "2021-02-28 16:45:26,844 : INFO : examples/sec: 241.052\n",
            "2021-02-28 16:45:26,975 : INFO : global_step/sec: 7.5658\n",
            "2021-02-28 16:45:26,976 : INFO : examples/sec: 242.106\n",
            "2021-02-28 16:45:27,107 : INFO : global_step/sec: 7.59371\n",
            "2021-02-28 16:45:27,108 : INFO : examples/sec: 242.999\n",
            "2021-02-28 16:45:27,238 : INFO : global_step/sec: 7.60442\n",
            "2021-02-28 16:45:27,239 : INFO : examples/sec: 243.342\n",
            "2021-02-28 16:45:27,368 : INFO : loss = 0.34330004 (1.335 sec)\n",
            "2021-02-28 16:45:27,372 : INFO : global_step/sec: 7.51475\n",
            "2021-02-28 16:45:27,374 : INFO : examples/sec: 240.472\n",
            "2021-02-28 16:45:27,505 : INFO : global_step/sec: 7.46527\n",
            "2021-02-28 16:45:27,506 : INFO : examples/sec: 238.889\n",
            "2021-02-28 16:45:27,644 : INFO : global_step/sec: 7.22159\n",
            "2021-02-28 16:45:27,645 : INFO : examples/sec: 231.091\n",
            "2021-02-28 16:45:27,782 : INFO : global_step/sec: 7.22654\n",
            "2021-02-28 16:45:27,784 : INFO : examples/sec: 231.249\n",
            "2021-02-28 16:45:27,929 : INFO : global_step/sec: 6.83268\n",
            "2021-02-28 16:45:27,930 : INFO : examples/sec: 218.646\n",
            "2021-02-28 16:45:28,062 : INFO : global_step/sec: 7.50521\n",
            "2021-02-28 16:45:28,063 : INFO : examples/sec: 240.167\n",
            "2021-02-28 16:45:28,200 : INFO : global_step/sec: 7.24132\n",
            "2021-02-28 16:45:28,201 : INFO : examples/sec: 231.722\n",
            "2021-02-28 16:45:28,334 : INFO : global_step/sec: 7.46325\n",
            "2021-02-28 16:45:28,335 : INFO : examples/sec: 238.824\n",
            "2021-02-28 16:45:28,468 : INFO : global_step/sec: 7.4356\n",
            "2021-02-28 16:45:28,469 : INFO : examples/sec: 237.939\n",
            "2021-02-28 16:45:28,602 : INFO : global_step/sec: 7.5141\n",
            "2021-02-28 16:45:28,602 : INFO : examples/sec: 240.451\n",
            "2021-02-28 16:45:28,736 : INFO : loss = 0.00030127304 (1.368 sec)\n",
            "2021-02-28 16:45:28,737 : INFO : global_step/sec: 7.36245\n",
            "2021-02-28 16:45:28,738 : INFO : examples/sec: 235.598\n",
            "2021-02-28 16:45:28,874 : INFO : global_step/sec: 7.32159\n",
            "2021-02-28 16:45:28,875 : INFO : examples/sec: 234.291\n",
            "2021-02-28 16:45:29,008 : INFO : global_step/sec: 7.44287\n",
            "2021-02-28 16:45:29,009 : INFO : examples/sec: 238.172\n",
            "2021-02-28 16:45:29,138 : INFO : global_step/sec: 7.70724\n",
            "2021-02-28 16:45:29,139 : INFO : examples/sec: 246.632\n",
            "2021-02-28 16:45:29,275 : INFO : global_step/sec: 7.3265\n",
            "2021-02-28 16:45:29,275 : INFO : examples/sec: 234.448\n",
            "2021-02-28 16:45:29,407 : INFO : global_step/sec: 7.56641\n",
            "2021-02-28 16:45:29,408 : INFO : examples/sec: 242.125\n",
            "2021-02-28 16:45:29,543 : INFO : global_step/sec: 7.32367\n",
            "2021-02-28 16:45:29,544 : INFO : examples/sec: 234.358\n",
            "2021-02-28 16:45:29,679 : INFO : global_step/sec: 7.36729\n",
            "2021-02-28 16:45:29,680 : INFO : examples/sec: 235.753\n",
            "2021-02-28 16:45:29,815 : INFO : global_step/sec: 7.34828\n",
            "2021-02-28 16:45:29,816 : INFO : examples/sec: 235.145\n",
            "2021-02-28 16:45:29,950 : INFO : global_step/sec: 7.4285\n",
            "2021-02-28 16:45:29,951 : INFO : examples/sec: 237.712\n",
            "2021-02-28 16:45:30,083 : INFO : loss = 0.0059179524 (1.348 sec)\n",
            "2021-02-28 16:45:30,087 : INFO : global_step/sec: 7.26776\n",
            "2021-02-28 16:45:30,088 : INFO : examples/sec: 232.568\n",
            "2021-02-28 16:45:30,222 : INFO : global_step/sec: 7.40217\n",
            "2021-02-28 16:45:30,223 : INFO : examples/sec: 236.869\n",
            "2021-02-28 16:45:30,353 : INFO : global_step/sec: 7.63638\n",
            "2021-02-28 16:45:30,354 : INFO : examples/sec: 244.364\n",
            "2021-02-28 16:45:30,486 : INFO : global_step/sec: 7.53684\n",
            "2021-02-28 16:45:30,487 : INFO : examples/sec: 241.179\n",
            "2021-02-28 16:45:30,620 : INFO : global_step/sec: 7.46343\n",
            "2021-02-28 16:45:30,623 : INFO : examples/sec: 238.83\n",
            "2021-02-28 16:45:30,755 : INFO : global_step/sec: 7.40173\n",
            "2021-02-28 16:45:30,758 : INFO : examples/sec: 236.856\n",
            "2021-02-28 16:45:30,890 : INFO : global_step/sec: 7.41621\n",
            "2021-02-28 16:45:30,891 : INFO : examples/sec: 237.319\n",
            "2021-02-28 16:45:31,024 : INFO : global_step/sec: 7.44186\n",
            "2021-02-28 16:45:31,025 : INFO : examples/sec: 238.139\n",
            "2021-02-28 16:45:31,156 : INFO : global_step/sec: 7.57705\n",
            "2021-02-28 16:45:31,157 : INFO : examples/sec: 242.465\n",
            "2021-02-28 16:45:31,289 : INFO : global_step/sec: 7.53649\n",
            "2021-02-28 16:45:31,291 : INFO : examples/sec: 241.168\n",
            "2021-02-28 16:45:31,425 : INFO : loss = 0.00027994916 (1.341 sec)\n",
            "2021-02-28 16:45:31,429 : INFO : global_step/sec: 7.15802\n",
            "2021-02-28 16:45:31,430 : INFO : examples/sec: 229.057\n",
            "2021-02-28 16:45:31,561 : INFO : global_step/sec: 7.53767\n",
            "2021-02-28 16:45:31,562 : INFO : examples/sec: 241.205\n",
            "2021-02-28 16:45:31,693 : INFO : global_step/sec: 7.61872\n",
            "2021-02-28 16:45:31,694 : INFO : examples/sec: 243.799\n",
            "2021-02-28 16:45:31,830 : INFO : global_step/sec: 7.29524\n",
            "2021-02-28 16:45:31,831 : INFO : examples/sec: 233.448\n",
            "2021-02-28 16:45:31,962 : INFO : global_step/sec: 7.53224\n",
            "2021-02-28 16:45:31,963 : INFO : examples/sec: 241.032\n",
            "2021-02-28 16:45:32,097 : INFO : global_step/sec: 7.40522\n",
            "2021-02-28 16:45:32,099 : INFO : examples/sec: 236.967\n",
            "2021-02-28 16:45:32,232 : INFO : global_step/sec: 7.41033\n",
            "2021-02-28 16:45:32,233 : INFO : examples/sec: 237.13\n",
            "2021-02-28 16:45:32,368 : INFO : global_step/sec: 7.3949\n",
            "2021-02-28 16:45:32,369 : INFO : examples/sec: 236.637\n",
            "2021-02-28 16:45:32,500 : INFO : global_step/sec: 7.53935\n",
            "2021-02-28 16:45:32,501 : INFO : examples/sec: 241.259\n",
            "2021-02-28 16:45:32,635 : INFO : global_step/sec: 7.42831\n",
            "2021-02-28 16:45:32,636 : INFO : examples/sec: 237.706\n",
            "2021-02-28 16:45:32,765 : INFO : loss = 0.00026019855 (1.340 sec)\n",
            "2021-02-28 16:45:32,768 : INFO : global_step/sec: 7.50656\n",
            "2021-02-28 16:45:32,770 : INFO : examples/sec: 240.21\n",
            "2021-02-28 16:45:32,906 : INFO : global_step/sec: 7.26703\n",
            "2021-02-28 16:45:32,907 : INFO : examples/sec: 232.545\n",
            "2021-02-28 16:45:33,038 : INFO : global_step/sec: 7.55679\n",
            "2021-02-28 16:45:33,039 : INFO : examples/sec: 241.817\n",
            "2021-02-28 16:45:33,175 : INFO : global_step/sec: 7.2836\n",
            "2021-02-28 16:45:33,179 : INFO : examples/sec: 233.075\n",
            "2021-02-28 16:45:33,310 : INFO : global_step/sec: 7.44207\n",
            "2021-02-28 16:45:33,311 : INFO : examples/sec: 238.146\n",
            "2021-02-28 16:45:33,445 : INFO : global_step/sec: 7.40329\n",
            "2021-02-28 16:45:33,446 : INFO : examples/sec: 236.905\n",
            "2021-02-28 16:45:33,578 : INFO : global_step/sec: 7.51363\n",
            "2021-02-28 16:45:33,579 : INFO : examples/sec: 240.436\n",
            "2021-02-28 16:45:33,711 : INFO : global_step/sec: 7.54057\n",
            "2021-02-28 16:45:33,711 : INFO : examples/sec: 241.298\n",
            "2021-02-28 16:45:33,844 : INFO : global_step/sec: 7.51857\n",
            "2021-02-28 16:45:33,844 : INFO : examples/sec: 240.594\n",
            "2021-02-28 16:45:33,978 : INFO : global_step/sec: 7.42097\n",
            "2021-02-28 16:45:33,979 : INFO : examples/sec: 237.471\n",
            "2021-02-28 16:45:34,108 : INFO : loss = 0.34288192 (1.343 sec)\n",
            "2021-02-28 16:45:34,110 : INFO : global_step/sec: 7.60747\n",
            "2021-02-28 16:45:34,112 : INFO : examples/sec: 243.439\n",
            "2021-02-28 16:45:34,246 : INFO : global_step/sec: 7.3453\n",
            "2021-02-28 16:45:34,247 : INFO : examples/sec: 235.049\n",
            "2021-02-28 16:45:34,379 : INFO : global_step/sec: 7.49861\n",
            "2021-02-28 16:45:34,380 : INFO : examples/sec: 239.956\n",
            "2021-02-28 16:45:34,509 : INFO : global_step/sec: 7.70513\n",
            "2021-02-28 16:45:34,510 : INFO : examples/sec: 246.564\n",
            "2021-02-28 16:45:34,640 : INFO : global_step/sec: 7.6356\n",
            "2021-02-28 16:45:34,641 : INFO : examples/sec: 244.339\n",
            "2021-02-28 16:45:34,774 : INFO : global_step/sec: 7.45734\n",
            "2021-02-28 16:45:34,775 : INFO : examples/sec: 238.635\n",
            "2021-02-28 16:45:34,904 : INFO : global_step/sec: 7.72009\n",
            "2021-02-28 16:45:34,905 : INFO : examples/sec: 247.043\n",
            "2021-02-28 16:45:35,033 : INFO : global_step/sec: 7.72826\n",
            "2021-02-28 16:45:35,034 : INFO : examples/sec: 247.304\n",
            "2021-02-28 16:45:35,166 : INFO : global_step/sec: 7.53879\n",
            "2021-02-28 16:45:35,166 : INFO : examples/sec: 241.241\n",
            "2021-02-28 16:45:35,295 : INFO : Saving checkpoints for 600 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:45:49,008 : INFO : global_step/sec: 0.0722404\n",
            "2021-02-28 16:45:49,009 : INFO : examples/sec: 2.31169\n",
            "2021-02-28 16:45:49,149 : INFO : loss = 0.0013527705 (15.041 sec)\n",
            "2021-02-28 16:45:49,152 : INFO : global_step/sec: 6.95074\n",
            "2021-02-28 16:45:49,154 : INFO : examples/sec: 222.424\n",
            "2021-02-28 16:45:49,290 : INFO : global_step/sec: 7.25884\n",
            "2021-02-28 16:45:49,291 : INFO : examples/sec: 232.283\n",
            "2021-02-28 16:45:49,428 : INFO : global_step/sec: 7.23276\n",
            "2021-02-28 16:45:49,429 : INFO : examples/sec: 231.448\n",
            "2021-02-28 16:45:49,561 : INFO : global_step/sec: 7.52535\n",
            "2021-02-28 16:45:49,562 : INFO : examples/sec: 240.811\n",
            "2021-02-28 16:45:49,693 : INFO : global_step/sec: 7.58571\n",
            "2021-02-28 16:45:49,694 : INFO : examples/sec: 242.743\n",
            "2021-02-28 16:45:49,823 : INFO : global_step/sec: 7.68306\n",
            "2021-02-28 16:45:49,824 : INFO : examples/sec: 245.858\n",
            "2021-02-28 16:45:49,953 : INFO : global_step/sec: 7.72109\n",
            "2021-02-28 16:45:49,953 : INFO : examples/sec: 247.075\n",
            "2021-02-28 16:45:50,083 : INFO : global_step/sec: 7.6815\n",
            "2021-02-28 16:45:50,084 : INFO : examples/sec: 245.808\n",
            "2021-02-28 16:45:50,217 : INFO : global_step/sec: 7.46939\n",
            "2021-02-28 16:45:50,217 : INFO : examples/sec: 239.021\n",
            "2021-02-28 16:45:50,350 : INFO : global_step/sec: 7.50198\n",
            "2021-02-28 16:45:50,351 : INFO : examples/sec: 240.063\n",
            "2021-02-28 16:45:50,486 : INFO : loss = 0.000433132 (1.337 sec)\n",
            "2021-02-28 16:45:50,488 : INFO : global_step/sec: 7.22662\n",
            "2021-02-28 16:45:50,489 : INFO : examples/sec: 231.252\n",
            "2021-02-28 16:45:50,623 : INFO : global_step/sec: 7.43077\n",
            "2021-02-28 16:45:50,624 : INFO : examples/sec: 237.785\n",
            "2021-02-28 16:45:50,756 : INFO : global_step/sec: 7.48586\n",
            "2021-02-28 16:45:50,757 : INFO : examples/sec: 239.547\n",
            "2021-02-28 16:45:50,892 : INFO : global_step/sec: 7.35643\n",
            "2021-02-28 16:45:50,893 : INFO : examples/sec: 235.406\n",
            "2021-02-28 16:45:51,026 : INFO : global_step/sec: 7.46502\n",
            "2021-02-28 16:45:51,027 : INFO : examples/sec: 238.881\n",
            "2021-02-28 16:45:51,159 : INFO : global_step/sec: 7.52008\n",
            "2021-02-28 16:45:51,160 : INFO : examples/sec: 240.643\n",
            "2021-02-28 16:45:51,288 : INFO : global_step/sec: 7.74842\n",
            "2021-02-28 16:45:51,289 : INFO : examples/sec: 247.949\n",
            "2021-02-28 16:45:51,422 : INFO : global_step/sec: 7.46655\n",
            "2021-02-28 16:45:51,423 : INFO : examples/sec: 238.93\n",
            "2021-02-28 16:45:51,555 : INFO : global_step/sec: 7.53477\n",
            "2021-02-28 16:45:51,556 : INFO : examples/sec: 241.113\n",
            "2021-02-28 16:45:51,685 : INFO : global_step/sec: 7.71491\n",
            "2021-02-28 16:45:51,686 : INFO : examples/sec: 246.877\n",
            "2021-02-28 16:45:51,819 : INFO : loss = 0.2920336 (1.333 sec)\n",
            "2021-02-28 16:45:51,821 : INFO : global_step/sec: 7.32726\n",
            "2021-02-28 16:45:51,823 : INFO : examples/sec: 234.472\n",
            "2021-02-28 16:45:51,959 : INFO : global_step/sec: 7.25366\n",
            "2021-02-28 16:45:51,960 : INFO : examples/sec: 232.117\n",
            "2021-02-28 16:45:52,093 : INFO : global_step/sec: 7.45116\n",
            "2021-02-28 16:45:52,094 : INFO : examples/sec: 238.437\n",
            "2021-02-28 16:45:52,226 : INFO : global_step/sec: 7.5523\n",
            "2021-02-28 16:45:52,228 : INFO : examples/sec: 241.673\n",
            "2021-02-28 16:45:52,361 : INFO : global_step/sec: 7.38136\n",
            "2021-02-28 16:45:52,362 : INFO : examples/sec: 236.204\n",
            "2021-02-28 16:45:52,495 : INFO : global_step/sec: 7.48742\n",
            "2021-02-28 16:45:52,496 : INFO : examples/sec: 239.598\n",
            "2021-02-28 16:45:52,628 : INFO : global_step/sec: 7.50363\n",
            "2021-02-28 16:45:52,629 : INFO : examples/sec: 240.116\n",
            "2021-02-28 16:45:52,761 : INFO : global_step/sec: 7.54432\n",
            "2021-02-28 16:45:52,761 : INFO : examples/sec: 241.418\n",
            "2021-02-28 16:45:52,891 : INFO : global_step/sec: 7.68227\n",
            "2021-02-28 16:45:52,892 : INFO : examples/sec: 245.833\n",
            "2021-02-28 16:45:53,022 : INFO : global_step/sec: 7.63392\n",
            "2021-02-28 16:45:53,023 : INFO : examples/sec: 244.285\n",
            "2021-02-28 16:45:53,153 : INFO : loss = 0.00024227341 (1.334 sec)\n",
            "2021-02-28 16:45:53,155 : INFO : global_step/sec: 7.50898\n",
            "2021-02-28 16:45:53,158 : INFO : examples/sec: 240.287\n",
            "2021-02-28 16:45:53,288 : INFO : global_step/sec: 7.53347\n",
            "2021-02-28 16:45:53,288 : INFO : examples/sec: 241.071\n",
            "2021-02-28 16:45:53,421 : INFO : global_step/sec: 7.4812\n",
            "2021-02-28 16:45:53,422 : INFO : examples/sec: 239.398\n",
            "2021-02-28 16:45:53,550 : INFO : global_step/sec: 7.76125\n",
            "2021-02-28 16:45:53,551 : INFO : examples/sec: 248.36\n",
            "2021-02-28 16:45:53,685 : INFO : global_step/sec: 7.39796\n",
            "2021-02-28 16:45:53,687 : INFO : examples/sec: 236.735\n",
            "2021-02-28 16:45:53,816 : INFO : global_step/sec: 7.64728\n",
            "2021-02-28 16:45:53,817 : INFO : examples/sec: 244.713\n",
            "2021-02-28 16:45:53,953 : INFO : global_step/sec: 7.3179\n",
            "2021-02-28 16:45:53,953 : INFO : examples/sec: 234.173\n",
            "2021-02-28 16:45:54,083 : INFO : global_step/sec: 7.70195\n",
            "2021-02-28 16:45:54,083 : INFO : examples/sec: 246.462\n",
            "2021-02-28 16:45:54,216 : INFO : global_step/sec: 7.48026\n",
            "2021-02-28 16:45:54,217 : INFO : examples/sec: 239.368\n",
            "2021-02-28 16:45:54,346 : INFO : global_step/sec: 7.71539\n",
            "2021-02-28 16:45:54,347 : INFO : examples/sec: 246.893\n",
            "2021-02-28 16:45:54,480 : INFO : loss = 0.0075088344 (1.327 sec)\n",
            "2021-02-28 16:45:54,484 : INFO : global_step/sec: 7.24985\n",
            "2021-02-28 16:45:54,485 : INFO : examples/sec: 231.995\n",
            "2021-02-28 16:45:54,618 : INFO : global_step/sec: 7.45618\n",
            "2021-02-28 16:45:54,619 : INFO : examples/sec: 238.598\n",
            "2021-02-28 16:45:54,748 : INFO : global_step/sec: 7.70225\n",
            "2021-02-28 16:45:54,749 : INFO : examples/sec: 246.472\n",
            "2021-02-28 16:45:54,881 : INFO : global_step/sec: 7.48462\n",
            "2021-02-28 16:45:54,882 : INFO : examples/sec: 239.508\n",
            "2021-02-28 16:45:55,014 : INFO : global_step/sec: 7.5122\n",
            "2021-02-28 16:45:55,015 : INFO : examples/sec: 240.391\n",
            "2021-02-28 16:45:55,151 : INFO : global_step/sec: 7.34184\n",
            "2021-02-28 16:45:55,151 : INFO : examples/sec: 234.939\n",
            "2021-02-28 16:45:55,284 : INFO : global_step/sec: 7.48607\n",
            "2021-02-28 16:45:55,285 : INFO : examples/sec: 239.554\n",
            "2021-02-28 16:45:55,417 : INFO : global_step/sec: 7.54321\n",
            "2021-02-28 16:45:55,418 : INFO : examples/sec: 241.383\n",
            "2021-02-28 16:45:55,547 : INFO : global_step/sec: 7.65197\n",
            "2021-02-28 16:45:55,548 : INFO : examples/sec: 244.863\n",
            "2021-02-28 16:45:55,676 : INFO : global_step/sec: 7.75789\n",
            "2021-02-28 16:45:55,677 : INFO : examples/sec: 248.253\n",
            "2021-02-28 16:45:55,811 : INFO : loss = 0.0018532816 (1.330 sec)\n",
            "2021-02-28 16:45:55,814 : INFO : global_step/sec: 7.27473\n",
            "2021-02-28 16:45:55,815 : INFO : examples/sec: 232.791\n",
            "2021-02-28 16:45:55,947 : INFO : global_step/sec: 7.52913\n",
            "2021-02-28 16:45:55,947 : INFO : examples/sec: 240.932\n",
            "2021-02-28 16:45:56,081 : INFO : global_step/sec: 7.46359\n",
            "2021-02-28 16:45:56,081 : INFO : examples/sec: 238.835\n",
            "2021-02-28 16:45:56,210 : INFO : global_step/sec: 7.71223\n",
            "2021-02-28 16:45:56,211 : INFO : examples/sec: 246.791\n",
            "2021-02-28 16:45:56,342 : INFO : global_step/sec: 7.56738\n",
            "2021-02-28 16:45:56,343 : INFO : examples/sec: 242.156\n",
            "2021-02-28 16:45:56,483 : INFO : global_step/sec: 7.13464\n",
            "2021-02-28 16:45:56,483 : INFO : examples/sec: 228.308\n",
            "2021-02-28 16:45:56,613 : INFO : global_step/sec: 7.66905\n",
            "2021-02-28 16:45:56,614 : INFO : examples/sec: 245.41\n",
            "2021-02-28 16:45:56,743 : INFO : global_step/sec: 7.70612\n",
            "2021-02-28 16:45:56,744 : INFO : examples/sec: 246.596\n",
            "2021-02-28 16:45:56,874 : INFO : global_step/sec: 7.64573\n",
            "2021-02-28 16:45:56,874 : INFO : examples/sec: 244.663\n",
            "2021-02-28 16:45:57,008 : INFO : global_step/sec: 7.44988\n",
            "2021-02-28 16:45:57,009 : INFO : examples/sec: 238.396\n",
            "2021-02-28 16:45:57,140 : INFO : loss = 0.0010424389 (1.330 sec)\n",
            "2021-02-28 16:45:57,142 : INFO : global_step/sec: 7.44991\n",
            "2021-02-28 16:45:57,143 : INFO : examples/sec: 238.397\n",
            "2021-02-28 16:45:57,277 : INFO : global_step/sec: 7.39022\n",
            "2021-02-28 16:45:57,278 : INFO : examples/sec: 236.487\n",
            "2021-02-28 16:45:57,415 : INFO : global_step/sec: 7.28655\n",
            "2021-02-28 16:45:57,416 : INFO : examples/sec: 233.17\n",
            "2021-02-28 16:45:57,549 : INFO : global_step/sec: 7.42553\n",
            "2021-02-28 16:45:57,550 : INFO : examples/sec: 237.617\n",
            "2021-02-28 16:45:57,682 : INFO : global_step/sec: 7.51468\n",
            "2021-02-28 16:45:57,683 : INFO : examples/sec: 240.47\n",
            "2021-02-28 16:45:57,818 : INFO : global_step/sec: 7.35069\n",
            "2021-02-28 16:45:57,819 : INFO : examples/sec: 235.222\n",
            "2021-02-28 16:45:57,954 : INFO : global_step/sec: 7.36489\n",
            "2021-02-28 16:45:57,955 : INFO : examples/sec: 235.676\n",
            "2021-02-28 16:45:58,086 : INFO : global_step/sec: 7.60459\n",
            "2021-02-28 16:45:58,087 : INFO : examples/sec: 243.347\n",
            "2021-02-28 16:45:58,221 : INFO : global_step/sec: 7.38818\n",
            "2021-02-28 16:45:58,222 : INFO : examples/sec: 236.422\n",
            "2021-02-28 16:45:58,354 : INFO : global_step/sec: 7.52776\n",
            "2021-02-28 16:45:58,355 : INFO : examples/sec: 240.888\n",
            "2021-02-28 16:45:58,487 : INFO : loss = 0.007579807 (1.347 sec)\n",
            "2021-02-28 16:45:58,490 : INFO : global_step/sec: 7.32946\n",
            "2021-02-28 16:45:58,492 : INFO : examples/sec: 234.543\n",
            "2021-02-28 16:45:58,624 : INFO : global_step/sec: 7.46868\n",
            "2021-02-28 16:45:58,625 : INFO : examples/sec: 238.998\n",
            "2021-02-28 16:45:58,756 : INFO : global_step/sec: 7.56901\n",
            "2021-02-28 16:45:58,757 : INFO : examples/sec: 242.208\n",
            "2021-02-28 16:45:58,888 : INFO : global_step/sec: 7.58041\n",
            "2021-02-28 16:45:58,889 : INFO : examples/sec: 242.573\n",
            "2021-02-28 16:45:59,022 : INFO : global_step/sec: 7.47107\n",
            "2021-02-28 16:45:59,023 : INFO : examples/sec: 239.074\n",
            "2021-02-28 16:45:59,154 : INFO : global_step/sec: 7.56247\n",
            "2021-02-28 16:45:59,155 : INFO : examples/sec: 241.999\n",
            "2021-02-28 16:45:59,285 : INFO : global_step/sec: 7.66382\n",
            "2021-02-28 16:45:59,285 : INFO : examples/sec: 245.242\n",
            "2021-02-28 16:45:59,416 : INFO : global_step/sec: 7.61352\n",
            "2021-02-28 16:45:59,417 : INFO : examples/sec: 243.633\n",
            "2021-02-28 16:45:59,551 : INFO : global_step/sec: 7.41823\n",
            "2021-02-28 16:45:59,552 : INFO : examples/sec: 237.383\n",
            "2021-02-28 16:45:59,684 : INFO : global_step/sec: 7.49948\n",
            "2021-02-28 16:45:59,685 : INFO : examples/sec: 239.983\n",
            "2021-02-28 16:45:59,817 : INFO : loss = 0.00021591457 (1.330 sec)\n",
            "2021-02-28 16:45:59,819 : INFO : global_step/sec: 7.41316\n",
            "2021-02-28 16:45:59,821 : INFO : examples/sec: 237.221\n",
            "2021-02-28 16:45:59,957 : INFO : global_step/sec: 7.25031\n",
            "2021-02-28 16:45:59,958 : INFO : examples/sec: 232.01\n",
            "2021-02-28 16:46:00,089 : INFO : global_step/sec: 7.57806\n",
            "2021-02-28 16:46:00,090 : INFO : examples/sec: 242.498\n",
            "2021-02-28 16:46:00,219 : INFO : global_step/sec: 7.67912\n",
            "2021-02-28 16:46:00,220 : INFO : examples/sec: 245.732\n",
            "2021-02-28 16:46:00,353 : INFO : global_step/sec: 7.4861\n",
            "2021-02-28 16:46:00,354 : INFO : examples/sec: 239.555\n",
            "2021-02-28 16:46:00,483 : INFO : global_step/sec: 7.65743\n",
            "2021-02-28 16:46:00,484 : INFO : examples/sec: 245.038\n",
            "2021-02-28 16:46:00,614 : INFO : global_step/sec: 7.63278\n",
            "2021-02-28 16:46:00,615 : INFO : examples/sec: 244.249\n",
            "2021-02-28 16:46:00,746 : INFO : global_step/sec: 7.62556\n",
            "2021-02-28 16:46:00,746 : INFO : examples/sec: 244.018\n",
            "2021-02-28 16:46:00,878 : INFO : global_step/sec: 7.54553\n",
            "2021-02-28 16:46:00,879 : INFO : examples/sec: 241.457\n",
            "2021-02-28 16:46:01,010 : INFO : global_step/sec: 7.57521\n",
            "2021-02-28 16:46:01,011 : INFO : examples/sec: 242.407\n",
            "2021-02-28 16:46:01,140 : INFO : loss = 0.0002156453 (1.323 sec)\n",
            "2021-02-28 16:46:01,144 : INFO : global_step/sec: 7.45216\n",
            "2021-02-28 16:46:01,145 : INFO : examples/sec: 238.469\n",
            "2021-02-28 16:46:01,279 : INFO : global_step/sec: 7.44661\n",
            "2021-02-28 16:46:01,279 : INFO : examples/sec: 238.292\n",
            "2021-02-28 16:46:01,410 : INFO : global_step/sec: 7.59668\n",
            "2021-02-28 16:46:01,411 : INFO : examples/sec: 243.094\n",
            "2021-02-28 16:46:01,547 : INFO : global_step/sec: 7.32838\n",
            "2021-02-28 16:46:01,547 : INFO : examples/sec: 234.508\n",
            "2021-02-28 16:46:01,682 : INFO : global_step/sec: 7.37668\n",
            "2021-02-28 16:46:01,683 : INFO : examples/sec: 236.054\n",
            "2021-02-28 16:46:01,822 : INFO : global_step/sec: 7.15888\n",
            "2021-02-28 16:46:01,823 : INFO : examples/sec: 229.084\n",
            "2021-02-28 16:46:01,956 : INFO : global_step/sec: 7.44032\n",
            "2021-02-28 16:46:01,957 : INFO : examples/sec: 238.09\n",
            "2021-02-28 16:46:02,088 : INFO : global_step/sec: 7.56834\n",
            "2021-02-28 16:46:02,089 : INFO : examples/sec: 242.187\n",
            "2021-02-28 16:46:02,225 : INFO : global_step/sec: 7.34371\n",
            "2021-02-28 16:46:02,225 : INFO : examples/sec: 234.999\n",
            "2021-02-28 16:46:02,359 : INFO : Saving checkpoints for 700 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:46:18,198 : INFO : global_step/sec: 0.0626037\n",
            "2021-02-28 16:46:18,200 : INFO : examples/sec: 2.00332\n",
            "2021-02-28 16:46:18,330 : INFO : loss = 0.0031254627 (17.190 sec)\n",
            "2021-02-28 16:46:18,332 : INFO : global_step/sec: 7.4776\n",
            "2021-02-28 16:46:18,333 : INFO : examples/sec: 239.283\n",
            "2021-02-28 16:46:18,465 : INFO : global_step/sec: 7.48631\n",
            "2021-02-28 16:46:18,466 : INFO : examples/sec: 239.562\n",
            "2021-02-28 16:46:18,596 : INFO : global_step/sec: 7.64465\n",
            "2021-02-28 16:46:18,597 : INFO : examples/sec: 244.629\n",
            "2021-02-28 16:46:18,731 : INFO : global_step/sec: 7.40445\n",
            "2021-02-28 16:46:18,732 : INFO : examples/sec: 236.942\n",
            "2021-02-28 16:46:18,862 : INFO : global_step/sec: 7.62738\n",
            "2021-02-28 16:46:18,864 : INFO : examples/sec: 244.076\n",
            "2021-02-28 16:46:18,996 : INFO : global_step/sec: 7.46594\n",
            "2021-02-28 16:46:18,997 : INFO : examples/sec: 238.91\n",
            "2021-02-28 16:46:19,127 : INFO : global_step/sec: 7.62469\n",
            "2021-02-28 16:46:19,128 : INFO : examples/sec: 243.99\n",
            "2021-02-28 16:46:19,263 : INFO : global_step/sec: 7.36704\n",
            "2021-02-28 16:46:19,264 : INFO : examples/sec: 235.745\n",
            "2021-02-28 16:46:19,397 : INFO : global_step/sec: 7.47347\n",
            "2021-02-28 16:46:19,398 : INFO : examples/sec: 239.151\n",
            "2021-02-28 16:46:19,529 : INFO : global_step/sec: 7.58061\n",
            "2021-02-28 16:46:19,530 : INFO : examples/sec: 242.579\n",
            "2021-02-28 16:46:19,658 : INFO : loss = 0.00021600057 (1.328 sec)\n",
            "2021-02-28 16:46:19,659 : INFO : global_step/sec: 7.67071\n",
            "2021-02-28 16:46:19,661 : INFO : examples/sec: 245.463\n",
            "2021-02-28 16:46:19,796 : INFO : global_step/sec: 7.31319\n",
            "2021-02-28 16:46:19,797 : INFO : examples/sec: 234.022\n",
            "2021-02-28 16:46:19,931 : INFO : global_step/sec: 7.38853\n",
            "2021-02-28 16:46:19,933 : INFO : examples/sec: 236.433\n",
            "2021-02-28 16:46:20,067 : INFO : global_step/sec: 7.40069\n",
            "2021-02-28 16:46:20,067 : INFO : examples/sec: 236.822\n",
            "2021-02-28 16:46:20,201 : INFO : global_step/sec: 7.41422\n",
            "2021-02-28 16:46:20,202 : INFO : examples/sec: 237.255\n",
            "2021-02-28 16:46:20,337 : INFO : global_step/sec: 7.38383\n",
            "2021-02-28 16:46:20,338 : INFO : examples/sec: 236.283\n",
            "2021-02-28 16:46:20,471 : INFO : global_step/sec: 7.44591\n",
            "2021-02-28 16:46:20,472 : INFO : examples/sec: 238.269\n",
            "2021-02-28 16:46:20,606 : INFO : global_step/sec: 7.428\n",
            "2021-02-28 16:46:20,607 : INFO : examples/sec: 237.696\n",
            "2021-02-28 16:46:20,739 : INFO : global_step/sec: 7.50607\n",
            "2021-02-28 16:46:20,740 : INFO : examples/sec: 240.194\n",
            "2021-02-28 16:46:20,874 : INFO : global_step/sec: 7.38559\n",
            "2021-02-28 16:46:20,875 : INFO : examples/sec: 236.339\n",
            "2021-02-28 16:46:21,010 : INFO : loss = 0.00059995207 (1.352 sec)\n",
            "2021-02-28 16:46:21,011 : INFO : global_step/sec: 7.31009\n",
            "2021-02-28 16:46:21,016 : INFO : examples/sec: 233.923\n",
            "2021-02-28 16:46:21,149 : INFO : global_step/sec: 7.23847\n",
            "2021-02-28 16:46:21,150 : INFO : examples/sec: 231.631\n",
            "2021-02-28 16:46:21,281 : INFO : global_step/sec: 7.59257\n",
            "2021-02-28 16:46:21,282 : INFO : examples/sec: 242.962\n",
            "2021-02-28 16:46:21,410 : INFO : global_step/sec: 7.7329\n",
            "2021-02-28 16:46:21,411 : INFO : examples/sec: 247.453\n",
            "2021-02-28 16:46:21,540 : INFO : global_step/sec: 7.69659\n",
            "2021-02-28 16:46:21,541 : INFO : examples/sec: 246.291\n",
            "2021-02-28 16:46:21,676 : INFO : global_step/sec: 7.35929\n",
            "2021-02-28 16:46:21,677 : INFO : examples/sec: 235.497\n",
            "2021-02-28 16:46:21,809 : INFO : global_step/sec: 7.5299\n",
            "2021-02-28 16:46:21,810 : INFO : examples/sec: 240.957\n",
            "2021-02-28 16:46:21,940 : INFO : global_step/sec: 7.65621\n",
            "2021-02-28 16:46:21,940 : INFO : examples/sec: 244.999\n",
            "2021-02-28 16:46:22,073 : INFO : global_step/sec: 7.50736\n",
            "2021-02-28 16:46:22,074 : INFO : examples/sec: 240.236\n",
            "2021-02-28 16:46:22,204 : INFO : global_step/sec: 7.60243\n",
            "2021-02-28 16:46:22,205 : INFO : examples/sec: 243.278\n",
            "2021-02-28 16:46:22,337 : INFO : loss = 0.0004791515 (1.328 sec)\n",
            "2021-02-28 16:46:22,340 : INFO : global_step/sec: 7.37053\n",
            "2021-02-28 16:46:22,343 : INFO : examples/sec: 235.857\n",
            "2021-02-28 16:46:22,475 : INFO : global_step/sec: 7.40928\n",
            "2021-02-28 16:46:22,476 : INFO : examples/sec: 237.097\n",
            "2021-02-28 16:46:22,608 : INFO : global_step/sec: 7.53055\n",
            "2021-02-28 16:46:22,609 : INFO : examples/sec: 240.978\n",
            "2021-02-28 16:46:22,741 : INFO : global_step/sec: 7.50083\n",
            "2021-02-28 16:46:22,742 : INFO : examples/sec: 240.026\n",
            "2021-02-28 16:46:22,874 : INFO : global_step/sec: 7.53924\n",
            "2021-02-28 16:46:22,875 : INFO : examples/sec: 241.256\n",
            "2021-02-28 16:46:23,009 : INFO : global_step/sec: 7.41755\n",
            "2021-02-28 16:46:23,009 : INFO : examples/sec: 237.362\n",
            "2021-02-28 16:46:23,142 : INFO : global_step/sec: 7.49624\n",
            "2021-02-28 16:46:23,149 : INFO : examples/sec: 239.88\n",
            "2021-02-28 16:46:23,279 : INFO : global_step/sec: 7.30167\n",
            "2021-02-28 16:46:23,280 : INFO : examples/sec: 233.653\n",
            "2021-02-28 16:46:23,409 : INFO : global_step/sec: 7.67225\n",
            "2021-02-28 16:46:23,410 : INFO : examples/sec: 245.512\n",
            "2021-02-28 16:46:23,544 : INFO : global_step/sec: 7.44042\n",
            "2021-02-28 16:46:23,544 : INFO : examples/sec: 238.093\n",
            "2021-02-28 16:46:23,673 : INFO : loss = 0.00021406618 (1.335 sec)\n",
            "2021-02-28 16:46:23,675 : INFO : global_step/sec: 7.58958\n",
            "2021-02-28 16:46:23,683 : INFO : examples/sec: 242.866\n",
            "2021-02-28 16:46:23,815 : INFO : global_step/sec: 7.15133\n",
            "2021-02-28 16:46:23,817 : INFO : examples/sec: 228.842\n",
            "2021-02-28 16:46:23,950 : INFO : global_step/sec: 7.42883\n",
            "2021-02-28 16:46:23,951 : INFO : examples/sec: 237.723\n",
            "2021-02-28 16:46:24,080 : INFO : global_step/sec: 7.68024\n",
            "2021-02-28 16:46:24,081 : INFO : examples/sec: 245.768\n",
            "2021-02-28 16:46:24,212 : INFO : global_step/sec: 7.57907\n",
            "2021-02-28 16:46:24,213 : INFO : examples/sec: 242.53\n",
            "2021-02-28 16:46:24,346 : INFO : global_step/sec: 7.48077\n",
            "2021-02-28 16:46:24,346 : INFO : examples/sec: 239.385\n",
            "2021-02-28 16:46:24,477 : INFO : global_step/sec: 7.58637\n",
            "2021-02-28 16:46:24,479 : INFO : examples/sec: 242.764\n",
            "2021-02-28 16:46:24,610 : INFO : global_step/sec: 7.52016\n",
            "2021-02-28 16:46:24,611 : INFO : examples/sec: 240.645\n",
            "2021-02-28 16:46:24,743 : INFO : global_step/sec: 7.54112\n",
            "2021-02-28 16:46:24,744 : INFO : examples/sec: 241.316\n",
            "2021-02-28 16:46:24,877 : INFO : global_step/sec: 7.45262\n",
            "2021-02-28 16:46:24,879 : INFO : examples/sec: 238.484\n",
            "2021-02-28 16:46:25,008 : INFO : loss = 0.0068273875 (1.335 sec)\n",
            "2021-02-28 16:46:25,010 : INFO : global_step/sec: 7.54245\n",
            "2021-02-28 16:46:25,012 : INFO : examples/sec: 241.358\n",
            "2021-02-28 16:46:25,147 : INFO : global_step/sec: 7.30439\n",
            "2021-02-28 16:46:25,147 : INFO : examples/sec: 233.74\n",
            "2021-02-28 16:46:25,279 : INFO : global_step/sec: 7.53271\n",
            "2021-02-28 16:46:25,280 : INFO : examples/sec: 241.047\n",
            "2021-02-28 16:46:25,411 : INFO : global_step/sec: 7.60656\n",
            "2021-02-28 16:46:25,412 : INFO : examples/sec: 243.41\n",
            "2021-02-28 16:46:25,543 : INFO : global_step/sec: 7.57673\n",
            "2021-02-28 16:46:25,544 : INFO : examples/sec: 242.455\n",
            "2021-02-28 16:46:25,673 : INFO : global_step/sec: 7.67304\n",
            "2021-02-28 16:46:25,674 : INFO : examples/sec: 245.537\n",
            "2021-02-28 16:46:25,807 : INFO : global_step/sec: 7.50499\n",
            "2021-02-28 16:46:25,807 : INFO : examples/sec: 240.16\n",
            "2021-02-28 16:46:25,941 : INFO : global_step/sec: 7.40845\n",
            "2021-02-28 16:46:25,944 : INFO : examples/sec: 237.071\n",
            "2021-02-28 16:46:26,075 : INFO : global_step/sec: 7.50538\n",
            "2021-02-28 16:46:26,075 : INFO : examples/sec: 240.172\n",
            "2021-02-28 16:46:26,210 : INFO : global_step/sec: 7.37093\n",
            "2021-02-28 16:46:26,211 : INFO : examples/sec: 235.87\n",
            "2021-02-28 16:46:26,339 : INFO : loss = 0.00021260796 (1.331 sec)\n",
            "2021-02-28 16:46:26,342 : INFO : global_step/sec: 7.60702\n",
            "2021-02-28 16:46:26,343 : INFO : examples/sec: 243.425\n",
            "2021-02-28 16:46:26,476 : INFO : global_step/sec: 7.44789\n",
            "2021-02-28 16:46:26,477 : INFO : examples/sec: 238.333\n",
            "2021-02-28 16:46:26,606 : INFO : global_step/sec: 7.69984\n",
            "2021-02-28 16:46:26,607 : INFO : examples/sec: 246.395\n",
            "2021-02-28 16:46:26,740 : INFO : global_step/sec: 7.4754\n",
            "2021-02-28 16:46:26,741 : INFO : examples/sec: 239.213\n",
            "2021-02-28 16:46:26,873 : INFO : global_step/sec: 7.48149\n",
            "2021-02-28 16:46:26,875 : INFO : examples/sec: 239.408\n",
            "2021-02-28 16:46:27,009 : INFO : global_step/sec: 7.39101\n",
            "2021-02-28 16:46:27,010 : INFO : examples/sec: 236.512\n",
            "2021-02-28 16:46:27,141 : INFO : global_step/sec: 7.56301\n",
            "2021-02-28 16:46:27,142 : INFO : examples/sec: 242.016\n",
            "2021-02-28 16:46:27,272 : INFO : global_step/sec: 7.65767\n",
            "2021-02-28 16:46:27,272 : INFO : examples/sec: 245.045\n",
            "2021-02-28 16:46:27,401 : INFO : global_step/sec: 7.71838\n",
            "2021-02-28 16:46:27,402 : INFO : examples/sec: 246.988\n",
            "2021-02-28 16:46:27,533 : INFO : global_step/sec: 7.56138\n",
            "2021-02-28 16:46:27,536 : INFO : examples/sec: 241.964\n",
            "2021-02-28 16:46:27,667 : INFO : loss = 0.00018036398 (1.328 sec)\n",
            "2021-02-28 16:46:27,670 : INFO : global_step/sec: 7.32452\n",
            "2021-02-28 16:46:27,671 : INFO : examples/sec: 234.385\n",
            "2021-02-28 16:46:27,801 : INFO : global_step/sec: 7.65468\n",
            "2021-02-28 16:46:27,801 : INFO : examples/sec: 244.95\n",
            "2021-02-28 16:46:27,933 : INFO : global_step/sec: 7.57592\n",
            "2021-02-28 16:46:27,933 : INFO : examples/sec: 242.43\n",
            "2021-02-28 16:46:28,065 : INFO : global_step/sec: 7.55016\n",
            "2021-02-28 16:46:28,066 : INFO : examples/sec: 241.605\n",
            "2021-02-28 16:46:28,198 : INFO : global_step/sec: 7.49367\n",
            "2021-02-28 16:46:28,199 : INFO : examples/sec: 239.797\n",
            "2021-02-28 16:46:28,335 : INFO : global_step/sec: 7.2967\n",
            "2021-02-28 16:46:28,336 : INFO : examples/sec: 233.494\n",
            "2021-02-28 16:46:28,465 : INFO : global_step/sec: 7.73546\n",
            "2021-02-28 16:46:28,466 : INFO : examples/sec: 247.535\n",
            "2021-02-28 16:46:28,595 : INFO : global_step/sec: 7.67974\n",
            "2021-02-28 16:46:28,596 : INFO : examples/sec: 245.752\n",
            "2021-02-28 16:46:28,726 : INFO : global_step/sec: 7.61742\n",
            "2021-02-28 16:46:28,727 : INFO : examples/sec: 243.757\n",
            "2021-02-28 16:46:28,865 : INFO : global_step/sec: 7.19218\n",
            "2021-02-28 16:46:28,866 : INFO : examples/sec: 230.15\n",
            "2021-02-28 16:46:29,001 : INFO : loss = 0.001827226 (1.334 sec)\n",
            "2021-02-28 16:46:29,003 : INFO : global_step/sec: 7.27967\n",
            "2021-02-28 16:46:29,005 : INFO : examples/sec: 232.949\n",
            "2021-02-28 16:46:29,135 : INFO : global_step/sec: 7.57413\n",
            "2021-02-28 16:46:29,135 : INFO : examples/sec: 242.372\n",
            "2021-02-28 16:46:29,266 : INFO : global_step/sec: 7.61255\n",
            "2021-02-28 16:46:29,267 : INFO : examples/sec: 243.602\n",
            "2021-02-28 16:46:29,401 : INFO : global_step/sec: 7.38655\n",
            "2021-02-28 16:46:29,402 : INFO : examples/sec: 236.37\n",
            "2021-02-28 16:46:29,532 : INFO : global_step/sec: 7.63692\n",
            "2021-02-28 16:46:29,533 : INFO : examples/sec: 244.381\n",
            "2021-02-28 16:46:29,667 : INFO : global_step/sec: 7.44858\n",
            "2021-02-28 16:46:29,667 : INFO : examples/sec: 238.355\n",
            "2021-02-28 16:46:29,797 : INFO : global_step/sec: 7.68821\n",
            "2021-02-28 16:46:29,799 : INFO : examples/sec: 246.023\n",
            "2021-02-28 16:46:29,930 : INFO : global_step/sec: 7.52306\n",
            "2021-02-28 16:46:29,931 : INFO : examples/sec: 240.738\n",
            "2021-02-28 16:46:30,066 : INFO : global_step/sec: 7.32479\n",
            "2021-02-28 16:46:30,067 : INFO : examples/sec: 234.393\n",
            "2021-02-28 16:46:30,196 : INFO : global_step/sec: 7.69613\n",
            "2021-02-28 16:46:30,197 : INFO : examples/sec: 246.276\n",
            "2021-02-28 16:46:30,333 : INFO : loss = 0.0005619265 (1.332 sec)\n",
            "2021-02-28 16:46:30,337 : INFO : global_step/sec: 7.10954\n",
            "2021-02-28 16:46:30,339 : INFO : examples/sec: 227.505\n",
            "2021-02-28 16:46:30,475 : INFO : global_step/sec: 7.22848\n",
            "2021-02-28 16:46:30,476 : INFO : examples/sec: 231.311\n",
            "2021-02-28 16:46:30,612 : INFO : global_step/sec: 7.32404\n",
            "2021-02-28 16:46:30,612 : INFO : examples/sec: 234.369\n",
            "2021-02-28 16:46:30,747 : INFO : global_step/sec: 7.40266\n",
            "2021-02-28 16:46:30,747 : INFO : examples/sec: 236.885\n",
            "2021-02-28 16:46:30,886 : INFO : global_step/sec: 7.17262\n",
            "2021-02-28 16:46:30,887 : INFO : examples/sec: 229.524\n",
            "2021-02-28 16:46:31,020 : INFO : global_step/sec: 7.47629\n",
            "2021-02-28 16:46:31,021 : INFO : examples/sec: 239.241\n",
            "2021-02-28 16:46:31,157 : INFO : global_step/sec: 7.28354\n",
            "2021-02-28 16:46:31,158 : INFO : examples/sec: 233.073\n",
            "2021-02-28 16:46:31,290 : INFO : global_step/sec: 7.53144\n",
            "2021-02-28 16:46:31,291 : INFO : examples/sec: 241.006\n",
            "2021-02-28 16:46:31,426 : INFO : global_step/sec: 7.37131\n",
            "2021-02-28 16:46:31,426 : INFO : examples/sec: 235.882\n",
            "2021-02-28 16:46:31,556 : INFO : Saving checkpoints for 800 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:46:48,997 : INFO : global_step/sec: 0.0569114\n",
            "2021-02-28 16:46:48,998 : INFO : examples/sec: 1.82117\n",
            "2021-02-28 16:46:49,139 : INFO : loss = 0.00040819094 (18.806 sec)\n",
            "2021-02-28 16:46:49,142 : INFO : global_step/sec: 6.89482\n",
            "2021-02-28 16:46:49,143 : INFO : examples/sec: 220.634\n",
            "2021-02-28 16:46:49,279 : INFO : global_step/sec: 7.28388\n",
            "2021-02-28 16:46:49,280 : INFO : examples/sec: 233.084\n",
            "2021-02-28 16:46:49,419 : INFO : global_step/sec: 7.14922\n",
            "2021-02-28 16:46:49,420 : INFO : examples/sec: 228.775\n",
            "2021-02-28 16:46:49,549 : INFO : global_step/sec: 7.68703\n",
            "2021-02-28 16:46:49,550 : INFO : examples/sec: 245.985\n",
            "2021-02-28 16:46:49,683 : INFO : global_step/sec: 7.48418\n",
            "2021-02-28 16:46:49,684 : INFO : examples/sec: 239.494\n",
            "2021-02-28 16:46:49,816 : INFO : global_step/sec: 7.47017\n",
            "2021-02-28 16:46:49,817 : INFO : examples/sec: 239.045\n",
            "2021-02-28 16:46:49,951 : INFO : global_step/sec: 7.45909\n",
            "2021-02-28 16:46:49,951 : INFO : examples/sec: 238.691\n",
            "2021-02-28 16:46:50,087 : INFO : global_step/sec: 7.35246\n",
            "2021-02-28 16:46:50,088 : INFO : examples/sec: 235.279\n",
            "2021-02-28 16:46:50,221 : INFO : global_step/sec: 7.44504\n",
            "2021-02-28 16:46:50,222 : INFO : examples/sec: 238.241\n",
            "2021-02-28 16:46:50,352 : INFO : global_step/sec: 7.63511\n",
            "2021-02-28 16:46:50,353 : INFO : examples/sec: 244.324\n",
            "2021-02-28 16:46:50,482 : INFO : loss = 0.00060907623 (1.343 sec)\n",
            "2021-02-28 16:46:50,484 : INFO : global_step/sec: 7.5907\n",
            "2021-02-28 16:46:50,485 : INFO : examples/sec: 242.903\n",
            "2021-02-28 16:46:50,624 : INFO : global_step/sec: 7.1184\n",
            "2021-02-28 16:46:50,625 : INFO : examples/sec: 227.789\n",
            "2021-02-28 16:46:50,756 : INFO : global_step/sec: 7.57492\n",
            "2021-02-28 16:46:50,757 : INFO : examples/sec: 242.398\n",
            "2021-02-28 16:46:50,890 : INFO : global_step/sec: 7.45112\n",
            "2021-02-28 16:46:50,891 : INFO : examples/sec: 238.436\n",
            "2021-02-28 16:46:51,021 : INFO : global_step/sec: 7.64598\n",
            "2021-02-28 16:46:51,022 : INFO : examples/sec: 244.671\n",
            "2021-02-28 16:46:51,155 : INFO : global_step/sec: 7.47653\n",
            "2021-02-28 16:46:51,156 : INFO : examples/sec: 239.249\n",
            "2021-02-28 16:46:51,287 : INFO : global_step/sec: 7.58781\n",
            "2021-02-28 16:46:51,287 : INFO : examples/sec: 242.81\n",
            "2021-02-28 16:46:51,421 : INFO : global_step/sec: 7.44443\n",
            "2021-02-28 16:46:51,422 : INFO : examples/sec: 238.222\n",
            "2021-02-28 16:46:51,552 : INFO : global_step/sec: 7.64594\n",
            "2021-02-28 16:46:51,552 : INFO : examples/sec: 244.67\n",
            "2021-02-28 16:46:51,682 : INFO : global_step/sec: 7.68851\n",
            "2021-02-28 16:46:51,683 : INFO : examples/sec: 246.032\n",
            "2021-02-28 16:46:51,813 : INFO : loss = 0.0001881554 (1.331 sec)\n",
            "2021-02-28 16:46:51,816 : INFO : global_step/sec: 7.43856\n",
            "2021-02-28 16:46:51,818 : INFO : examples/sec: 238.034\n",
            "2021-02-28 16:46:51,954 : INFO : global_step/sec: 7.24022\n",
            "2021-02-28 16:46:51,955 : INFO : examples/sec: 231.687\n",
            "2021-02-28 16:46:52,086 : INFO : global_step/sec: 7.58039\n",
            "2021-02-28 16:46:52,087 : INFO : examples/sec: 242.572\n",
            "2021-02-28 16:46:52,223 : INFO : global_step/sec: 7.33231\n",
            "2021-02-28 16:46:52,224 : INFO : examples/sec: 234.634\n",
            "2021-02-28 16:46:52,363 : INFO : global_step/sec: 7.13919\n",
            "2021-02-28 16:46:52,364 : INFO : examples/sec: 228.454\n",
            "2021-02-28 16:46:52,499 : INFO : global_step/sec: 7.3181\n",
            "2021-02-28 16:46:52,500 : INFO : examples/sec: 234.179\n",
            "2021-02-28 16:46:52,634 : INFO : global_step/sec: 7.45472\n",
            "2021-02-28 16:46:52,634 : INFO : examples/sec: 238.551\n",
            "2021-02-28 16:46:52,768 : INFO : global_step/sec: 7.46132\n",
            "2021-02-28 16:46:52,768 : INFO : examples/sec: 238.762\n",
            "2021-02-28 16:46:52,901 : INFO : global_step/sec: 7.47685\n",
            "2021-02-28 16:46:52,902 : INFO : examples/sec: 239.259\n",
            "2021-02-28 16:46:53,036 : INFO : global_step/sec: 7.42637\n",
            "2021-02-28 16:46:53,037 : INFO : examples/sec: 237.644\n",
            "2021-02-28 16:46:53,169 : INFO : loss = 0.0058719655 (1.356 sec)\n",
            "2021-02-28 16:46:53,172 : INFO : global_step/sec: 7.35131\n",
            "2021-02-28 16:46:53,177 : INFO : examples/sec: 235.242\n",
            "2021-02-28 16:46:53,311 : INFO : global_step/sec: 7.19773\n",
            "2021-02-28 16:46:53,312 : INFO : examples/sec: 230.327\n",
            "2021-02-28 16:46:53,446 : INFO : global_step/sec: 7.39135\n",
            "2021-02-28 16:46:53,447 : INFO : examples/sec: 236.523\n",
            "2021-02-28 16:46:53,581 : INFO : global_step/sec: 7.43916\n",
            "2021-02-28 16:46:53,582 : INFO : examples/sec: 238.053\n",
            "2021-02-28 16:46:53,714 : INFO : global_step/sec: 7.47399\n",
            "2021-02-28 16:46:53,715 : INFO : examples/sec: 239.168\n",
            "2021-02-28 16:46:53,844 : INFO : global_step/sec: 7.73144\n",
            "2021-02-28 16:46:53,845 : INFO : examples/sec: 247.406\n",
            "2021-02-28 16:46:53,980 : INFO : global_step/sec: 7.35851\n",
            "2021-02-28 16:46:53,980 : INFO : examples/sec: 235.472\n",
            "2021-02-28 16:46:54,112 : INFO : global_step/sec: 7.54781\n",
            "2021-02-28 16:46:54,113 : INFO : examples/sec: 241.53\n",
            "2021-02-28 16:46:54,246 : INFO : global_step/sec: 7.46784\n",
            "2021-02-28 16:46:54,247 : INFO : examples/sec: 238.971\n",
            "2021-02-28 16:46:54,377 : INFO : global_step/sec: 7.62465\n",
            "2021-02-28 16:46:54,378 : INFO : examples/sec: 243.989\n",
            "2021-02-28 16:46:54,507 : INFO : loss = 0.00055539556 (1.338 sec)\n",
            "2021-02-28 16:46:54,509 : INFO : global_step/sec: 7.57665\n",
            "2021-02-28 16:46:54,511 : INFO : examples/sec: 242.453\n",
            "2021-02-28 16:46:54,645 : INFO : global_step/sec: 7.38199\n",
            "2021-02-28 16:46:54,646 : INFO : examples/sec: 236.224\n",
            "2021-02-28 16:46:54,783 : INFO : global_step/sec: 7.23568\n",
            "2021-02-28 16:46:54,784 : INFO : examples/sec: 231.542\n",
            "2021-02-28 16:46:54,917 : INFO : global_step/sec: 7.45785\n",
            "2021-02-28 16:46:54,918 : INFO : examples/sec: 238.651\n",
            "2021-02-28 16:46:55,048 : INFO : global_step/sec: 7.65408\n",
            "2021-02-28 16:46:55,048 : INFO : examples/sec: 244.93\n",
            "2021-02-28 16:46:55,182 : INFO : global_step/sec: 7.44812\n",
            "2021-02-28 16:46:55,185 : INFO : examples/sec: 238.34\n",
            "2021-02-28 16:46:55,315 : INFO : global_step/sec: 7.50179\n",
            "2021-02-28 16:46:55,316 : INFO : examples/sec: 240.057\n",
            "2021-02-28 16:46:55,450 : INFO : global_step/sec: 7.43046\n",
            "2021-02-28 16:46:55,451 : INFO : examples/sec: 237.775\n",
            "2021-02-28 16:46:55,579 : INFO : global_step/sec: 7.71722\n",
            "2021-02-28 16:46:55,580 : INFO : examples/sec: 246.951\n",
            "2021-02-28 16:46:55,709 : INFO : global_step/sec: 7.70256\n",
            "2021-02-28 16:46:55,710 : INFO : examples/sec: 246.482\n",
            "2021-02-28 16:46:55,840 : INFO : loss = 0.00018549946 (1.334 sec)\n",
            "2021-02-28 16:46:55,843 : INFO : global_step/sec: 7.44994\n",
            "2021-02-28 16:46:55,844 : INFO : examples/sec: 238.398\n",
            "2021-02-28 16:46:55,979 : INFO : global_step/sec: 7.36942\n",
            "2021-02-28 16:46:55,980 : INFO : examples/sec: 235.821\n",
            "2021-02-28 16:46:56,112 : INFO : global_step/sec: 7.52761\n",
            "2021-02-28 16:46:56,115 : INFO : examples/sec: 240.884\n",
            "2021-02-28 16:46:56,248 : INFO : global_step/sec: 7.33552\n",
            "2021-02-28 16:46:56,249 : INFO : examples/sec: 234.737\n",
            "2021-02-28 16:46:56,385 : INFO : global_step/sec: 7.30065\n",
            "2021-02-28 16:46:56,386 : INFO : examples/sec: 233.621\n",
            "2021-02-28 16:46:56,518 : INFO : global_step/sec: 7.53948\n",
            "2021-02-28 16:46:56,519 : INFO : examples/sec: 241.263\n",
            "2021-02-28 16:46:56,651 : INFO : global_step/sec: 7.49407\n",
            "2021-02-28 16:46:56,652 : INFO : examples/sec: 239.81\n",
            "2021-02-28 16:46:56,788 : INFO : global_step/sec: 7.32991\n",
            "2021-02-28 16:46:56,789 : INFO : examples/sec: 234.557\n",
            "2021-02-28 16:46:56,927 : INFO : global_step/sec: 7.16036\n",
            "2021-02-28 16:46:56,928 : INFO : examples/sec: 229.132\n",
            "2021-02-28 16:46:57,061 : INFO : global_step/sec: 7.49028\n",
            "2021-02-28 16:46:57,062 : INFO : examples/sec: 239.689\n",
            "2021-02-28 16:46:57,195 : INFO : loss = 0.0027560657 (1.354 sec)\n",
            "2021-02-28 16:46:57,196 : INFO : global_step/sec: 7.3795\n",
            "2021-02-28 16:46:57,198 : INFO : examples/sec: 236.144\n",
            "2021-02-28 16:46:57,333 : INFO : global_step/sec: 7.33479\n",
            "2021-02-28 16:46:57,333 : INFO : examples/sec: 234.713\n",
            "2021-02-28 16:46:57,463 : INFO : global_step/sec: 7.66424\n",
            "2021-02-28 16:46:57,464 : INFO : examples/sec: 245.256\n",
            "2021-02-28 16:46:57,600 : INFO : global_step/sec: 7.30436\n",
            "2021-02-28 16:46:57,601 : INFO : examples/sec: 233.74\n",
            "2021-02-28 16:46:57,732 : INFO : global_step/sec: 7.58191\n",
            "2021-02-28 16:46:57,733 : INFO : examples/sec: 242.621\n",
            "2021-02-28 16:46:57,868 : INFO : global_step/sec: 7.32907\n",
            "2021-02-28 16:46:57,869 : INFO : examples/sec: 234.53\n",
            "2021-02-28 16:46:57,998 : INFO : global_step/sec: 7.72899\n",
            "2021-02-28 16:46:58,000 : INFO : examples/sec: 247.328\n",
            "2021-02-28 16:46:58,132 : INFO : global_step/sec: 7.46561\n",
            "2021-02-28 16:46:58,133 : INFO : examples/sec: 238.899\n",
            "2021-02-28 16:46:58,268 : INFO : global_step/sec: 7.33935\n",
            "2021-02-28 16:46:58,269 : INFO : examples/sec: 234.859\n",
            "2021-02-28 16:46:58,402 : INFO : global_step/sec: 7.455\n",
            "2021-02-28 16:46:58,404 : INFO : examples/sec: 238.56\n",
            "2021-02-28 16:46:58,539 : INFO : loss = 0.00062859606 (1.345 sec)\n",
            "2021-02-28 16:46:58,542 : INFO : global_step/sec: 7.13185\n",
            "2021-02-28 16:46:58,544 : INFO : examples/sec: 228.219\n",
            "2021-02-28 16:46:58,678 : INFO : global_step/sec: 7.36255\n",
            "2021-02-28 16:46:58,679 : INFO : examples/sec: 235.602\n",
            "2021-02-28 16:46:58,809 : INFO : global_step/sec: 7.63452\n",
            "2021-02-28 16:46:58,810 : INFO : examples/sec: 244.305\n",
            "2021-02-28 16:46:58,943 : INFO : global_step/sec: 7.4878\n",
            "2021-02-28 16:46:58,943 : INFO : examples/sec: 239.609\n",
            "2021-02-28 16:46:59,074 : INFO : global_step/sec: 7.64169\n",
            "2021-02-28 16:46:59,074 : INFO : examples/sec: 244.534\n",
            "2021-02-28 16:46:59,209 : INFO : global_step/sec: 7.37157\n",
            "2021-02-28 16:46:59,210 : INFO : examples/sec: 235.89\n",
            "2021-02-28 16:46:59,340 : INFO : global_step/sec: 7.66552\n",
            "2021-02-28 16:46:59,341 : INFO : examples/sec: 245.297\n",
            "2021-02-28 16:46:59,473 : INFO : global_step/sec: 7.52335\n",
            "2021-02-28 16:46:59,473 : INFO : examples/sec: 240.747\n",
            "2021-02-28 16:46:59,607 : INFO : global_step/sec: 7.44628\n",
            "2021-02-28 16:46:59,608 : INFO : examples/sec: 238.281\n",
            "2021-02-28 16:46:59,736 : INFO : global_step/sec: 7.7561\n",
            "2021-02-28 16:46:59,737 : INFO : examples/sec: 248.195\n",
            "2021-02-28 16:46:59,869 : INFO : loss = 0.0020535176 (1.330 sec)\n",
            "2021-02-28 16:46:59,872 : INFO : global_step/sec: 7.36604\n",
            "2021-02-28 16:46:59,873 : INFO : examples/sec: 235.713\n",
            "2021-02-28 16:47:00,008 : INFO : global_step/sec: 7.3275\n",
            "2021-02-28 16:47:00,009 : INFO : examples/sec: 234.48\n",
            "2021-02-28 16:47:00,139 : INFO : global_step/sec: 7.62712\n",
            "2021-02-28 16:47:00,140 : INFO : examples/sec: 244.068\n",
            "2021-02-28 16:47:00,271 : INFO : global_step/sec: 7.57484\n",
            "2021-02-28 16:47:00,272 : INFO : examples/sec: 242.395\n",
            "2021-02-28 16:47:00,406 : INFO : global_step/sec: 7.43301\n",
            "2021-02-28 16:47:00,407 : INFO : examples/sec: 237.856\n",
            "2021-02-28 16:47:00,540 : INFO : global_step/sec: 7.44726\n",
            "2021-02-28 16:47:00,541 : INFO : examples/sec: 238.312\n",
            "2021-02-28 16:47:00,669 : INFO : global_step/sec: 7.74556\n",
            "2021-02-28 16:47:00,670 : INFO : examples/sec: 247.858\n",
            "2021-02-28 16:47:00,802 : INFO : global_step/sec: 7.5344\n",
            "2021-02-28 16:47:00,803 : INFO : examples/sec: 241.101\n",
            "2021-02-28 16:47:00,933 : INFO : global_step/sec: 7.62368\n",
            "2021-02-28 16:47:00,934 : INFO : examples/sec: 243.958\n",
            "2021-02-28 16:47:01,067 : INFO : global_step/sec: 7.45133\n",
            "2021-02-28 16:47:01,068 : INFO : examples/sec: 238.443\n",
            "2021-02-28 16:47:01,204 : INFO : loss = 0.001352883 (1.335 sec)\n",
            "2021-02-28 16:47:01,206 : INFO : global_step/sec: 7.20595\n",
            "2021-02-28 16:47:01,210 : INFO : examples/sec: 230.59\n",
            "2021-02-28 16:47:01,338 : INFO : global_step/sec: 7.56436\n",
            "2021-02-28 16:47:01,339 : INFO : examples/sec: 242.06\n",
            "2021-02-28 16:47:01,474 : INFO : global_step/sec: 7.33917\n",
            "2021-02-28 16:47:01,475 : INFO : examples/sec: 234.853\n",
            "2021-02-28 16:47:01,610 : INFO : global_step/sec: 7.38413\n",
            "2021-02-28 16:47:01,611 : INFO : examples/sec: 236.292\n",
            "2021-02-28 16:47:01,744 : INFO : global_step/sec: 7.46551\n",
            "2021-02-28 16:47:01,745 : INFO : examples/sec: 238.896\n",
            "2021-02-28 16:47:01,878 : INFO : global_step/sec: 7.47275\n",
            "2021-02-28 16:47:01,878 : INFO : examples/sec: 239.128\n",
            "2021-02-28 16:47:02,013 : INFO : global_step/sec: 7.39675\n",
            "2021-02-28 16:47:02,014 : INFO : examples/sec: 236.696\n",
            "2021-02-28 16:47:02,147 : INFO : global_step/sec: 7.45533\n",
            "2021-02-28 16:47:02,148 : INFO : examples/sec: 238.571\n",
            "2021-02-28 16:47:02,280 : INFO : global_step/sec: 7.5383\n",
            "2021-02-28 16:47:02,282 : INFO : examples/sec: 241.226\n",
            "2021-02-28 16:47:02,412 : INFO : Saving checkpoints for 900 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:47:13,700 : INFO : global_step/sec: 0.087563\n",
            "2021-02-28 16:47:13,701 : INFO : examples/sec: 2.80202\n",
            "2021-02-28 16:47:13,835 : INFO : loss = 0.00018422221 (12.631 sec)\n",
            "2021-02-28 16:47:13,845 : INFO : global_step/sec: 6.90632\n",
            "2021-02-28 16:47:13,846 : INFO : examples/sec: 221.002\n",
            "2021-02-28 16:47:13,980 : INFO : global_step/sec: 7.40678\n",
            "2021-02-28 16:47:13,981 : INFO : examples/sec: 237.017\n",
            "2021-02-28 16:47:14,114 : INFO : global_step/sec: 7.45083\n",
            "2021-02-28 16:47:14,115 : INFO : examples/sec: 238.427\n",
            "2021-02-28 16:47:14,245 : INFO : global_step/sec: 7.64447\n",
            "2021-02-28 16:47:14,246 : INFO : examples/sec: 244.623\n",
            "2021-02-28 16:47:14,378 : INFO : global_step/sec: 7.53132\n",
            "2021-02-28 16:47:14,380 : INFO : examples/sec: 241.002\n",
            "2021-02-28 16:47:14,513 : INFO : global_step/sec: 7.40853\n",
            "2021-02-28 16:47:14,513 : INFO : examples/sec: 237.073\n",
            "2021-02-28 16:47:14,641 : INFO : global_step/sec: 7.77109\n",
            "2021-02-28 16:47:14,642 : INFO : examples/sec: 248.675\n",
            "2021-02-28 16:47:14,774 : INFO : global_step/sec: 7.51315\n",
            "2021-02-28 16:47:14,775 : INFO : examples/sec: 240.421\n",
            "2021-02-28 16:47:14,907 : INFO : global_step/sec: 7.52435\n",
            "2021-02-28 16:47:14,908 : INFO : examples/sec: 240.779\n",
            "2021-02-28 16:47:15,041 : INFO : global_step/sec: 7.49857\n",
            "2021-02-28 16:47:15,041 : INFO : examples/sec: 239.954\n",
            "2021-02-28 16:47:15,173 : INFO : loss = 0.0035451427 (1.339 sec)\n",
            "2021-02-28 16:47:15,180 : INFO : global_step/sec: 7.1901\n",
            "2021-02-28 16:47:15,181 : INFO : examples/sec: 230.083\n",
            "2021-02-28 16:47:15,313 : INFO : global_step/sec: 7.52104\n",
            "2021-02-28 16:47:15,314 : INFO : examples/sec: 240.673\n",
            "2021-02-28 16:47:15,447 : INFO : global_step/sec: 7.44861\n",
            "2021-02-28 16:47:15,448 : INFO : examples/sec: 238.355\n",
            "2021-02-28 16:47:15,581 : INFO : global_step/sec: 7.47303\n",
            "2021-02-28 16:47:15,581 : INFO : examples/sec: 239.137\n",
            "2021-02-28 16:47:15,714 : INFO : global_step/sec: 7.50162\n",
            "2021-02-28 16:47:15,715 : INFO : examples/sec: 240.052\n",
            "2021-02-28 16:47:15,847 : INFO : global_step/sec: 7.54447\n",
            "2021-02-28 16:47:15,847 : INFO : examples/sec: 241.423\n",
            "2021-02-28 16:47:15,984 : INFO : global_step/sec: 7.29453\n",
            "2021-02-28 16:47:15,985 : INFO : examples/sec: 233.425\n",
            "2021-02-28 16:47:16,117 : INFO : global_step/sec: 7.51741\n",
            "2021-02-28 16:47:16,117 : INFO : examples/sec: 240.557\n",
            "2021-02-28 16:47:16,245 : INFO : global_step/sec: 7.79906\n",
            "2021-02-28 16:47:16,246 : INFO : examples/sec: 249.57\n",
            "2021-02-28 16:47:16,380 : INFO : global_step/sec: 7.38866\n",
            "2021-02-28 16:47:16,381 : INFO : examples/sec: 236.437\n",
            "2021-02-28 16:47:16,515 : INFO : loss = 0.001088473 (1.341 sec)\n",
            "2021-02-28 16:47:16,516 : INFO : global_step/sec: 7.36029\n",
            "2021-02-28 16:47:16,518 : INFO : examples/sec: 235.529\n",
            "2021-02-28 16:47:16,651 : INFO : global_step/sec: 7.44117\n",
            "2021-02-28 16:47:16,651 : INFO : examples/sec: 238.117\n",
            "2021-02-28 16:47:16,781 : INFO : global_step/sec: 7.63696\n",
            "2021-02-28 16:47:16,782 : INFO : examples/sec: 244.383\n",
            "2021-02-28 16:47:16,913 : INFO : global_step/sec: 7.61865\n",
            "2021-02-28 16:47:16,914 : INFO : examples/sec: 243.797\n",
            "2021-02-28 16:47:17,048 : INFO : global_step/sec: 7.36729\n",
            "2021-02-28 16:47:17,049 : INFO : examples/sec: 235.753\n",
            "2021-02-28 16:47:17,183 : INFO : global_step/sec: 7.40828\n",
            "2021-02-28 16:47:17,184 : INFO : examples/sec: 237.065\n",
            "2021-02-28 16:47:17,317 : INFO : global_step/sec: 7.46154\n",
            "2021-02-28 16:47:17,318 : INFO : examples/sec: 238.769\n",
            "2021-02-28 16:47:17,449 : INFO : global_step/sec: 7.62444\n",
            "2021-02-28 16:47:17,449 : INFO : examples/sec: 243.982\n",
            "2021-02-28 16:47:17,579 : INFO : global_step/sec: 7.66528\n",
            "2021-02-28 16:47:17,580 : INFO : examples/sec: 245.289\n",
            "2021-02-28 16:47:17,712 : INFO : global_step/sec: 7.5429\n",
            "2021-02-28 16:47:17,713 : INFO : examples/sec: 241.373\n",
            "2021-02-28 16:47:17,848 : INFO : loss = 0.00017433595 (1.333 sec)\n",
            "2021-02-28 16:47:17,849 : INFO : global_step/sec: 7.26312\n",
            "2021-02-28 16:47:17,851 : INFO : examples/sec: 232.42\n",
            "2021-02-28 16:47:17,989 : INFO : global_step/sec: 7.17811\n",
            "2021-02-28 16:47:17,989 : INFO : examples/sec: 229.699\n",
            "2021-02-28 16:47:18,125 : INFO : global_step/sec: 7.31111\n",
            "2021-02-28 16:47:18,126 : INFO : examples/sec: 233.956\n",
            "2021-02-28 16:47:18,263 : INFO : global_step/sec: 7.27133\n",
            "2021-02-28 16:47:18,265 : INFO : examples/sec: 232.682\n",
            "2021-02-28 16:47:18,397 : INFO : global_step/sec: 7.47786\n",
            "2021-02-28 16:47:18,398 : INFO : examples/sec: 239.292\n",
            "2021-02-28 16:47:18,533 : INFO : global_step/sec: 7.31413\n",
            "2021-02-28 16:47:18,535 : INFO : examples/sec: 234.052\n",
            "2021-02-28 16:47:18,663 : INFO : global_step/sec: 7.69182\n",
            "2021-02-28 16:47:18,664 : INFO : examples/sec: 246.138\n",
            "2021-02-28 16:47:18,800 : INFO : global_step/sec: 7.31952\n",
            "2021-02-28 16:47:18,801 : INFO : examples/sec: 234.225\n",
            "2021-02-28 16:47:18,935 : INFO : global_step/sec: 7.38703\n",
            "2021-02-28 16:47:18,936 : INFO : examples/sec: 236.385\n",
            "2021-02-28 16:47:19,069 : INFO : global_step/sec: 7.50048\n",
            "2021-02-28 16:47:19,070 : INFO : examples/sec: 240.015\n",
            "2021-02-28 16:47:19,207 : INFO : loss = 0.003824528 (1.359 sec)\n",
            "2021-02-28 16:47:19,209 : INFO : global_step/sec: 7.1414\n",
            "2021-02-28 16:47:19,210 : INFO : examples/sec: 228.525\n",
            "2021-02-28 16:47:19,217 : INFO : Saving checkpoints for 941 into ./output-wiki-1/model.ckpt.\n",
            "2021-02-28 16:47:43,496 : INFO : Loss for final step: 0.003824528.\n",
            "2021-02-28 16:47:43,497 : INFO : training_loop marked as finished\n",
            "2021-02-28 16:47:43,508 : INFO : Writing example 0 of 861\n",
            "2021-02-28 16:47:43,509 : INFO : *** Example ***\n",
            "2021-02-28 16:47:43,511 : INFO : guid: dev-0\n",
            "2021-02-28 16:47:43,512 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:43,513 : INFO : tokens: [CLS] 使 用 形 式 化 方 法 會 帶 來 很 高 的 成 本 [SEP]\n",
            "2021-02-28 16:47:43,514 : INFO : input_ids: 101 886 4500 2501 2466 1265 3175 3791 3298 2380 889 2523 7770 4638 2768 3315 102 0 0 0\n",
            "2021-02-28 16:47:43,515 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            "2021-02-28 16:47:43,516 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:43,517 : INFO : *** Example ***\n",
            "2021-02-28 16:47:43,519 : INFO : guid: dev-1\n",
            "2021-02-28 16:47:43,520 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:43,524 : INFO : tokens: [CLS] 機 會 成 本 指 的 是 生 產 的 經 濟 成 本 [SEP]\n",
            "2021-02-28 16:47:43,525 : INFO : input_ids: 101 3582 3298 2768 3315 2900 4638 3221 4495 4496 4638 5195 4089 2768 3315 102 0 0 0 0\n",
            "2021-02-28 16:47:43,529 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "2021-02-28 16:47:43,530 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:43,532 : INFO : *** Example ***\n",
            "2021-02-28 16:47:43,533 : INFO : guid: dev-2\n",
            "2021-02-28 16:47:43,538 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:43,539 : INFO : tokens: [CLS] 更 包 含 瞭 計 算 實 際 成 本 的 因 素 [SEP]\n",
            "2021-02-28 16:47:43,539 : INFO : input_ids: 101 3291 1259 1419 4747 6243 5050 2179 7396 2768 3315 4638 1728 5162 102 0 0 0 0 0\n",
            "2021-02-28 16:47:43,542 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "2021-02-28 16:47:43,543 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:43,544 : INFO : *** Example ***\n",
            "2021-02-28 16:47:43,546 : INFO : guid: dev-3\n",
            "2021-02-28 16:47:43,547 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:43,548 : INFO : tokens: [CLS] 而 不 是 其 他 較 為 昂 貴 的 替 代 品 [SEP]\n",
            "2021-02-28 16:47:43,548 : INFO : input_ids: 101 5445 679 3221 1071 800 6733 4158 3203 6523 4638 3296 807 1501 102 0 0 0 0 0\n",
            "2021-02-28 16:47:43,549 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "2021-02-28 16:47:43,549 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:43,550 : INFO : *** Example ***\n",
            "2021-02-28 16:47:43,551 : INFO : guid: dev-4\n",
            "2021-02-28 16:47:43,552 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:43,552 : INFO : tokens: [CLS] 供 給 [UNK] 線 上 的 點 則 代 錶 瞭 邊 際 成 本 [SEP]\n",
            "2021-02-28 16:47:43,553 : INFO : input_ids: 101 897 5183 100 5221 677 4638 7953 1179 807 7100 4747 6920 7396 2768 3315 102 0 0 0\n",
            "2021-02-28 16:47:43,554 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            "2021-02-28 16:47:43,554 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:43,856 : INFO : ***** Running evaluation *****\n",
            "2021-02-28 16:47:43,857 : INFO :   Num examples = 861 (861 actual, 0 padding)\n",
            "2021-02-28 16:47:43,858 : INFO :   Batch size = 32\n",
            "2021-02-28 16:47:45,208 : INFO : Calling model_fn.\n",
            "2021-02-28 16:47:45,209 : INFO : Running eval on CPU\n",
            "2021-02-28 16:47:45,212 : INFO : *** Features ***\n",
            "2021-02-28 16:47:45,213 : INFO :   name = input_ids, shape = (?, 20)\n",
            "2021-02-28 16:47:45,214 : INFO :   name = input_mask, shape = (?, 20)\n",
            "2021-02-28 16:47:45,221 : INFO :   name = is_real_example, shape = (?,)\n",
            "2021-02-28 16:47:45,222 : INFO :   name = label_ids, shape = (?, 3)\n",
            "2021-02-28 16:47:45,223 : INFO :   name = segment_ids, shape = (?, 20)\n",
            "2021-02-28 16:47:47,222 : INFO : **** Trainable Variables ****\n",
            "2021-02-28 16:47:47,223 : INFO :   name = bert/embeddings/word_embeddings:0, shape = (21128, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,224 : INFO :   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,231 : INFO :   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,235 : INFO :   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,235 : INFO :   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,236 : INFO :   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,242 : INFO :   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,254 : INFO :   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,256 : INFO :   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,258 : INFO :   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,259 : INFO :   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,266 : INFO :   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,269 : INFO :   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,275 : INFO :   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,276 : INFO :   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,276 : INFO :   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,277 : INFO :   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,278 : INFO :   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,278 : INFO :   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,279 : INFO :   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,280 : INFO :   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,280 : INFO :   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,284 : INFO :   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,285 : INFO :   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,286 : INFO :   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,290 : INFO :   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,290 : INFO :   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,294 : INFO :   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,297 : INFO :   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,298 : INFO :   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,307 : INFO :   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,309 : INFO :   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,311 : INFO :   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,313 : INFO :   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,314 : INFO :   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,317 : INFO :   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,318 : INFO :   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,320 : INFO :   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,321 : INFO :   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,330 : INFO :   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,334 : INFO :   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,334 : INFO :   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,335 : INFO :   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,336 : INFO :   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,337 : INFO :   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,337 : INFO :   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,338 : INFO :   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,340 : INFO :   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,341 : INFO :   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,343 : INFO :   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,347 : INFO :   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,348 : INFO :   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,350 : INFO :   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,352 : INFO :   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,353 : INFO :   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,359 : INFO :   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,366 : INFO :   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,367 : INFO :   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,370 : INFO :   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,370 : INFO :   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,373 : INFO :   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,376 : INFO :   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,378 : INFO :   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,389 : INFO :   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,390 : INFO :   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,392 : INFO :   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,392 : INFO :   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,396 : INFO :   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,397 : INFO :   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,399 : INFO :   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,400 : INFO :   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,402 : INFO :   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,407 : INFO :   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,409 : INFO :   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,412 : INFO :   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,413 : INFO :   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,415 : INFO :   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,417 : INFO :   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,418 : INFO :   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,420 : INFO :   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,421 : INFO :   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,422 : INFO :   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,422 : INFO :   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,424 : INFO :   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,426 : INFO :   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,428 : INFO :   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,430 : INFO :   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,435 : INFO :   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,435 : INFO :   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,443 : INFO :   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,444 : INFO :   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,445 : INFO :   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,448 : INFO :   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,449 : INFO :   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,449 : INFO :   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,452 : INFO :   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,452 : INFO :   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,453 : INFO :   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,453 : INFO :   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,459 : INFO :   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,459 : INFO :   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,460 : INFO :   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,460 : INFO :   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,461 : INFO :   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,461 : INFO :   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,462 : INFO :   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,462 : INFO :   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,463 : INFO :   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,463 : INFO :   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,463 : INFO :   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,464 : INFO :   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,464 : INFO :   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,465 : INFO :   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,466 : INFO :   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,467 : INFO :   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,467 : INFO :   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,469 : INFO :   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,469 : INFO :   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,472 : INFO :   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,473 : INFO :   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,473 : INFO :   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,474 : INFO :   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,474 : INFO :   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,475 : INFO :   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,478 : INFO :   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,479 : INFO :   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,479 : INFO :   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,480 : INFO :   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,480 : INFO :   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,481 : INFO :   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,481 : INFO :   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,484 : INFO :   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,485 : INFO :   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,485 : INFO :   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,486 : INFO :   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,486 : INFO :   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,487 : INFO :   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,487 : INFO :   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,489 : INFO :   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,489 : INFO :   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,490 : INFO :   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,493 : INFO :   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,494 : INFO :   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,494 : INFO :   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,495 : INFO :   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,495 : INFO :   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,496 : INFO :   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,496 : INFO :   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,497 : INFO :   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,499 : INFO :   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,499 : INFO :   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,500 : INFO :   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,500 : INFO :   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,501 : INFO :   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,503 : INFO :   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,504 : INFO :   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,504 : INFO :   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,505 : INFO :   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,505 : INFO :   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,506 : INFO :   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,507 : INFO :   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,508 : INFO :   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,510 : INFO :   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,512 : INFO :   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,512 : INFO :   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,513 : INFO :   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,515 : INFO :   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,515 : INFO :   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,519 : INFO :   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,520 : INFO :   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,520 : INFO :   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,521 : INFO :   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,526 : INFO :   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,527 : INFO :   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,527 : INFO :   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,528 : INFO :   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,529 : INFO :   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,531 : INFO :   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,532 : INFO :   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,533 : INFO :   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,533 : INFO :   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,535 : INFO :   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,536 : INFO :   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,537 : INFO :   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,537 : INFO :   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,539 : INFO :   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,540 : INFO :   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,540 : INFO :   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,541 : INFO :   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,541 : INFO :   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,545 : INFO :   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,545 : INFO :   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,546 : INFO :   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,547 : INFO :   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,547 : INFO :   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,548 : INFO :   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,550 : INFO :   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,551 : INFO :   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,552 : INFO :   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:47,552 : INFO :   name = intent_output_weights:0, shape = (3, 768)\n",
            "2021-02-28 16:47:47,553 : INFO :   name = intent_output_bias:0, shape = (3,)\n",
            "2021-02-28 16:47:48,737 : INFO : Done calling model_fn.\n",
            "2021-02-28 16:47:48,758 : INFO : Starting evaluation at 2021-02-28T16:47:48Z\n",
            "2021-02-28 16:47:49,177 : INFO : Graph was finalized.\n",
            "2021-02-28 16:47:49,289 : INFO : Restoring parameters from ./output-wiki-1/model.ckpt-941\n",
            "2021-02-28 16:47:50,057 : INFO : Running local_init_op.\n",
            "2021-02-28 16:47:50,144 : INFO : Done running local_init_op.\n",
            "2021-02-28 16:47:52,022 : INFO : Finished evaluation at 2021-02-28-16:47:52\n",
            "2021-02-28 16:47:52,024 : INFO : Saving dict for global step 941: class00_f1 = 1.0, class00_precision = 1.0, class00_recall = 1.0, class00_threshold = 0.0050251256, class01_f1 = 1.0, class01_precision = 1.0, class01_recall = 1.0, class01_threshold = 0.015075377, class02_f1 = 1.0, class02_precision = 1.0, class02_recall = 1.0, class02_threshold = 0.0050251256, class_intent_f1 = 1.0, class_precision = 1.0, class_recall = 1.0, class_threshold_ = 0.015075377, global_step = 941, loss = 0.0010355153\n",
            "2021-02-28 16:47:52,543 : INFO : Saving 'checkpoint_path' summary for global step 941: ./output-wiki-1/model.ckpt-941\n",
            "2021-02-28 16:47:52,550 : INFO : evaluation_loop marked as finished\n",
            "2021-02-28 16:47:52,550 : INFO : ***** Eval results *****\n",
            "2021-02-28 16:47:52,551 : INFO :   class00_f1 = 1.0\n",
            "2021-02-28 16:47:52,553 : INFO :   class00_precision = 1.0\n",
            "2021-02-28 16:47:52,558 : INFO :   class00_recall = 1.0\n",
            "2021-02-28 16:47:52,558 : INFO :   class00_threshold = 0.0050251256\n",
            "2021-02-28 16:47:52,560 : INFO : \n",
            "2021-02-28 16:47:52,561 : INFO :   class01_f1 = 1.0\n",
            "2021-02-28 16:47:52,566 : INFO :   class01_precision = 1.0\n",
            "2021-02-28 16:47:52,570 : INFO :   class01_recall = 1.0\n",
            "2021-02-28 16:47:52,579 : INFO :   class01_threshold = 0.015075377\n",
            "2021-02-28 16:47:52,581 : INFO : \n",
            "2021-02-28 16:47:52,582 : INFO :   class02_f1 = 1.0\n",
            "2021-02-28 16:47:52,582 : INFO :   class02_precision = 1.0\n",
            "2021-02-28 16:47:52,583 : INFO :   class02_recall = 1.0\n",
            "2021-02-28 16:47:52,584 : INFO :   class02_threshold = 0.0050251256\n",
            "2021-02-28 16:47:52,584 : INFO : \n",
            "2021-02-28 16:47:52,587 : INFO :   class_intent_f1 = 1.0\n",
            "2021-02-28 16:47:52,594 : INFO :   class_precision = 1.0\n",
            "2021-02-28 16:47:52,595 : INFO :   class_recall = 1.0\n",
            "2021-02-28 16:47:52,598 : INFO :   class_threshold_ = 0.015075377\n",
            "2021-02-28 16:47:52,599 : INFO :   loss = 0.0010355153\n",
            "2021-02-28 16:47:52,601 : INFO :   global_step = 941\n",
            "2021-02-28 16:47:52,604 : INFO : Writing example 0 of 95\n",
            "2021-02-28 16:47:52,605 : INFO : *** Example ***\n",
            "2021-02-28 16:47:52,606 : INFO : guid: test-0\n",
            "2021-02-28 16:47:52,608 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:52,608 : INFO : tokens: [CLS] 使 用 l i n u x 主 要 的 成 本 為 移 植 [SEP]\n",
            "2021-02-28 16:47:52,609 : INFO : input_ids: 101 886 4500 154 151 156 163 166 712 6206 4638 2768 3315 4158 4919 3490 102 0 0 0\n",
            "2021-02-28 16:47:52,610 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            "2021-02-28 16:47:52,612 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:52,613 : INFO : *** Example ***\n",
            "2021-02-28 16:47:52,614 : INFO : guid: test-1\n",
            "2021-02-28 16:47:52,614 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:52,617 : INFO : tokens: [CLS] 但 電 報 的 成 本 卻 始 終 沒 有 降 下 來 [SEP]\n",
            "2021-02-28 16:47:52,618 : INFO : input_ids: 101 852 7442 1841 4638 2768 3315 1320 1993 5173 3760 3300 7360 678 889 102 0 0 0 0\n",
            "2021-02-28 16:47:52,618 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "2021-02-28 16:47:52,618 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:52,621 : INFO : *** Example ***\n",
            "2021-02-28 16:47:52,621 : INFO : guid: test-2\n",
            "2021-02-28 16:47:52,622 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:52,624 : INFO : tokens: [CLS] 超 重 水 的 製 取 成 本 比 重 水 高 上 萬 倍 [SEP]\n",
            "2021-02-28 16:47:52,624 : INFO : input_ids: 101 6631 7028 3717 4638 6182 1357 2768 3315 3683 7028 3717 7770 677 5857 945 102 0 0 0\n",
            "2021-02-28 16:47:52,625 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
            "2021-02-28 16:47:52,625 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:52,628 : INFO : *** Example ***\n",
            "2021-02-28 16:47:52,628 : INFO : guid: test-3\n",
            "2021-02-28 16:47:52,629 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:52,629 : INFO : tokens: [CLS] 在 大 橋 所 有 區 段 橋 樑 中 最 為 昂 貴 [SEP]\n",
            "2021-02-28 16:47:52,630 : INFO : input_ids: 101 1762 1920 3578 2792 3300 1281 3667 3578 3558 704 3297 4158 3203 6523 102 0 0 0 0\n",
            "2021-02-28 16:47:52,631 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "2021-02-28 16:47:52,633 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:52,634 : INFO : *** Example ***\n",
            "2021-02-28 16:47:52,635 : INFO : guid: test-4\n",
            "2021-02-28 16:47:52,636 : INFO : label: [經濟_成本]\n",
            "2021-02-28 16:47:52,638 : INFO : tokens: [CLS] 這 些 小 成 本 作 品 口 碑 大 多 不 錯 [SEP]\n",
            "2021-02-28 16:47:52,638 : INFO : input_ids: 101 6857 763 2207 2768 3315 868 1501 1366 4811 1920 1914 679 7097 102 0 0 0 0 0\n",
            "2021-02-28 16:47:52,639 : INFO : input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            "2021-02-28 16:47:52,640 : INFO : segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "2021-02-28 16:47:52,706 : INFO : ***** Running prediction*****\n",
            "2021-02-28 16:47:52,711 : INFO :   Num examples = 95 (95 actual, 0 padding)\n",
            "2021-02-28 16:47:52,715 : INFO :   Batch size = 32\n",
            "2021-02-28 16:47:52,802 : INFO : Calling model_fn.\n",
            "2021-02-28 16:47:52,803 : INFO : Running infer on CPU\n",
            "2021-02-28 16:47:52,804 : INFO : *** Features ***\n",
            "2021-02-28 16:47:52,805 : INFO :   name = input_ids, shape = (?, 20)\n",
            "2021-02-28 16:47:52,807 : INFO :   name = input_mask, shape = (?, 20)\n",
            "2021-02-28 16:47:52,807 : INFO :   name = is_real_example, shape = (?,)\n",
            "2021-02-28 16:47:52,808 : INFO :   name = label_ids, shape = (?, 3)\n",
            "2021-02-28 16:47:52,810 : INFO :   name = segment_ids, shape = (?, 20)\n",
            "2021-02-28 16:47:54,842 : INFO : **** Trainable Variables ****\n",
            "2021-02-28 16:47:54,843 : INFO :   name = bert/embeddings/word_embeddings:0, shape = (21128, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,843 : INFO :   name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,853 : INFO :   name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,855 : INFO :   name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,858 : INFO :   name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,859 : INFO :   name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,860 : INFO :   name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,861 : INFO :   name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,862 : INFO :   name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,863 : INFO :   name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,864 : INFO :   name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,865 : INFO :   name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,866 : INFO :   name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,868 : INFO :   name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,868 : INFO :   name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,869 : INFO :   name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,872 : INFO :   name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,872 : INFO :   name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,873 : INFO :   name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,876 : INFO :   name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,876 : INFO :   name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,877 : INFO :   name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,877 : INFO :   name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,880 : INFO :   name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,880 : INFO :   name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,881 : INFO :   name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,881 : INFO :   name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,883 : INFO :   name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,884 : INFO :   name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,885 : INFO :   name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,887 : INFO :   name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,888 : INFO :   name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,888 : INFO :   name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,891 : INFO :   name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,891 : INFO :   name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,892 : INFO :   name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,893 : INFO :   name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,895 : INFO :   name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,896 : INFO :   name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,896 : INFO :   name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,899 : INFO :   name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,899 : INFO :   name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,900 : INFO :   name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,901 : INFO :   name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,903 : INFO :   name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,903 : INFO :   name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,904 : INFO :   name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,907 : INFO :   name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,908 : INFO :   name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,908 : INFO :   name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,909 : INFO :   name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,911 : INFO :   name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,912 : INFO :   name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,913 : INFO :   name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,915 : INFO :   name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,915 : INFO :   name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,916 : INFO :   name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,916 : INFO :   name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,919 : INFO :   name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,919 : INFO :   name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,920 : INFO :   name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,920 : INFO :   name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,921 : INFO :   name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,922 : INFO :   name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,923 : INFO :   name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,923 : INFO :   name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,925 : INFO :   name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,926 : INFO :   name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,926 : INFO :   name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,927 : INFO :   name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,929 : INFO :   name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,930 : INFO :   name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,930 : INFO :   name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,931 : INFO :   name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,932 : INFO :   name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,933 : INFO :   name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,933 : INFO :   name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,934 : INFO :   name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,937 : INFO :   name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,938 : INFO :   name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,938 : INFO :   name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,939 : INFO :   name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,939 : INFO :   name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,940 : INFO :   name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,941 : INFO :   name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,942 : INFO :   name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,944 : INFO :   name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,945 : INFO :   name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,945 : INFO :   name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,945 : INFO :   name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,947 : INFO :   name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,948 : INFO :   name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,949 : INFO :   name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,950 : INFO :   name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,952 : INFO :   name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,952 : INFO :   name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,953 : INFO :   name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,953 : INFO :   name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,954 : INFO :   name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,955 : INFO :   name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,956 : INFO :   name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,957 : INFO :   name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,960 : INFO :   name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,960 : INFO :   name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,961 : INFO :   name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,961 : INFO :   name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,962 : INFO :   name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,963 : INFO :   name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,964 : INFO :   name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,964 : INFO :   name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,966 : INFO :   name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,967 : INFO :   name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,967 : INFO :   name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,968 : INFO :   name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,969 : INFO :   name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,970 : INFO :   name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,971 : INFO :   name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,972 : INFO :   name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,973 : INFO :   name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,974 : INFO :   name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,975 : INFO :   name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,976 : INFO :   name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,978 : INFO :   name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,979 : INFO :   name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,979 : INFO :   name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,980 : INFO :   name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,980 : INFO :   name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,983 : INFO :   name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,984 : INFO :   name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,984 : INFO :   name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,985 : INFO :   name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,986 : INFO :   name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,986 : INFO :   name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,987 : INFO :   name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,988 : INFO :   name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,988 : INFO :   name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,990 : INFO :   name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,991 : INFO :   name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,991 : INFO :   name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,994 : INFO :   name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,995 : INFO :   name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,995 : INFO :   name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,996 : INFO :   name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,996 : INFO :   name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,997 : INFO :   name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,998 : INFO :   name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:54,999 : INFO :   name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,000 : INFO :   name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,001 : INFO :   name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,001 : INFO :   name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,003 : INFO :   name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,004 : INFO :   name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,005 : INFO :   name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,005 : INFO :   name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,006 : INFO :   name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,008 : INFO :   name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,009 : INFO :   name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,009 : INFO :   name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,010 : INFO :   name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,011 : INFO :   name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,012 : INFO :   name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,013 : INFO :   name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,014 : INFO :   name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,015 : INFO :   name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,016 : INFO :   name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,017 : INFO :   name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,018 : INFO :   name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,020 : INFO :   name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,020 : INFO :   name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,021 : INFO :   name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,022 : INFO :   name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,024 : INFO :   name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,024 : INFO :   name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,025 : INFO :   name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,025 : INFO :   name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,028 : INFO :   name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,028 : INFO :   name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,029 : INFO :   name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,029 : INFO :   name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,031 : INFO :   name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,032 : INFO :   name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,032 : INFO :   name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,033 : INFO :   name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,034 : INFO :   name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,035 : INFO :   name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,036 : INFO :   name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,037 : INFO :   name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,038 : INFO :   name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,039 : INFO :   name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,040 : INFO :   name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,042 : INFO :   name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,042 : INFO :   name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,043 : INFO :   name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,044 : INFO :   name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,045 : INFO :   name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,046 : INFO :   name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,051 : INFO :   name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,052 : INFO :   name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,053 : INFO :   name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2021-02-28 16:47:55,054 : INFO :   name = intent_output_weights:0, shape = (3, 768)\n",
            "2021-02-28 16:47:55,056 : INFO :   name = intent_output_bias:0, shape = (3,)\n",
            "2021-02-28 16:47:55,066 : INFO : Done calling model_fn.\n",
            "2021-02-28 16:47:55,890 : INFO : Graph was finalized.\n",
            "2021-02-28 16:47:55,898 : INFO : Restoring parameters from ./output-wiki-1/model.ckpt-941\n",
            "2021-02-28 16:47:56,692 : INFO : Running local_init_op.\n",
            "2021-02-28 16:47:56,761 : INFO : Done running local_init_op.\n",
            "2021-02-28 16:47:57,478 : INFO : prediction_loop marked as finished\n",
            "2021-02-28 16:47:57,479 : INFO : prediction_loop marked as finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3VuZIFsjNte"
      },
      "source": [
        "# 顯示結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dAM_7_Oj4Eh",
        "outputId": "65f3e807-fa78-48f2-953e-d96900177f55"
      },
      "source": [
        "with open(\"./output-wiki-1/eval_results.txt\") as f:\n",
        "  for l in f.readlines():\n",
        "    print(l)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class00_f1 = 1.0\n",
            "\n",
            "class00_precision = 1.0\n",
            "\n",
            "class00_recall = 1.0\n",
            "\n",
            "class00_threshold = 0.0050251256\n",
            "\n",
            "\n",
            "\n",
            "class01_f1 = 1.0\n",
            "\n",
            "class01_precision = 1.0\n",
            "\n",
            "class01_recall = 1.0\n",
            "\n",
            "class01_threshold = 0.015075377\n",
            "\n",
            "\n",
            "\n",
            "class02_f1 = 1.0\n",
            "\n",
            "class02_precision = 1.0\n",
            "\n",
            "class02_recall = 1.0\n",
            "\n",
            "class02_threshold = 0.0050251256\n",
            "\n",
            "\n",
            "\n",
            "class_intent_f1 = 1.0\n",
            "\n",
            "class_precision = 1.0\n",
            "\n",
            "class_recall = 1.0\n",
            "\n",
            "class_threshold_ = 0.015075377\n",
            "\n",
            "loss = 0.0010355153\n",
            "\n",
            "global_step = 941\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8bdUsDSjxpQ",
        "outputId": "520ae225-1d05-4e76-f319-deb0ee79ef63"
      },
      "source": [
        "with open(\"./output-wiki-1/test_results.txt\") as f:\n",
        "  for l in f.readlines():\n",
        "    print(l)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class00_f1 = 1.0\n",
            "\n",
            "class00_precision = 1.0\n",
            "\n",
            "class00_recall = 1.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class01_f1 = 1.0\n",
            "\n",
            "class01_precision = 1.0\n",
            "\n",
            "class01_recall = 1.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class02_f1 = 1.0\n",
            "\n",
            "class02_precision = 1.0\n",
            "\n",
            "class02_recall = 1.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class_intent_f1 = 1.0\n",
            "\n",
            "class_intent_precision = 1.0\n",
            "\n",
            "class_intent_recall = 1.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCn5P4drjNUw",
        "outputId": "231fe2d8-0efb-4594-919e-193bdeab300d"
      },
      "source": [
        "with open(\"./output-wiki-1/test_results.tsv\") as f:\n",
        "  for l in f.readlines():\n",
        "    print(l)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frame_O_X\tintent OX\tintent_label\tintent_pred\tsentence\n",
            "\n",
            "[4.0233135e-05 6.1273575e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]使用linux主要的成本為移植[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1333179e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]但電報的成本卻始終沒有降下來[SEP]\n",
            "\n",
            "[4.0262938e-05 6.1243773e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]超重水的製取成本比重水高上萬倍[SEP]\n",
            "\n",
            "[4.0352345e-05 6.1392784e-05 9.9992651e-01]\t經濟_成本\t經濟_成本\t[CLS]在大橋所有區段橋樑中最為昂貴[SEP]\n",
            "\n",
            "[4.0173531e-05 6.1452389e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]這些小成本作品口碑大多不錯[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1273575e-05 9.9992651e-01]\t經濟_成本\t經濟_成本\t[CLS]雖然當時的位圖顯示器十分昂貴[SEP]\n",
            "\n",
            "[4.0173531e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]單位成本和開關功率消耗下降[SEP]\n",
            "\n",
            "[4.0173531e-05 6.1273575e-05 9.9992651e-01]\t經濟_成本\t經濟_成本\t[CLS]然而從中開採天然氣的成本較高[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1422586e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]而情侶們在情人節當天花費較多[SEP]\n",
            "\n",
            "[4.017353e-05 6.130338e-05 9.999265e-01]\t經濟_成本\t經濟_成本\t[CLS]來創建一個符[UNK]成本效益的提案[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1184168e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]而貨櫃碼頭的泊運費用也十分昂貴[SEP]\n",
            "\n",
            "[4.0262938e-05 6.1273575e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]另一方麵也節省下測試人員的成本[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1333179e-05 9.9992651e-01]\t經濟_成本\t經濟_成本\t[CLS]大幅減低成本以保障公司的存亡[SEP]\n",
            "\n",
            "[4.0382147e-05 6.1213970e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]供水成本已成為縣政府的沉重負擔[SEP]\n",
            "\n",
            "[4.0382147e-05 6.1184168e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]霍爾曼也花費相當多時間來陪伴她[SEP]\n",
            "\n",
            "[4.0173531e-05 6.1422586e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]為瞭解決這個花費過高的問題[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1422586e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]但由於成本原因並沒有采納使用[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1273575e-05 9.9992651e-01]\t經濟_成本\t經濟_成本\t[CLS]飛行員操作強度和成本能互相兼顧[SEP]\n",
            "\n",
            "[4.017353e-05 6.145239e-05 9.999265e-01]\t經濟_成本\t經濟_成本\t[CLS]福特緻力於係統化的降低成本[SEP]\n",
            "\n",
            "[4.0382147e-05 6.1273575e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]而報業也已要麵對新聞紙成本上昇[SEP]\n",
            "\n",
            "[4.0143728e-05 6.1452389e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]錶示同等工作比計劃少花成本[SEP]\n",
            "\n",
            "[4.0262938e-05 6.1452389e-05 9.9992639e-01]\t經濟_成本\t經濟_成本\t[CLS]核能艦艇的建造成本逐年下降[SEP]\n",
            "\n",
            "[4.0262938e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]億美元的新型航空母艦研發成本[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1422586e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]讓卡森伯格更加注重成本削減[SEP]\n",
            "\n",
            "[4.0262938e-05 6.1422586e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]佔鐵路成本中相當重要的部分[SEP]\n",
            "\n",
            "[4.0352345e-05 6.1243773e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]那麼風能和太陽能的成本將分彆在[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1303377e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]因成本問題和客量不足而遭擱置[SEP]\n",
            "\n",
            "[4.029274e-05 6.136298e-05 9.999264e-01]\t經濟_成本\t經濟_成本\t[CLS]時間及成本上遠不及水路和公路[SEP]\n",
            "\n",
            "[4.0352345e-05 6.1184168e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]那麽生產成本和交換價值意義相同[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1392784e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]成為香港史上最昂貴的鐵路項目[SEP]\n",
            "\n",
            "[4.0173531e-05 6.1273575e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]鑒於貝爾的設備和服務太過昂貴[SEP]\n",
            "\n",
            "[4.017353e-05 6.145239e-05 9.999264e-01]\t經濟_成本\t經濟_成本\t[CLS]轟炸機和防空建築的成本降低[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]房地產最昂貴的地區在佩徹斯剋[SEP]\n",
            "\n",
            "[4.0143728e-05 6.1511993e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]為瞭預先控製新艦的建造成本[SEP]\n",
            "\n",
            "[4.0143728e-05 6.1452389e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]加上雙交直流型電車成本較高[SEP]\n",
            "\n",
            "[4.0143728e-05 6.1422586e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]以低成本製造藥物滿足國內需要[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1303377e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]討論這些要素的分佈花費與價值[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]離岸發電成本較高但效率也高[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]兩種方式生成本質上等價的概念[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1333179e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]在澳洲高薪水高人工成本的情況下[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1362982e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]中小企業可以憑專利低成本融資[SEP]\n",
            "\n",
            "[4.0143728e-05 6.1392784e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]推齣瞭低成本的成人遊戲作品[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]這場遊行的總花費仍在新颱幣[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1213970e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]但因為拍攝成本比一般的多齣一倍[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1333179e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]是香港當時造價第二昂貴的建築物[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1392784e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]廣告都是以韆次印象成本計費[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1422586e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]和相對的日漸上升的維修成本[SEP]\n",
            "\n",
            "[4.0441751e-05 6.1273575e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]但鑒於此次起義已經花費十萬餘元[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1333179e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]支付預期的損失和花費以及分紅[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1333179e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]減少用油開支也間接降低整體成本[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]大幅節省瞭航空公司的人力成本[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1333179e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]在當時是世界上造價最昂貴的胸罩[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1273575e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]盡管這些年來齣版成本一直在增加[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1273575e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]高度的精細導緻生產成本極為高昂[SEP]\n",
            "\n",
            "[4.0143728e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]因為它們擁有同樣的成本函數[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1273575e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]這大大降低瞭從頭計算的計算成本[SEP]\n",
            "\n",
            "[4.0143728e-05 6.1392784e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]計畫為名尋求一款低成本機種[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1273575e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]擁有充分的流動性且沒有交易成本[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]可降低第三方的健康風險和成本[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1273575e-05 9.9992651e-01]\t經濟_成本\t經濟_成本\t[CLS]符[UNK]低成本航空高效率的營運原則[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]政府估計此刻修訂需要花費至少[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1452389e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]以取代成本較高的正版貝瑞塔[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1303377e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]李嘉圖都建立瞭生産成本的理論[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1511993e-05 9.9992639e-01]\t經濟_成本\t經濟_成本\t[CLS]而且朝鮮的汽車價格極之昂貴[SEP]\n",
            "\n",
            "[4.0352345e-05 6.1273575e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]認為既是公益活動為何要扣除成本[SEP]\n",
            "\n",
            "[4.0441751e-05 6.1184168e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]乾隆三十七年至四十二年花費白銀[SEP]\n",
            "\n",
            "[4.0143728e-05 6.1392784e-05 9.9992651e-01]\t經濟_成本\t經濟_成本\t[CLS]以交易成本概念解釋企業規模[SEP]\n",
            "\n",
            "[4.0173531e-05 6.1452389e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]低成本航空的機票較種類單一[SEP]\n",
            "\n",
            "[4.0292740e-05 6.1243773e-05 9.9992657e-01]\t經濟_成本\t經濟_成本\t[CLS]以較低持有成本獲取較高年化利率[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1452389e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]具有相當快速且低成本的優點[SEP]\n",
            "\n",
            "[4.0352345e-05 6.1184168e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]而計畫從開始到終止的花費超過瞭[SEP]\n",
            "\n",
            "[4.0173531e-05 6.1362982e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]供他們完成本地或海外大學課程[SEP]\n",
            "\n",
            "[4.0203333e-05 6.1362982e-05 9.9992651e-01]\t經濟_成本\t經濟_成本\t[CLS]自創品牌令其成本可大幅下降[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1452389e-05 9.9992645e-01]\t經濟_成本\t經濟_成本\t[CLS]成本和大眾疑慮又遠低於核能[SEP]\n",
            "\n",
            "[4.0233135e-05 6.1422586e-05 9.9992639e-01]\t經濟_成本\t經濟_成本\t[CLS]因建造tft工廠的巨大花費[SEP]\n",
            "\n",
            "[9.9994022e-01 1.2344122e-04 1.3813376e-04]\t永續_污染\t永續_污染\t[CLS]黃河流域的生態破壞開始減少[SEP]\n",
            "\n",
            "[9.9994051e-01 1.2305379e-04 1.3783574e-04]\t永續_污染\t永續_污染\t[CLS]因此自然環境基本上未被破壞[SEP]\n",
            "\n",
            "[9.9994129e-01 1.2207031e-04 1.3738871e-04]\t永續_污染\t永續_污染\t[CLS]不會對環境造成破壞或是損害健康[SEP]\n",
            "\n",
            "[9.9994040e-01 1.2326241e-04 1.3828278e-04]\t永續_污染\t永續_污染\t[CLS]山體滑坡等自然災害時有發生[SEP]\n",
            "\n",
            "[9.9994111e-01 1.2201071e-04 1.3816357e-04]\t永續_污染\t永續_污染\t[CLS]此處自古以來就沒有大的自然災害[SEP]\n",
            "\n",
            "[9.99941289e-01 1.21831894e-04 1.37865543e-04]\t永續_污染\t永續_污染\t[CLS]包括各種自然災害和多種意外事故[SEP]\n",
            "\n",
            "[9.9994075e-01 1.2257695e-04 1.3813376e-04]\t永續_污染\t永續_污染\t[CLS]危害人體健康或者破壞生態環境[SEP]\n",
            "\n",
            "[9.9994087e-01 1.2248755e-04 1.3667345e-04]\t永續_污染\t永續_污染\t[CLS]並且是造成地球海洋的主要供應者[SEP]\n",
            "\n",
            "[9.9994075e-01 1.2230873e-04 1.3867021e-04]\t永續_污染\t永續_污染\t[CLS]火山爆發造成當地生態係統的滅絕[SEP]\n",
            "\n",
            "[9.9994040e-01 1.2338161e-04 1.3783574e-04]\t永續_污染\t永續_污染\t[CLS]避免引起巨大聲浪及影響環境[SEP]\n",
            "\n",
            "[9.9994141e-01 1.2210011e-04 1.3625622e-04]\t永續_污染\t永續_污染\t[CLS]當地政府意識到造成的環境問題後[SEP]\n",
            "\n",
            "[0.00296995 0.9989264  0.0021821 ]\t社會_人民感受\t社會_人民感受\t[CLS]由此造成瞭長期的民族關係緊張[SEP]\n",
            "\n",
            "[0.00296083 0.9989244  0.00218034]\t社會_人民感受\t社會_人民感受\t[CLS]以緻在貝魯特造成瞭宗教關係緊張[SEP]\n",
            "\n",
            "[0.0029763  0.9989276  0.00218636]\t社會_人民感受\t社會_人民感受\t[CLS]造成與中國和韓國的緊張關係[SEP]\n",
            "\n",
            "[0.00298023 0.9989295  0.00217682]\t社會_人民感受\t社會_人民感受\t[CLS]而拿破侖的軍隊在恐慌中潰敗瞭[SEP]\n",
            "\n",
            "[0.00299072 0.99893165 0.00217965]\t社會_人民感受\t社會_人民感受\t[CLS]建築物的情況曾引起學生恐慌[SEP]\n",
            "\n",
            "[0.00299048 0.99893165 0.00217962]\t社會_人民感受\t社會_人民感受\t[CLS]雖然當時曾齣現過短暫的恐慌[SEP]\n",
            "\n",
            "[0.00297305 0.998928   0.00217384]\t社會_人民感受\t社會_人民感受\t[CLS]不少公眾對該彗星的齣現感到恐慌[SEP]\n",
            "\n",
            "[0.0029808 0.9989296 0.0021767]\t社會_人民感受\t社會_人民感受\t[CLS]當時曾經引發全國公務員的恐慌[SEP]\n",
            "\n",
            "[0.00298107 0.9989297  0.00217653]\t社會_人民感受\t社會_人民感受\t[CLS]香港市民毋須因這次事件而恐慌[SEP]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
